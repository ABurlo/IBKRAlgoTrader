# =====================
# CORE IMPORTS
# =====================
from ib_insync import *
import pandas as pd
import numpy as np
import mplfinance as mpf
from datetime import datetime, timedelta, time
import asyncio
import nest_asyncio
import logging
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
from time import sleep
from matplotlib.colors import ListedColormap, Normalize, LinearSegmentedColormap
from collections.abc import MutableMapping
import pytz
import re
import matplotlib.patheffects as pe
from matplotlib.cm import ScalarMappable
import seaborn as sns
from matplotlib.dates import DateFormatter

# =====================
# GLOBAL CONFIGURATION
# =====================
class GlobalConfig:
    nest_asyncio.apply()
    symbol = 'TSLA'
    durationStr = '30 D'
    barSizeSetting = '1 hour'
    currency = 'USD'
    initial_balance = 10000
    MIN_REQUIRED_BANDS = 2
    gradient_levels = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
    colors = ['#FF0000', '#FFA500', '#00FF00', '#0000FF']
    outer_levels = ['weak', 'moderate', 'strong']

sns.set_style("whitegrid")
sns.set_context("notebook")
sns.set_palette("tab10")
plt.rcParams.update({
    'font.size': 10,
    'axes.labelcolor': 'black',
    'axes.titlepad': 12,
    'grid.color': 'gray',
    'figure.dpi': 300,
    'axes.facecolor': 'white',
    'figure.facecolor': 'white'
})

MRC_GRADIENT_STYLE = 'full_spectrum'
full_spectrum_colors = ['#FF0000', '#FFA500', '#00FF00', '#0000FF']

def create_colormap(colors_list):
    return LinearSegmentedColormap.from_list('custom_mrc', colors_list, N=len(GlobalConfig.gradient_levels))

full_spectrum_cmap = create_colormap(full_spectrum_colors)
mrc_cmap = full_spectrum_cmap

# =====================
# LINKED LIST DICTIONARY IMPLEMENTATION
# =====================
class LLNode:
    __slots__ = ('key', 'value', 'next')
    def __init__(self, key, value, next=None):
        self.key = key
        self.value = value
        self.next = next

class LLDict(MutableMapping):
    def __init__(self):
        self.head = None
        self._size = 0

    def __setitem__(self, key, value):
        current = self.head
        while current is not None:
            if current.key == key:
                current.value = value
                return
            current = current.next
        self.head = LLNode(key, value, self.head)
        self._size += 1

    def __getitem__(self, key):
        current = self.head
        while current is not None:
            if current.key == key:
                return current.value
            current = current.next
        raise KeyError(key)

    def __delitem__(self, key):
        prev = None
        current = self.head
        while current is not None:
            if current.key == key:
                if prev:
                    prev.next = current.next
                else:
                    self.head = current.next
                self._size -= 1
                return
            prev = current
            current = current.next
        raise KeyError(key)

    def __iter__(self):
        current = self.head
        while current is not None:
            yield current.key
            current = current.next

    def __len__(self):
        return self._size

# =====================
# MARKET CLOSURE WARNING
# =====================
def enforce_ny_timezone(timestamp):
    ny_tz = pytz.timezone('America/New_York')
    if not isinstance(timestamp, pd.Timestamp):
        timestamp = pd.to_datetime(timestamp)
    if timestamp.tzinfo is None:
        logger.debug(f"Localizing naive timestamp {timestamp} to NY timezone")
        return ny_tz.localize(timestamp)
    else:
        logger.debug(f"Converting tz-aware timestamp {timestamp} to NY timezone")
        return timestamp.tz_convert(ny_tz)

def is_market_close(index):
    ny_tz = pytz.timezone('America/New_York')
    if index.tzinfo is None:
        logger.debug(f"Localizing naive index {index} to NY timezone")
        index = index.tz_localize(ny_tz)
    else:
        logger.debug(f"Converting tz-aware index {index} to NY timezone")
        index = index.tz_convert(ny_tz)
    
    current_time = index.time
    market_close_time = time(16, 0)
    time_delta = timedelta(minutes=10)
    
    dummy_date = index.date()
    market_close_dt = ny_tz.localize(datetime.combine(dummy_date, market_close_time))
    
    return (market_close_dt - time_delta) <= index <= market_close_dt

# =====================
# METRICS CALCULATION
# =====================
def calculate_day_metrics(trades, risk_free_rate=0.02):
    """
    Calculate comprehensive daily trading metrics from a list of trade dictionaries.
    
    Parameters:
    - trades: List of trade dictionaries, each containing 'pnl' and 'timestamp'.
    - risk_free_rate: Annualized risk-free rate (default 0.02 or 2%), used for Sharpe/Sortino ratios.
    
    Returns:
    - Dictionary with metrics: win_rate, win_loss_ratio, num_trades, total_pnl, avg_pnl,
      sharpe_ratio, sortino_ratio, max_drawdown, avg_win, avg_loss, profit_factor.
    """
    if not trades:
        return {
            'win_rate': 0.0,
            'win_loss_ratio': 0.0,
            'num_trades': 0,
            'total_pnl': 0.0,
            'avg_pnl': 0.0,
            'sharpe_ratio': 0.0,
            'sortino_ratio': 0.0,
            'max_drawdown': 0.0,
            'avg_win': 0.0,
            'avg_loss': 0.0,
            'profit_factor': 0.0
        }

    num_trades = len(trades)
    wins = losses = total_pnl = 0.0
    pnl_list = []  # For Sharpe, Sortino, and drawdown calculations
    win_pnls = []  # For average win
    loss_pnls = []  # For average loss
    
    for t in trades:
        if not isinstance(t, dict) or 'timestamp' not in t:
            logger.error("Invalid trade format in calculate_day_metrics")
            continue
        trade_pnl = float(t.get('pnl', 0.0))
        pnl_list.append(trade_pnl)
        total_pnl += trade_pnl
        if trade_pnl > 0:
            wins += 1
            win_pnls.append(trade_pnl)
        elif trade_pnl < 0:
            losses += 1
            loss_pnls.append(trade_pnl)

    win_rate = (wins / num_trades * 100) if num_trades > 0 else 0.0
    win_loss_ratio = (wins / losses) if losses > 0 else float('inf') if wins > 0 else 0.0
    avg_pnl = total_pnl / num_trades if num_trades > 0 else 0.0
    avg_win = sum(win_pnls) / len(win_pnls) if win_pnls else 0.0
    avg_loss = sum(loss_pnls) / len(loss_pnls) if loss_pnls else 0.0
    profit_factor = sum(win_pnls) / abs(sum(loss_pnls)) if loss_pnls else float('inf') if win_pnls else 0.0

    pnl_array = np.array(pnl_list)
    daily_rfr = risk_free_rate / 252
    excess_returns = pnl_array - daily_rfr
    mean_excess_return = np.mean(excess_returns)
    std_dev = np.std(pnl_array, ddof=1) if num_trades > 1 else 0.0
    sharpe_ratio = (mean_excess_return / std_dev) * np.sqrt(252) if std_dev > 0 else 0.0

    downside_returns = pnl_array[pnl_array < 0]
    downside_dev = np.std(downside_returns, ddof=1) if len(downside_returns) > 1 else 0.0
    sortino_ratio = (mean_excess_return / downside_dev) * np.sqrt(252) if downside_dev > 0 else 0.0

    if pnl_array.size > 0:
        cumulative_pnl = np.cumsum(pnl_array)
        peak = np.maximum.accumulate(cumulative_pnl)
        drawdowns = (peak - cumulative_pnl) / (peak + 1e-8)
        max_drawdown = np.max(drawdowns) * 100
    else:
        max_drawdown = 0.0

    return {
        'win_rate': round(win_rate, 2),
        'win_loss_ratio': round(win_loss_ratio, 2) if win_loss_ratio != float('inf') else float('inf'),
        'num_trades': num_trades,
        'total_pnl': round(total_pnl, 2),
        'avg_pnl': round(avg_pnl, 2),
        'sharpe_ratio': round(sharpe_ratio, 2),
        'sortino_ratio': round(sortino_ratio, 2),
        'max_drawdown': round(max_drawdown, 2),
        'avg_win': round(avg_win, 2),
        'avg_loss': round(avg_loss, 2),
        'profit_factor': round(profit_factor, 2) if profit_factor != float('inf') else float('inf')
    }

# =====================
# BACKTEST ENGINE
# =====================
class BacktestEngine:
    def __init__(self, mode='neutral'):
        self.mode = mode
        self.mode_config = {
            'aggressive': {
                'rsi_entry': 28, 'williams_entry': -85, 'position_risk': 0.03, 'volatility_mult': 1.8,
                'profit_target': 1.8, 'stop_loss': 0.96, 'adx_threshold': 22, 'di_ratio': 1.25,
                'macd_crossover': 1.15, 'vwap_margin': 0.98, 'stochastic_k_entry': 15
            },
            'neutral': {
                'rsi_entry': 32, 'williams_entry': -80, 'position_risk': 0.02, 'volatility_mult': 1.5,
                'profit_target': 1.5, 'stop_loss': 0.94, 'adx_threshold': 25, 'di_ratio': 1.35,
                'macd_crossover': 1.05, 'vwap_margin': 0.99, 'stochastic_k_entry': 20
            },
            'conservative': {
                'rsi_entry': 35, 'williams_entry': -75, 'position_risk': 0.01, 'volatility_mult': 1.2,
                'profit_target': 1.2, 'stop_loss': 0.92, 'adx_threshold': 28, 'di_ratio': 1.5,
                'macd_crossover': 1.0, 'vwap_margin': 0.995, 'stochastic_k_entry': 25
            }
        }
        self.validate_mode_config()
        self.balance = GlobalConfig.initial_balance
        self.positions = LLDict()
        self.trade_history = []  # Store all trades with additional details
        self.current_position = None
        self.fee_per_share = 0.0035
        self.slippage = 0.0002
        self.volatility_filter = {'min_mrc': 0.02, 'max_mrc': 0.05}
        self.daily_pnl = {}
        self.indicator_weights = {
            'rsi': 0.25, 'williams': 0.25, 'macd': 0.2, 'vwap': 0.15, 'adx': 0.1, 'volume': 0.05
        }
        self.adx_params = {
            'mean_reversion_threshold': 25, 'low_volatility_threshold': 15, 'trend_strength_exit': 40,
            'rapid_trend_threshold': 15
        }
        self.time_exit_hours = 4
        self.signal_exit_threshold = 0.6
        self.profit_target = 0.02
        self.stop_loss = 0.01
        self.backtest_data = []  # Store all data for CSV export

    @property
    def max_position_size(self):
        return self.balance * 0.25

    def validate_mode_config(self):
        required_keys = ['rsi_entry', 'williams_entry', 'position_risk', 'volatility_mult', 'profit_target', 
                         'stop_loss', 'adx_threshold', 'di_ratio', 'macd_crossover']
        for mode, config in self.mode_config.items():
            if not all(k in config for k in required_keys):
                raise ValueError(f"Missing config keys in {mode}")

    def calculate_position_size(self, row):
        mp = self.mode_config[self.mode]
        risk_capital = self.balance * mp['position_risk']
        combined_vol = (max(0.01, row['meanrange']) * mp['volatility_mult'] + row['ATR']) / 2
        return min(self.max_position_size, risk_capital / combined_vol)

    def composite_signal_score(self, row):
        volatility_regime = 1 + min(2, (row['ATR'] / row['close']) * 2.5)
        total_weight = sum(self.indicator_weights.values())
        scores = {}
        conditions_met = 0
        total_conditions = len(self.indicator_weights) + 2

        mode_config = self.mode_config[self.mode]
        rsi_threshold = mode_config['rsi_entry']
        williams_threshold = mode_config['williams_entry']
        adx_threshold = mode_config['adx_threshold']
        macd_crossover = mode_config['macd_crossover']
        di_ratio = mode_config['di_ratio']

        if row['RSI_shifted'] > (100 - rsi_threshold):
            scores['rsi'] = self.indicator_weights['rsi']
            conditions_met += 1
        else:
            scores['rsi'] = 0

        if row['Williams_%R_shifted'] > (-100 - williams_threshold):
            scores['williams'] = self.indicator_weights['williams']
            conditions_met += 1
        else:
            scores['williams'] = 0

        if row['MACD_shifted'] > row['Signal_shifted'] * macd_crossover:
            scores['macd'] = self.indicator_weights['macd']
            conditions_met += 1
        else:
            scores['macd'] = 0

        if row['VWAP_shifted'] < row['close_shifted']:
            scores['vwap'] = self.indicator_weights['vwap']
            conditions_met += 1
        else:
            scores['vwap'] = 0

        if row['adx_shifted'] > adx_threshold:
            scores['adx'] = self.indicator_weights['adx']
            conditions_met += 1
        else:
            scores['adx'] = 0

        if row['volume'] > row['volume_ma']:
            scores['volume'] = self.indicator_weights['volume']
            conditions_met += 1
        else:
            scores['volume'] = 0

        if row['+di_shifted'] > row['-di_shifted'] * di_ratio:
            conditions_met += 1

        if row['%K_shifted'] > row['%D_shifted'] and row['%D_shifted'] > 80:
            conditions_met += 1

        weighted_score = sum(scores[k] for k in self.indicator_weights) / total_weight
        percentage_score = (conditions_met / total_conditions) * volatility_regime * weighted_score

        logger.debug(f"Signal score at {row.name}: {percentage_score:.2%} "
                     f"(Conditions met: {conditions_met}/{total_conditions})")
        return min(1.0, percentage_score)

    def apply_slippage(self, price, is_buy):
        slippage_factor = 1 + (self.slippage if is_buy else -self.slippage)
        return price * slippage_factor
    
    def calculate_fees(self, shares):
        return abs(shares * self.fee_per_share)

    def execute_trade(self, price, shares, action, timestamp, exit_type=None, row=None):
        try:
            price_with_slippage = self.apply_slippage(price, action == 'BUY')
            fees = self.calculate_fees(shares)
            position_value = shares * price_with_slippage

            trade = {
                'timestamp': timestamp,
                'action': action,
                'price': price_with_slippage,
                'shares': shares,
                'position_value': position_value,
                'balance_before': self.balance,
                'exit_type': exit_type if action == 'SELL' else None
            }

            if action == 'BUY':
                if position_value > self.balance:
                    logger.warning(f"Insufficient funds for {GlobalConfig.symbol}: {position_value} > {self.balance}")
                    return None
                self.current_position = {
                    'symbol': GlobalConfig.symbol, 'entry_price': price_with_slippage, 'shares': shares, 
                    'timestamp': timestamp, 'position_value': position_value, 'entry_time': timestamp
                }
                self.balance -= (position_value + fees)
                trade['pnl'] = 0.0
                trade['pnl_pct'] = 0.0
            elif action == 'SELL' and self.current_position:
                entry_price = self.current_position['entry_price']
                entry_value = self.current_position['position_value']
                exit_value = position_value
                pnl = exit_value - entry_value - fees
                pnl_pct = (pnl / entry_value) * 100 if entry_value != 0 else 0

                trade['pnl'] = pnl
                trade['pnl_pct'] = pnl_pct
                self.balance += (exit_value - fees)
                self.daily_pnl[timestamp.strftime('%Y-%m-%d')] = (
                    self.daily_pnl.get(timestamp.strftime('%Y-%m-%d'), 0) + pnl
                )
                self.current_position = None

            trade['balance_after'] = self.balance
            if row is not None:
                trade.update(row.to_dict())  # Add all DataFrame row data (OHLCV, indicators)
            self.trade_history.append(trade)
            self.backtest_data.append(trade)
            return trade
        except Exception as e:
            logger.error(f"Trade execution failed: {str(e)}")
            return None

# =====================
# TRADE EXECUTION CORE
# =====================
def execute_entry(price, timestamp, position_size, row):
    timestamp = enforce_ny_timezone(pd.to_datetime(timestamp))
    shares = max(0.01, position_size / price)
    if not np.isfinite(shares):
        logger.error(f"Invalid share calculation: {position_size}/{price}")
        return None
    trade = engine.execute_trade(price=price, shares=shares, action='BUY', timestamp=timestamp, row=row)
    if trade:
        log_trade(trade)
        return trade
    return None

def execute_exit(price, timestamp, exit_type, row):
    if not engine.current_position:
        logger.warning("Exit attempted with no open position")
        return None
    timestamp = enforce_ny_timezone(pd.to_datetime(timestamp))
    position = engine.current_position
    exit_shares = min(position['shares'], engine.max_position_size)
    trade = engine.execute_trade(price=price, shares=exit_shares, action='SELL', timestamp=timestamp, exit_type=exit_type, row=row)
    if trade:
        log_trade(trade)
        return trade
    return None

# Initialize engine globally
engine = BacktestEngine()

# =====================
# CONDITION CHECKS
# =====================
def check_entry_conditions(df, index):
    if str(index.tz) != 'America/New_York':
        raise ValueError(f"Invalid timezone in entry check: {index.tz}")
    
    try:
        row = df.loc[index]
        short_sma = df['close'].rolling(window=10).mean().shift(1)[index]
        long_sma = df['close'].rolling(window=50).mean().shift(1)[index]
        prev_short_sma = df['close'].rolling(window=10).mean().shift(2)[index]
        prev_long_sma = df['close'].rolling(window=50).mean().shift(2)[index]

        crossover_up = (prev_short_sma <= prev_long_sma) and (short_sma > long_sma)
        position_ok = engine.balance > 1000 and not engine.current_position
        time_ok = not is_market_close(index)

        logger.debug(f"Entry check at {index}: "
                     f"Short SMA={short_sma:.2f}, Long SMA={long_sma:.2f}, "
                     f"Prev Short SMA={prev_short_sma:.2f}, Prev Long SMA={prev_long_sma:.2f}, "
                     f"Crossover Up={crossover_up}, PositionOK={position_ok}, TimeOK={time_ok}")

        return crossover_up and position_ok and time_ok
    
    except KeyError as e:
        logger.error(f"Missing data at {index}: '{e}'")
        return False
    except Exception as e:
        logger.error(f"Error in entry condition check at {index}: {str(e)}")
        return False

def check_exit_conditions(df, index):
    if str(index.tz) != 'America/New_York':
        raise ValueError(f"Invalid timezone in exit check: {index.tz}")
    
    if not engine.current_position:
        return None
    
    try:
        row = df.loc[index]
        current_time = enforce_ny_timezone(index)
        entry_time = engine.current_position['entry_time']
        entry_price = engine.current_position['entry_price']
        current_price = row['close']

        # 1. Time-Based Exit: Check if 4 hours have passed
        time_diff = (current_time - entry_time).total_seconds() / 3600  # Convert to hours
        time_exit = time_diff >= engine.time_exit_hours

        # 2. Signal Score Exit: High score indicating reversal
        signal_score = engine.composite_signal_score(row)
        signal_exit = signal_score >= engine.signal_exit_threshold

        # 3. Profit Target/Stop Loss Exit
        price_change = (current_price - entry_price) / entry_price
        profit_target_exit = price_change >= engine.profit_target
        stop_loss_exit = price_change <= -engine.stop_loss
        pt_sl_exit = profit_target_exit or stop_loss_exit

        # Determine which exit condition is met first
        if time_exit:
            return 'Time-Based'
        elif signal_exit:
            return 'Signal Score'
        elif pt_sl_exit:
            return 'Profit Target/Stop Loss'
        
        return None
    
    except KeyError as e:
        logger.error(f"Missing data at {index}: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"Error in exit condition check at {index}: {str(e)}")
        return None

# =====================
# LOGGING SETUP
# =====================
class TradeFormatter(logging.Formatter):
    GREEN = '\033[92m'
    RED = '\033[91m'
    WHITE = '\033[0m'
    
    def format(self, record):
        message = super().format(record)
        message = self.colorize_actions(message)
        message = self.colorize_values(message)
        return message

    def colorize_actions(self, message):
        return re.sub(r'^(BUY|SELL)(\s+\|)', 
                      lambda m: f"{self.GREEN if m.group(1) == 'BUY' else self.RED}{m.group(1)}{self.WHITE}{m.group(2)}",
                      message, count=1)
        
    def colorize_values(self, message):
        def color_repl(match):
            value_str = match.group(1) or match.group(2)
            try:
                value = float(value_str)
                color = self.GREEN if value > 0 else self.RED
            except:
                color = self.WHITE
            return f"{color}{match.group(0)}{self.WHITE}"
        
        parts = message.split(' | ')
        for i, part in enumerate(parts):
            if part.startswith(('Price:', 'Size:')):
                continue
            parts[i] = re.sub(r'\$ *(-?\d+\.\d+)|(-?\d+\.\d+)%', color_repl, part)
        return ' | '.join(parts)

root_logger = logging.getLogger()
root_logger.setLevel(logging.DEBUG)
for handler in root_logger.handlers[:]:
    root_logger.removeHandler(handler)

console_handler = logging.StreamHandler()
console_handler.setFormatter(TradeFormatter('%(asctime)s | %(message)s'))
file_handler = logging.FileHandler('strategy_execution.log')
file_handler.setFormatter(logging.Formatter('%(asctime)s | %(message)s'))
root_logger.addHandler(console_handler)
root_logger.addHandler(file_handler)
logger = logging.getLogger(__name__)

# =====================
# LOG TRADE FUNCTION
# =====================
def log_trade(trade):
    try:
        timestamp = pd.to_datetime(trade['timestamp'])
        if timestamp.tz is None:
            timestamp = timestamp.tz_localize('UTC')
        trade_time = timestamp.tz_convert('America/New_York')
        
        log_parts = [
            f"{TradeFormatter.GREEN if trade['action'] == 'BUY' else TradeFormatter.RED}"
            f"{trade['action'].ljust(6)}\033[0m | {GlobalConfig.symbol.ljust(5)}",
            f"Time:  {trade_time.strftime('%Y-%m-%d %H:%M:%S%z')}",
            f"Price: \033[97m${trade['price']:7.2f}\033[0m",
            f"Size:  \033[97m${trade['position_value']:7.2f}\033[0m",
            f"Shares: \033[97m{trade['shares']:>6.2f}\033[0m"
        ]
        if trade['action'] == 'SELL':
            pnl_color = TradeFormatter.GREEN if trade['pnl'] > 0 else TradeFormatter.RED
            log_parts.extend([
                f"PnL:   {pnl_color}${trade['pnl']:7.2f}{TradeFormatter.WHITE}",
                f"Return: {pnl_color}{trade['pnl_pct']:6.2f}%{TradeFormatter.WHITE}",
                f"Exit:  {trade['exit_type']}"
            ])
        logger.info(" | ".join(log_parts))
    except Exception as e:
        logger.error(f"Failed to log trade: {str(e)}", exc_info=True)

# =====================
# DATA MANAGEMENT
# =====================
def calculate_mrc_with_gradient(df, length=100, gradient_levels=[0.5, 1.0, 1.5, 2.0, 2.5, 3.0], outer_levels=GlobalConfig.outer_levels):
    df['prev_close'] = df['close'].shift(1).ffill()
    df['tr1'] = df['high'] - df['low']
    df['tr2'] = abs(df['high'] - df['prev_close'])
    df['tr3'] = abs(df['low'] - df['prev_close'])
    df['tr'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)
    df.drop(['tr1', 'tr2', 'tr3', 'prev_close'], axis=1, inplace=True, errors='ignore')

    df['meanline'] = supersmoother(df['hlc3'], length).bfill().ffill()
    df['meanrange'] = df['tr'].rolling(20).mean().bfill().ffill()
    logger.debug(f"Meanline sample: {df['meanline'].head().tolist()}")
    logger.debug(f"Meanrange sample: {df['meanrange'].head().tolist()}")

    for level in gradient_levels:
        df[f'upband_{level}'] = df['meanline'] + (df['meanrange'] * level)
        df[f'loband_{level}'] = df['meanline'] - (df['meanrange'] * level)
        df[f'upband_{level}_shifted'] = df[f'upband_{level}'].shift(1).ffill()
        df[f'loband_{level}_shifted'] = df[f'loband_{level}'].shift(1).ffill()
        logger.debug(f"Upband_{level} sample: {df[f'upband_{level}'].head().tolist()}")

    outer_multiples = {'weak': 3.0, 'moderate': 3.5, 'strong': 4.0}
    for level_name in outer_levels:
        multiple = outer_multiples[level_name]
        df[f'upband_{level_name}'] = df['meanline'] + (df['meanrange'] * multiple)
        df[f'loband_{level_name}'] = df['meanline'] - (df['meanrange'] * multiple)

    df['meanrange_shifted'] = df['meanrange'].shift(1).ffill()
    return df

def supersmoother(src: pd.Series, length: int) -> pd.Series:
    if len(src) < 3:
        return src.ffill().bfill()
    a1 = np.exp(-np.sqrt(2) * np.pi / length)
    b1 = 2 * a1 * np.cos(np.sqrt(2) * np.pi / length)
    c3 = -a1**2
    c2 = b1
    c1 = 1 - c2 - c3
    
    ss = np.zeros_like(src)
    ss[0] = src.iloc[0]
    ss[1] = src.iloc[1]
    for i in range(2, len(src)):
        ss[i] = c1 * src.iloc[i] + c2 * ss[i-1] + c3 * ss[i-2]
    return pd.Series(ss, index=src.index).bfill().ffill()

def williams_r(high, low, close, lookback=14):
    highest_high = high.rolling(window=lookback, min_periods=1).max()
    lowest_low = low.rolling(window=lookback, min_periods=1).min()
    denominator = highest_high - lowest_low
    denominator = denominator.replace(0, np.nan)
    wr = -100 * ((highest_high - close) / denominator)
    return wr.fillna(-50).replace([np.inf, -np.inf], -50)

def stochastic_oscillator(df, k_period=14, d_period=3):
    low_min = df['low'].rolling(k_period).min()
    high_max = df['high'].rolling(k_period).max()
    df['%K'] = 100 * ((df['close'] - low_min) / (high_max - low_min))
    df['%K'] = df['%K'].fillna(50)
    df['%D'] = df['%K'].rolling(d_period).mean()
    return df

def get_historical_data(ib, exchange='SMART', currency='USD', backtest=False):
    contract = Stock(GlobalConfig.symbol, exchange, currency)
    ib.qualifyContracts(contract)
    if backtest:
        logger.info(f"Requesting historical data for {GlobalConfig.symbol}")
        bars = ib.reqHistoricalData(
            contract, endDateTime='', durationStr=GlobalConfig.durationStr, barSizeSetting=GlobalConfig.barSizeSetting,
            whatToShow='TRADES', useRTH=True, formatDate=2, keepUpToDate=False
        )
        
        if not bars:
            logger.error("No historical data received from IBKR")
            raise ValueError("No historical data received")
        
        df = util.df(bars)
        if df.empty:
            logger.error("Empty DataFrame received from IB")
            raise ValueError("Empty DataFrame received from IB")

        df['date'] = pd.to_datetime(df['date'], utc=True)
        df.set_index('date', inplace=True)
        df.index = df.index.tz_convert('America/New_York')

        required_cols = ['open', 'high', 'low', 'close', 'volume']
        for col in required_cols:
            if col not in df.columns:
                logger.error(f"Missing column {col}")
                raise ValueError(f"Missing column {col}")
            df[col] = pd.to_numeric(df[col], errors='coerce').replace([np.inf, -np.inf, np.nan], np.nan).ffill().bfill()
            if df[col].isna().all() or (df[col] <= 0).any():
                logger.error(f"Invalid data in {col}")
                raise ValueError(f"Invalid data in {col}")

        df['hlc3'] = (df['high'] + df['low'] + df['close']) / 3
        df = calculate_mrc_with_gradient(df)
        df = calculate_adx(df)
        df = stochastic_oscillator(df)

        df['vwap_numerator'] = df['volume'] * df['hlc3']
        df['vwap_denominator'] = df['volume'].cumsum()
        df['VWAP'] = df['vwap_numerator'].cumsum() / df['vwap_denominator']

        exp12 = df['close'].ewm(span=12, adjust=False).mean()
        exp26 = df['close'].ewm(span=26, adjust=False).mean()
        df['MACD'] = exp12 - exp26
        df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
        df['Histogram'] = df['MACD'] - df['Signal']

        df['RSI'] = calculate_rsi(df['close'])
        df['Williams_%R'] = williams_r(df['high'], df['low'], df['close'])
        df['ATR'] = df['tr'].rolling(14).mean().replace([np.inf, -np.inf, np.nan], 0).ffill().bfill()
        df['volume_ma'] = df['volume'].rolling(20).mean().replace([np.inf, -np.inf, np.nan], 0).ffill().bfill()
        df['SMA_20'] = df['close'].rolling(20).mean().replace([np.inf, -np.inf, np.nan], 0).ffill().bfill()

        shifted_cols = ['close', 'RSI', 'Williams_%R', 'VWAP', 'MACD', 'Signal', 'adx', '+di', '-di', '%K', '%D', 'volume_ma', 'SMA_20']
        for col in shifted_cols:
            df[f'{col}_shifted'] = df[col].shift(1).ffill().bfill()

        df = df.drop(['vwap_numerator', 'vwap_denominator'], axis=1, errors='ignore')
        
        logger.info(f"Processed historical data with {len(df)} rows")
        return df

# ==================
# HELPER FUNCTIONS
# ==================
def calculate_macd(close, fast=12, slow=26, signal=9):
    ema_fast = close.ewm(span=fast, adjust=False).mean()
    ema_slow = close.ewm(span=slow, adjust=False).mean()
    macd = ema_fast - ema_slow
    signal_line = macd.ewm(span=signal, adjust=False).mean()
    histogram = macd - signal_line
    return macd, signal_line, histogram

def calculate_williams_r(high, low, close, period=14):
    highest_high = high.rolling(window=period).max()
    lowest_low = low.rolling(window=period).min()
    return -100 * (highest_high - close) / (highest_high - lowest_low)

def calculate_adx(df, window=14):
    high = df['high']
    low = df['low']
    close = df['close']
    tr = np.maximum(high - low, np.maximum(np.abs(high - close.shift().bfill()), np.abs(low - close.shift().bfill())))
    up_move = high.diff()
    down_move = -low.diff()
    tr_smooth = tr.ewm(alpha=1/window, adjust=False).mean()
    plus_dm = up_move.where((up_move > down_move) & (up_move > 0), 0.0)
    minus_dm = down_move.where((down_move > up_move) & (down_move > 0), 0.0)
    plus_di = 100 * (plus_dm.ewm(alpha=1/window, adjust=False).mean() / tr_smooth)
    minus_di = 100 * (minus_dm.ewm(alpha=1/window, adjust=False).mean() / tr_smooth)
    di_diff = np.abs(plus_di - minus_di)
    di_sum = (plus_di + minus_di).replace(0, 1e-8)
    dx = 100 * (di_diff / di_sum)
    adx = dx.ewm(alpha=1/window, adjust=False).mean().clip(0, 100)
    df['adx'] = adx
    df['+di'] = plus_di
    df['-di'] = minus_di
    df['adx_shifted'] = adx.shift(1).fillna(0)
    return df

def calculate_rsi(close, period=14):
    delta = close.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

def calculate_plus_di(high, low, close, period=14):
    plus_dm = (high - high.shift()).where((high - high.shift()) > (low.shift() - low), 0)
    tr = pd.concat([high - low, (high - close.shift()).abs(), (low - close.shift()).abs()], axis=1).max(axis=1)
    atr = tr.rolling(window=period).mean()
    return 100 * plus_dm.rolling(window=period).mean() / atr

def calculate_minus_di(high, low, close, period=14):
    minus_dm = (low.shift() - low).where((low.shift() - low) > (high - high.shift()), 0)
    tr = pd.concat([high - low, (high - close.shift()).abs(), (low - close.shift()).abs()], axis=1).max(axis=1)
    atr = tr.rolling(window=period).mean()
    return 100 * minus_dm.rolling(window=period).mean() / atr

def calculate_stoch(high, low, close, k_period=14, d_period=3):
    lowest_low = low.rolling(window=k_period).min()
    highest_high = high.rolling(window=k_period).max()
    k = 100 * (close - lowest_low) / (highest_high - lowest_low)
    d = k.rolling(window=d_period).mean()
    return k, d

def calculate_vwap(high, low, close, volume):
    typical_price = (high + low + close) / 3
    vwap = (typical_price * volume).cumsum() / volume.cumsum()
    return vwap

# =====================
# VISUALIZATION ENGINE
# =====================
def plot_candlestick(df, backtest=False, time_frame=GlobalConfig.barSizeSetting):
    if df.empty:
        logger.error("Cannot plot empty DataFrame")
        raise ValueError("Cannot plot empty DataFrame")

    required_cols = ['open', 'high', 'low', 'close', 'volume', 'meanline'] + \
                    [f'upband_{level}' for level in GlobalConfig.gradient_levels] + \
                    [f'loband_{level}' for level in GlobalConfig.gradient_levels]
    indicator_cols = ['MACD', 'Signal', 'Histogram', 'RSI', 'Williams_%R', 'adx', '%K', '%D', 'volume']
    for col in required_cols:
        if col not in df.columns:
            logger.error(f"Missing required column {col}")
            raise ValueError(f"Missing required column {col}")
        df[col] = pd.to_numeric(df[col], errors='coerce').replace([np.inf, -np.inf, np.nan], np.nan).ffill().bfill()
        if df[col].isna().all():
            logger.error(f"Column {col} contains only NaN values")
            raise ValueError(f"Column {col} contains only NaN values")
        logger.debug(f"{col} sample: {df[col].head().tolist()}, NaN count: {df[col].isna().sum()}")

    if df.index.tz != pytz.timezone('America/New_York'):
        df.index = df.index.tz_convert('America/New_York')
    df = df.sort_index()

    logger.debug(f"Index range: {df.index.min()} to {df.index.max()}")
    for col in indicator_cols:
        if col in df.columns:
            logger.debug(f"{col} NaN count: {df[col].isna().sum()}")

    style = mpf.make_mpf_style(
        base_mpf_style='classic',
        marketcolors=mpf.make_marketcolors(up='#00FF00', down='#FF0000', edge='black', wick='black', volume='gray'),
        gridstyle=':', gridcolor='gray', facecolor='white'
    )

    addplots = []
    panels_used = set()

    if 'volume' in df.columns:
        addplots.append(mpf.make_addplot(df['volume'], panel=1, type='bar', color='gray', ylabel='Volume'))
        panels_used.add(1)

    if all(col in df.columns for col in ['MACD', 'Signal', 'Histogram']):
        addplots.extend([
            mpf.make_addplot(df['MACD'], panel=2, color='#1f77b4', width=1.5, ylabel='MACD'),
            mpf.make_addplot(df['Signal'], panel=2, color='#ff7f0e', width=1.5),
            mpf.make_addplot(df['Histogram'], panel=2, type='bar', color=np.where(df['Histogram'] >= 0, '#5cb85c', '#d62728'), alpha=0.6)
        ])
        panels_used.add(2)

    if 'RSI' in df.columns:
        addplots.append(mpf.make_addplot(df['RSI'], panel=3, color='#4B0082', width=1.5, ylim=(0, 100), ylabel='RSI'))
        panels_used.add(3)

    if 'Williams_%R' in df.columns:
        addplots.append(mpf.make_addplot(df['Williams_%R'], panel=4, color='#9467bd', width=1.5, ylim=(-100, 0), ylabel='Williams %R'))
        panels_used.add(4)

    if 'adx' in df.columns:
        addplots.append(mpf.make_addplot(df['adx'], panel=5, color='#2ca02c', width=1.5, ylim=(0, 100), ylabel='ADX'))
        panels_used.add(5)

    if all(col in df.columns for col in ['%K', '%D']):
        addplots.extend([
            mpf.make_addplot(df['%K'], panel=6, color='#8c564b', width=1.5, ylabel='Stochastic'),
            mpf.make_addplot(df['%D'], panel=6, color='#e377c2', width=1.5)
        ])
        panels_used.add(6)

    num_panels = 1 + len(panels_used)
    panel_ratios = [10] + [3] * len(panels_used)

    fig, axlist = mpf.plot(
        df[['open', 'high', 'low', 'close']],
        type='candle',
        style=style,
        addplot=addplots,
        volume=False,
        panel_ratios=tuple(panel_ratios),
        figsize=(20, 8 + 2 * len(panels_used)),
        title=f'{GlobalConfig.symbol} Candlestick Chart - {GlobalConfig.barSizeSetting} (Backtest: {backtest})',
        returnfig=True,
        datetime_format='%Y-%m-%d %H:%M'
    )

    plot_mrc_gradient(axlist[0], df)

    for i, ax in enumerate(axlist):
        ax.set_facecolor('white')
        ax.grid(True, color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
        ax.tick_params(colors='black', labelsize=8)
        ax.xaxis.set_major_formatter(DateFormatter('%H:%M'))
        ax.set_xlim(df.index[0], df.index[-1])

    y_min = min(df['low'].min(), df[[f'loband_{level}' for level in GlobalConfig.gradient_levels]].min().min()) * 0.95
    y_max = max(df['high'].max(), df[[f'upband_{level}' for level in GlobalConfig.gradient_levels]].max().max()) * 1.05
    axlist[0].set_ylim(y_min, y_max)

    fig.set_facecolor('white')
    plt.tight_layout(pad=2.0)
    logger.info("Chart plotted successfully")
    plt.show()

def plot_mrc_gradient(ax, df, time_frame=GlobalConfig.barSizeSetting):
    meanline = df['meanline'].replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
    if meanline.empty or meanline.isna().all():
        logger.error("Meanline data is empty or contains only NaN values")
        return

    ax.plot(df.index, meanline, color='purple', linestyle='-', linewidth=2.5, zorder=10, label='Meanline')
    norm = Normalize(vmin=min(GlobalConfig.gradient_levels), vmax=max(GlobalConfig.gradient_levels))

    for i in range(len(GlobalConfig.gradient_levels)):
        level = GlobalConfig.gradient_levels[i]
        upper_band = df[f'upband_{level}'].replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
        lower_band = df[f'loband_{level}'].replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
        color = mrc_cmap(norm(level))

        if i == 0:
            ax.fill_between(df.index, meanline, upper_band, color=color, alpha=0.5, zorder=2 + i, label=f'Level {level}')
            ax.fill_between(df.index, meanline, lower_band, color=color, alpha=0.5, zorder=2 + i)
        else:
            prev_level = GlobalConfig.gradient_levels[i - 1]
            prev_upper_band = df[f'upband_{prev_level}'].replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
            prev_lower_band = df[f'loband_{prev_level}'].replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
            ax.fill_between(df.index, prev_upper_band, upper_band, color=color, alpha=0.5, zorder=2 + i, label=f'Level {level}')
            ax.fill_between(df.index, prev_lower_band, lower_band, color=color, alpha=0.5, zorder=2 + i)

    ax.legend(loc='upper left', fontsize=8)
    y_min = min(df['low'].min(), lower_band.min()) * 0.95
    y_max = max(df['high'].max(), upper_band.max()) * 1.05
    ax.set_ylim(y_min, y_max)
    ax.set_xlim(df.index[0], df.index[-1])

# =====================
# MODE SELECTION
# =====================
def select_trading_mode():
    print("\nSelect Trading Strategy Mode:")
    print("1. Aggressive")
    print("2. Neutral (Default)")
    print("3. Conservative")
    choice = input("Enter choice (1-3): ").strip()
    modes = {'1': 'aggressive', '2': 'neutral', '3': 'conservative'}
    selected_mode = modes.get(choice, 'neutral')
    logger.info(f"Selected trading mode: {selected_mode}")
    return selected_mode

def run_backtest(df, mode):
    global engine
    engine = BacktestEngine(mode=mode)
    
    for index, row in df.iterrows():
        if not is_market_close(index):
            if check_entry_conditions(df, index):
                execute_entry(row['close'], index, engine.calculate_position_size(row), row)
            elif engine.current_position:
                exit_type = check_exit_conditions(df, index)
                if exit_type:
                    execute_exit(row['close'], index, exit_type, row)
            # Log non-trade data points with current balance
            else:
                non_trade_data = {
                    'timestamp': index,
                    'action': 'NONE',
                    'price': row['close'],
                    'shares': 0,
                    'position_value': 0,
                    'pnl': 0.0,
                    'pnl_pct': 0.0,
                    'balance_before': engine.balance,
                    'balance_after': engine.balance,
                    'exit_type': None
                }
                non_trade_data.update(row.to_dict())
                engine.backtest_data.append(non_trade_data)

    logger.info(f"Backtest completed with {len(engine.trade_history)} trades")
    return engine, df

# =====================
# MAIN EXECUTION
# =====================
def main():
    global engine
    selected_mode = select_trading_mode()
    engine = BacktestEngine(mode=selected_mode)
    ib = IB()
    
    try:
        ib.connect('127.0.0.1', 7497, clientId=1)
        logger.info("Connected to IBKR")
        
        daily_data = get_historical_data(ib, backtest=True)
        if daily_data is None or daily_data.empty:
            raise ValueError("Failed to retrieve historical data")
        
        required_cols = ['open', 'high', 'low', 'close', 'volume', 'meanline'] + \
                        [f'upband_{level}' for level in GlobalConfig.gradient_levels] + \
                        [f'loband_{level}' for level in GlobalConfig.gradient_levels] + \
                        ['MACD', 'Signal', 'Histogram', 'RSI', 'Williams_%R', 'adx', '%K', '%D', 'VWAP']
        missing = [col for col in required_cols if col not in daily_data.columns]
        if missing:
            logger.error(f"Missing required columns: {missing}")
            raise ValueError(f"Missing required columns: {missing}")
        
        engine, daily_data = run_backtest(daily_data, selected_mode)
        
        logger.debug(f"Data shape: {daily_data.shape}")
        logger.debug(f"Columns available: {daily_data.columns.tolist()}")
        
        plot_candlestick(daily_data, backtest=True)

        # Export backtest data to CSV
        backtest_df = pd.DataFrame(engine.backtest_data)
        backtest_df['timestamp'] = pd.to_datetime(backtest_df['timestamp']).dt.tz_convert('America/New_York')
        backtest_df.to_csv('backtest_raw_data.csv', index=False)
        logger.info("Backtest data exported to 'backtest_raw_data.csv'")
            
    except Exception as e:
        logger.error(f"Main execution error: {str(e)}", exc_info=True)
    finally:
        if ib.isConnected():
            ib.disconnect()
            logger.info("Disconnected from IBKR")

if __name__ == '__main__':
    main()
