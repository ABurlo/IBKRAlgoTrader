# =====================
# CORE IMPORTS
# =====================
from ib_insync import *
import pandas as pd
import numpy as np
import mplfinance as mpf
from datetime import datetime, timedelta, time
import asyncio
import nest_asyncio
import logging
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
from time import sleep
from matplotlib.colors import ListedColormap
from collections.abc import MutableMapping  # FIX: Added correct abstract base class import
import pytz
import re

# =====================
# LINKED LIST DICTIONARY IMPLEMENTATION
# =====================
class LLNode:
    __slots__ = ('key', 'value', 'next')
    def __init__(self, key, value, next=None):
        self.key = key
        self.value = value
        self.next = next

class LLDict(MutableMapping):  # FIX: Replaced DictAbstract with MutableMapping
    def __init__(self):
        self.head = None
        self._size = 0

    def __setitem__(self, key, value):
        current = self.head
        while current is not None:
            if current.key == key:
                current.value = value
                return
            current = current.next
        self.head = LLNode(key, value, self.head)
        self._size += 1

    def __getitem__(self, key):
        current = self.head
        while current is not None:
            if current.key == key:
                return current.value
            current = current.next
        raise KeyError(key)

    def __delitem__(self, key):
        prev = None
        current = self.head
        while current is not None:
            if current.key == key:
                if prev:
                    prev.next = current.next
                else:
                    self.head = current.next
                self._size -= 1
                return
            prev = current
            current = current.next
        raise KeyError(key)

    def __iter__(self):
        current = self.head
        while current is not None:
            yield current.key
            current = current.next

    def __len__(self):
        return self._size

# =====================
# GLOBAL CONFIGURATION
# =====================
symbol = 'AAPL' # Random Stock Ticker Generator - API call IBKR random pos in array of NYSE/NASDAQ tickers list?
initial_balance = 10000

# =====================
# MARKET CLOSURE WARNING
# =====================
def is_market_close(index):
    """Check if current time is near market close"""
    ny_tz = pytz.timezone('America/New_York')
    current_time = index.tz_convert(ny_tz).time()
    market_close_time = time(16, 0)  # 4 PM ET
    
    # Create dummy datetime for comparison
    dummy_date = datetime.today().date()
    market_close = datetime.combine(dummy_date, market_close_time)
    comparison_time = datetime.combine(dummy_date, current_time)
    
    time_delta = timedelta(minutes=10)
    return (market_close - time_delta).time() <= current_time <= market_close.time()

# =====================
# PNL CALENDAR (FIXED)
# =====================
def plot_pnl_calendar(engine, start_date, end_date, initial_balance, symbol):
    ny_tz = pytz.timezone('America/New_York')

    # Convert start and end dates to NY timezone
    start_date = pd.Timestamp(start_date).tz_convert(ny_tz).normalize()
    end_date = pd.Timestamp(end_date).tz_convert(ny_tz).normalize()

    current_date = start_date
    while current_date <= end_date:
        # Calculate the end of the current month
        next_month = current_date.replace(day=1) + pd.DateOffset(months=1)
        month_end = min(next_month - pd.Timedelta(days=1), end_date)

        # Generate all dates in the current month
        all_dates = pd.date_range(start=current_date, end=month_end, freq='D', tz=ny_tz)

        # Process daily PnL data
        daily_pnl = pd.DataFrame.from_dict(engine.daily_pnl, orient='index', columns=['pnl'])
        daily_pnl.index = pd.to_datetime(daily_pnl.index).tz_localize('UTC').tz_convert(ny_tz)
        daily_pnl = daily_pnl.reindex(all_dates, fill_value=0).reset_index()
        daily_pnl.rename(columns={'index': 'date'}, inplace=True)

        # Add title to the calendar dynamically
        title = f"{symbol} Trading Performance {current_date.strftime('%B %Y')}"

        # Visualization with details
        fig, ax = plt.subplots(figsize=(16, 28))
        ax.set_facecolor('#f0f0f0')

        # Calculate offset for first day and number of weeks
        first_day_of_month = current_date.replace(day=1)
        first_day_offset = first_day_of_month.weekday()
        days_in_month = (current_date + pd.offsets.MonthEnd(1)).day
        num_weeks = ((days_in_month + first_day_offset - 1) // 7) + 1

        # Plot each day
        for i, row in daily_pnl.iterrows():
            date = row['date']
            col = date.weekday()  # Day of the week (Monday=0, Sunday=6)
            day_of_month = date.day
            week_num = (day_of_month + first_day_offset - 1) // 7
            row_pos = -week_num

            # Check if the day is Saturday (5) or Sunday (6)
            if col in [5, 6]:
                color = '#000000'  # Solid black
                # Plot cell rectangle
                ax.add_patch(plt.Rectangle(
                    (col, row_pos), 1, 1,
                    facecolor=color,
                    edgecolor='gray',
                    lw=0.5
                ))
            else:
                # Filter trades for the specific date
                trades = [t for t in engine.trade_history if pd.Timestamp(t['timestamp']).date() == date.date()]

                # Calculate metrics for the day
                metrics = calculate_day_metrics(trades)

                # If no trades occurred, set the color to grey
                if metrics['num_trades'] == 0:
                    color = '#d3d3d3'  # Default grey for no trades
                else:
                    # Determine cell color intensity based on PnL
                    max_abs_pnl = abs(daily_pnl['pnl']).max()
                    color_intensity = min(1, abs(row.pnl) / max_abs_pnl) if max_abs_pnl > 0 else 0
                    color = f"#{int((0.8-color_intensity)*255):02x}ff{int((0.8-color_intensity)*255):02x}"

                # Plot cell rectangle
                ax.add_patch(plt.Rectangle(
                    (col, row_pos), 1, 1,
                    facecolor=color,
                    edgecolor='gray',
                    lw=0.5
                ))

                # Add text for metrics
                ax.text(col + 0.05, row_pos + 0.85, str(day_of_month), ha='left', va='top', fontsize=8)
                ax.text(col + 0.5, row_pos + 0.5,
                        f"${row.pnl:.2f}\nW%: {metrics['win_rate']:.2f}%\nTrades: {metrics['num_trades']}",
                        ha='center', va='center', fontsize=6)

        # Configure axis limits and labels
        ax.set_xlim(-0.5, 6.5)
        ax.set_ylim(-num_weeks - 0.5, 0.5)  # Dynamically adjust y-axis based on num_weeks

        ax.set_xticks(range(7))
        ax.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])
        ax.set_yticks([])

        plt.suptitle(title, fontsize=16)
        plt.tight_layout()
        plt.show()

        # Move to next month
        current_date = next_month

def calculate_day_metrics(trades):
    """Calculate trading metrics with proper error handling"""
    num_trades = len(trades)
    wins = 0
    losses = 0
    pnl = 0.0
    
    for t in trades:
        trade_pnl = t.get('pnl', 0.0)
        pnl += float(trade_pnl)
        
        if trade_pnl > 0:
            wins += 1
        elif trade_pnl < 0:
            losses += 1

    # FIXED CONTINUATION
    win_rate = (wins / num_trades * 100) if num_trades > 0 else 0.0
    win_loss_ratio = (wins / losses) if losses > 0 else float('inf')
    
    return {
        'win_rate': round(win_rate, 2),
        'win_loss_ratio': win_loss_ratio if win_loss_ratio < float('inf') else np.inf,
        'num_trades': num_trades,
        'pnl': round(pnl, 2)
    }

    
# =====================
# BACKTESTING ENGINE
# =====================
class BacktestEngine:
    def __init__(self):
        self.current_row = None  # Track current market data
        self.balance = initial_balance
        self.positions = LLDict()
        self.trade_history = []
        self.current_position = None
        self.fee_per_share = 0.0035
        self.slippage = 0.0002
        self.trade_markers = []
        self.daily_pnl = {}
        self.entry_conditions = {
            'rsi_threshold': False,
            'position_status': False
        }
        self.williams_params = {
            'lookback': 30,
            'oversold': -80,
            'overbought': -20,
            'confirmation_bars': 3
        }
        self.indicator_weights = {
            'rsi': 0.25,
            'williams': 0.25,
            'macd': 0.2,
            'vwap': 0.15,
            'adx': 0.1,
            'volume': 0.05  # New component
        }
        self.volatility_filter = {
            'min_mrc': 0.02,
            'max_mrc': 0.05    
        }
        self.adx_params = {
            'mean_reversion_threshold': 25,
            'low_volatility_threshold': 15,  # New filter
            'trend_strength_exit': 40,
            'rapid_trend_threshold': 15
        }
    
    # =====================
    # UPDATED POSITION SIZING
    # =====================
    def calculate_position_size(self, row):
        """Complete position sizing implementation"""
        if 'meanrange' not in row:
            raise KeyError("Missing MRC 'meanrange'")
        risk_per_trade = self.balance * 0.02
        volatility_measure = row['meanrange']
        position_size = risk_per_trade / volatility_measure
        return max(1, position_size)
    
    def composite_signal_score(self, row):
        """Enhanced composite score with dynamic volatility scaling and proper normalization"""
        # Volatility scaling using ATR (1-3x multiplier)
        volatility_scaler = 1 + min(2, (row['ATR'] / row['close']) * 2)
        
        # Component scores with bounded ranges and improved normalization
        scores = {
            'rsi': max(-1, min(1, (40 - row['RSI']) / 20)),  # -1 (overbought) to 1 (oversold)
            'williams': max(-1, min(1, (-80 - row['Williams_%R']) / 40)),  # -1 to 1 range
            'macd': self._normalize_macd(row['MACD'], row['Signal']),
            'vwap': (row['VWAP'] - row['close']) / row['VWAP'] * 2,  # -2 to 2 range
            'adx': self._dynamic_adx_weight(row['adx'], row['+di'], row['-di']),
            'volume': (row['volume'] - row['volume_ma']) / row['volume_ma']  # Volume momentum
        }
        
        # Apply weights and volatility scaling
        weighted_score = sum(
            self.indicator_weights[k] * scores[k] 
            for k in self.indicator_weights
        ) * volatility_scaler
    
        return max(-1, min(1, weighted_score))  # Clamped output for stability

    def _normalize_macd(self, macd, signal):
        """Safe MACD normalization with signal consideration"""
        denominator = abs(macd) + abs(signal)
        if denominator < 1e-8:
            return 0
        return (macd - signal) / denominator

    def _dynamic_adx_weight(self, adx, plus_di, minus_di):
        """ADX weighting that considers trend direction and strength"""
        di_diff = abs(plus_di - minus_di)
        trend_strength = max(0, (25 - min(adx, 25)) / 25)  # 0-1 based on ADX <25
        direction_confidence = 1 - (di_diff / 100)  # 1 when DIs converge
        return trend_strength * direction_confidence

    def apply_slippage(self, price, is_buy):
        """
        Applies slippage to the execution price
        """
        slippage_factor = 1 + (self.slippage if is_buy else -self.slippage)
        return price * slippage_factor
    
    def calculate_fees(self, shares):
        """
        Calculates trading fees based on number of shares
        """
        return abs(shares * self.fee_per_share)

    # =====================
    # RUNTIME VALIDATION (ADD TO BacktestEngine)
    # =====================
    def execute_trade(self, symbol, price, shares, action, timestamp):
        # Add validation for MRC columns
        required_mrc_columns = ['meanline', 'meanrange', 'loband1']
        missing = [col for col in required_mrc_columns if col not in self.current_row]
        if missing:
            raise KeyError(f"Missing MRC columns: {missing} - run calculate_mrc() first")
        
        if np.isnan(self.current_row['VWAP']):
            logger.error("Skipping trade with invalid VWAP")
            return None
        
        # Full trade execution logic
        executed_price = (0.7 * self.current_row['VWAP'] + 
                        0.3 * self.current_row['close'])
        
        if np.isnan(self.current_row['RSI']):
            logger.error("Skipping trade with invalid RSI")
            return None
        
        '''logger.info(f"Executing {action} for {shares} shares of {symbol} at ${price:.2f} on {timestamp}")'''
        # Get current market data row
        current_row = self.current_row  
        
        # VWAP-weighted execution price
        vwap_weight = 0.7 if action == 'BUY' else 0.3
        executed_price = (vwap_weight * current_row['VWAP'] + 
                        (1-vwap_weight) * current_row['close'])
        
        # Volatility damping factor
        volatility_impact = 1 - (current_row['meanrange']/current_row['meanline'])
        shares *= volatility_impact
        fees = self.calculate_fees(shares)
        position_value = abs(shares * executed_price)
        trade = {
            'timestamp': timestamp,
            'action': action,
            'price': executed_price,
            'shares': round(shares, 2),  # Ensures rounded values for shares
            'position_value': round(position_value, 2),
            'fees': round(fees, 2),
            'new_balance': round(self.balance, 2),
            'pnl': 0.0,  # Default PnL is 0.0, updated on 'SELL'
        }
        
        if pd.isnull(current_row['VWAP']):
            raise ValueError("Missing VWAP value for trade execution")
        if shares < 0.01:
            raise ValueError(f"Invalid share quantity: {shares}")

        trade_date = pd.Timestamp(timestamp).date()
        if trade_date not in self.daily_pnl:
            self.daily_pnl[trade_date] = 0.0
            
        if action == 'SELL' and self.current_position:
            pnl = (executed_price - self.current_position['entry_price']) * self.current_position['shares']
            self.daily_pnl[trade_date] += pnl
            # PnL represents gross profit/loss before fees
            # Fees are deducted from account balance separately
            trade['pnl'] = round(pnl, 2)  # Gross PnL
            trade['pnl_pct'] = round((pnl / self.current_position['entry_price']) * 100, 2)

            self.balance += round(pnl - fees, 2)
            self.current_position = None  # Reset current position on sell
            
        elif action == 'BUY':
            self.balance -= position_value + fees
            self.current_position = {
                'entry_price': executed_price,
                'shares': shares,
                'timestamp': timestamp
            }
            self.trade_markers.append({
                'date': timestamp,
                'price': executed_price,
                'marker': '↑' if action == 'BUY' else '↓',
                'color': 'green' if action == 'BUY' else 'red'
            })

        # Append the trade to history regardless of the action
        self.trade_history.append(trade)
        '''logger.info(f"{action} executed: {trade}")'''
        return trade

# Initialize engine globally
engine = BacktestEngine()

# =====================
# STRATEGY CONDITIONS
# =====================
# =====================
# CORRECTED ENTRY/EXIT CONDITIONS
# =====================
def check_entry_conditions(df, index):
    """Fixed entry conditions with proper operators"""
    row = df.loc[index]
    
    entry_confluence = (
        (row['close'] < row['loband1']) and # Correct column name from MRC calculation
        (row['RSI'] < 30) and
        (row['Williams_%R'] < -80) and
        (row['VWAP'] > row['close']) and
        (row['MACD'] < row['Signal']) and
        (row['adx'] < engine.adx_params['mean_reversion_threshold']) and
        (row['+di'] < row['-di']) and
        (row['%K'] < 25) and
        (row['%D'] < 30) and
        (row['%K'] > row['%D'])
    )

    volatility_confirmation = (
        (row['meanrange'] > engine.volatility_filter['min_mrc'] * 1.5) and
        np.abs(row['+di'] - row['-di']) > 5
    )
    
    # Volatility Filter using engine reference
    volatility_ok = (
        engine.volatility_filter['min_mrc'] < row['meanrange'] < 
        engine.volatility_filter['max_mrc']
    )

    
    # ADX Range Filtering (using shifted values)
    adx_ok = (
        (row['adx_shifted'] > engine.adx_params['low_volatility_threshold']) and
        (row['adx_shifted'] < engine.adx_params['mean_reversion_threshold'])
    )
    
    # FIXED (using MRC metrics)
    volatility_confirmation = (
        (row['meanrange'] > engine.volatility_filter['min_mrc'] * 1.5) and
        np.abs(row['+di'] - row['-di']) > 5  # FIXED
    )
    
    # Position & Balance Checks
    position_ok = (
        engine.composite_signal_score(row) > 0.7 and
        engine.balance > 1000 and
        not engine.current_position and
        volatility_ok
    )
    
    # Time Filter
    time_ok = not is_market_close(index)
    
    return (
        entry_confluence and 
        position_ok and 
        time_ok and 
        adx_ok and  # New ADX range check
        volatility_confirmation  # Additional filter
    )

def check_exit_conditions(df, index):
    """Enhanced exit conditions with ADX trend monitoring"""
    if not engine.current_position:
        return False

    row = df.loc[index]
    entry_price = engine.current_position['entry_price']
    
    # Profit Target Conditions
    profit_conditions = [
        row['close'] > row['SMA_20'],                    # Price above SMA
        row['RSI'] > 40,                                 # RSI normalization
        row['Williams_%R'] > -60,                        # Williams %R recovery
        row['close'] > row['VWAP'],                      # Price above VWAP
        row['adx'] > 40,                                 # Strong trend emerging
        row['+di'] > row['-di']                          # Bullish DI crossover
        (row['%K'] > 75), 
        (row['%D'] > 70), 
        (row['%K'] < row['%D'])  # Bearish crossover
    ]
    
    # FIXED (using MRC metrics)
    stop_loss_conditions = (
        row['close'] < entry_price * 0.98 or
        row['meanrange'] > engine.volatility_filter['max_mrc'] * 1.5 or
        np.abs(row['adx_shifted'] - row['adx_shifted'].shift(3)) > 15  # FIXED
    )

    return any(profit_conditions) or stop_loss_conditions

# =====================
# EXIT CONDITION IMPLEMENTATION 
# =====================
def check_exit_conditions(df, index):
    """Enhanced exit conditions with ADX trend monitoring"""
    if not engine.current_position:
        return False

    row = df.loc[index]
    entry_price = engine.current_position['entry_price']
    
    # Profit Target Conditions
    profit_conditions = [
        row['close'] > row['SMA_20'],                    # Price above SMA
        row['RSI'] > 40,                                 # RSI normalization
        row['Williams_%R'] > -60,                        # Williams %R recovery
        row['close'] > row['VWAP'],                      # Price above VWAP
        row['adx'] > 40,                                 # Strong trend emerging
        row['+di'] > row['-di']                          # Bullish DI crossover
    ]
    
    # Dynamic Stop Loss System
    stop_loss_conditions = (
        row['close'] < entry_price * 0.98 or             # 2% hard stop
        row['meanrange'] > engine.volatility_filter['max_mrc'] * 1.5 or
        (row['adx'] - row['adx'].shift(3)) > 15          # Rapid trend strengthening
    )
    
    # Time-Based Exit (30-minute timeout)
    position_age = (index - engine.current_position['timestamp']).total_seconds() / 60
    time_exit = position_age > 30
    
    return any(profit_conditions) or stop_loss_conditions or time_exit

# =====================
# ENHANCED LOGGING WITH PROPER COLORIZATION
# =====================
class TradeFormatter(logging.Formatter):
    # ANSI color codes
    GREEN = '\033[92m'
    RED = '\033[91m'
    WHITE = '\033[0m'
    
    def format(self, record):
        message = super().format(record)
        message = self.colorize_actions(message)
        message = self.colorize_values(message)
        return message

    def colorize_actions(self, message):
        """Color-code BUY/SELL tags with proper regex"""
        return re.sub(
            r'^(BUY|SELL)(\s+\|)',
            lambda m: (f"{self.GREEN if m.group(1) == 'BUY' else self.RED}"
                      f"{m.group(1)}{self.WHITE}{m.group(2)}"),
            message,
            count=1
        )
        
    def colorize_values(self, message):
        """Apply color based on numeric values with proper handling"""
        def color_repl(match):
            value_str = match.group(1) or match.group(2)
            try:
                value = float(value_str)
                color = self.GREEN if value > 0 else self.RED
            except:
                color = self.WHITE
            return f"{color}{match.group(0)}{self.WHITE}"

        # Split message into components and skip Price/Size fields
        parts = message.split(' | ')
        for i, part in enumerate(parts):
            if part.startswith(('Price:', 'Size:')):
                continue  # Skip already-colored fields
            parts[i] = re.sub(
                r'\$ *(-?\d+\.\d+)|(-?\d+\.\d+)%',
                color_repl,
                part
            )
        return ' | '.join(parts)

# Configure root logger
root_logger = logging.getLogger()
root_logger.setLevel(logging.DEBUG)  # Changed to DEBUG for verbose logging

# Clear existing handlers
for handler in root_logger.handlers[:]:
    root_logger.removeHandler(handler)

# Create and configure handlers
console_handler = logging.StreamHandler()
console_handler.setFormatter(TradeFormatter('%(asctime)s | %(message)s'))
file_handler = logging.FileHandler('strategy_execution.log')
file_handler.setFormatter(logging.Formatter('%(asctime)s | %(message)s'))

root_logger.addHandler(console_handler)
root_logger.addHandler(file_handler)
logger = logging.getLogger(__name__)

# =====================
# MODIFIED LOG_TRADE FUNCTION
# =====================
def log_trade(trade, symbol):
    """Robust logging with improved color handling"""
    try:
        # Validate required fields and parse timestamp
        trade_time = pd.to_datetime(trade['timestamp'], utc=True).tz_convert('America/New_York')
        
        # Build log message with direct color formatting
        log_parts = [
                    f"{TradeFormatter.GREEN if trade['action'] == 'BUY' else TradeFormatter.RED}"
                    f"{trade['action'].ljust(6)}\033[0m | {symbol.ljust(5)}",
                    f"Time:  {trade_time.strftime('%Y-%m-%d %H:%M:%S%z')}",
                    f"Price: \033[97m${trade['price']:7.2f}\033[0m",  # Force white
                    f"Size:  \033[97m${trade['position_value']:7.2f}\033[0m"  # Force white
                    f"Shares: \033[97m{trade['shares']:>6.2f}\033[0m"  # White text
                ]
        
        if trade['action'] == 'SELL':
            # Direct ANSI color codes for PnL
            pnl_color = TradeFormatter.GREEN if trade['pnl'] > 0 else TradeFormatter.RED
            log_parts.extend([
                f"PnL:   {pnl_color}${trade['pnl']:7.2f}{TradeFormatter.WHITE}",
                f"Return: {pnl_color}{trade['pnl_pct']:6.2f}%{TradeFormatter.WHITE}"
            ])
            
        logger.info(" | ".join(log_parts))

    except Exception as e:
        logger.error(f"Failed to log trade: {str(e)}", exc_info=True)

# =====================
# DATA MANAGEMENT (UPDATED FOR MRC)
# =====================
nest_asyncio.apply()


def calculate_mrc(df: pd.DataFrame, length=75) -> pd.DataFrame:  # Increased length
    """Calculate Mean Reversion Channel."""
    df = df.copy()

    # Calculate HLC3 if missing
    if 'hlc3' not in df.columns:
        df['hlc3'] = (df['high'] + df['low'] + df['close']) / 3

    # Calculate meanline using supersmoother
    df['meanline'] = supersmoother(df['hlc3'], length)

    # True Range calculation
    tr = np.maximum(
        df['high'] - df['low'],
        np.maximum(
            np.abs(df['high'] - df['close'].shift().bfill()),
            np.abs(df['low'] - df['close'].shift().bfill())
        )
    )
    df['meanrange'] = supersmoother(tr, length)

    # Apply scaling factor to meanrange
    scaling_factor = 0.3  # Adjust as needed
    df['meanrange'] *= scaling_factor

    # Create MRC bands with adjusted multipliers
    inner_mult = 1.0
    outer_mult = 2.0
    df['upband1'] = df['meanline'] + (df['meanrange'] * inner_mult)
    df['loband1'] = df['meanline'] - (df['meanrange'] * inner_mult)
    df['upband2'] = df['meanline'] + (df['meanrange'] * outer_mult)
    df['loband2'] = df['meanline'] - (df['meanrange'] * outer_mult)

    return df

def get_historical_data(ib, symbol, exchange='SMART', currency='USD', backtest=False):
    contract = Stock(symbol, exchange, currency)
    if backtest:
        bars = ib.reqHistoricalData(
            contract,
            endDateTime='',
            durationStr='7 D',
            barSizeSetting='1 hour',
            whatToShow='TRADES',
            useRTH=True,
            formatDate=1,
            keepUpToDate=False
        )
        
        if not bars:
            raise ValueError("No historical data received")
        
        df = util.df(bars)
        if df.empty:
            raise ValueError("Empty DataFrame received from IB")

        # Clean column names first
        df = df.rename(columns={
            'open': 'open',
            'high': 'high',
            'low': 'low', 
            'close': 'close',
            'volume': 'volume'
        }).drop(columns=['average', 'barCount'], errors='ignore')

        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)

        # Add MRC before other indicators
        df = calculate_mrc(df)
        
        # Add post-calculation validation
        required_mrc_cols = ['meanline', 'upband1', 'loband1', 'upband2', 'loband2']
        if not all(col in df.columns for col in required_mrc_cols):
            missing = [col for col in required_mrc_cols if col not in df.columns]
            raise ValueError(f"Post-MRC missing columns: {missing}")
        
        # Technical indicators
        adx_components = calculate_adx(df)
        df = df.join(adx_components, lsuffix='', rsuffix='_drop').drop(columns=['adx_drop', '+di_drop', '-di_drop', 'adx_shifted_drop'], errors='ignore')
        df[['adx', '+di', '-di']] = df[['adx', '+di', '-di']].fillna(0)

        # Stochastic oscillator
        df = stochastic_oscillator(df)
        
        # VWAP calculation
        df['vwap_numerator'] = df['volume'] * df['hlc3']  # Use existing hlc3
        df['vwap_denominator'] = df['volume']
        df['trading_date'] = df.index.date
        df['VWAP'] = (df.groupby('trading_date')['vwap_numerator'].cumsum() /
                     df.groupby('trading_date')['vwap_denominator'].cumsum())
        
        # MACD with noise filtering
        exp12 = df['close'].ewm(span=12, adjust=False).mean()
        exp26 = df['close'].ewm(span=26, adjust=False).mean()
        df['MACD'] = np.where(np.abs(exp12 - exp26) < 1e-8, 0, exp12 - exp26)
        df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
        df['Histogram'] = df['MACD'] - df['Signal']
        
        # RSI calculation
        delta = df['close'].diff()
        gain = delta.where(delta > 0, 0.0)
        loss = -delta.where(delta < 0, 0.0)
        avg_gain = gain.ewm(alpha=1/14, adjust=False).mean()
        avg_loss = loss.ewm(alpha=1/14, adjust=False).mean()        
        df['RSI'] = 100 - (100 / (1 + (avg_gain / avg_loss)))
        
        # Williams %R
        df['Williams_%R'] = williams_r(df['high'], df['low'], df['close'])
        df['Williams_%R_diff'] = df['Williams_%R'].diff(3).fillna(0)
        
        df['ATR'] = df['high'] - df['low']  # Basic implementation - replace with proper ATR
        df['volume_ma'] = df['volume'].rolling(20).mean()
        
        
        # Feature engineering updates
        df = df.drop(['vwap_numerator', 'vwap_denominator', 'trading_date'], axis=1)
        df['RSI_shifted'] = df['RSI'].shift(1)
        df['MACD_shifted'] = df['MACD'].shift(1)
        df['Signal_shifted'] = df['Signal'].shift(1)
        df['Volume_MA_shifted'] = df['volume'].rolling(20).mean().shift(1)
        df['adx_shifted'] = df['adx'].shift(1)
        
        scaling_factor = 0.5  # Adjust based on your data
        df['meanrange'] *= scaling_factor
        
        # Validate core indicators for composite score
        composite_required = ['ATR', 'volume_ma', 'adx', 'RSI', 'Williams_%R', 'MACD', 'VWAP']
        missing = [col for col in composite_required if col not in df.columns]
        if missing:
            raise ValueError(f"Missing composite score columns: {missing}")

        # Cleanup MRC bands only if actually used elsewhere

        mrc_bands = ['meanline', 'upband1', 'loband1', 'upband2', 'loband2']
        df.dropna(subset=mrc_bands, inplace=True)
        
        if df.empty:
            raise ValueError("Empty DataFrame after MRC processing")
            
        assert not df[['adx', '+di', '-di'] + required_mrc_cols].isnull().values.any(), \
            "NaN values present in critical columns"
            
        required_mrc_cols = ['meanline', 'upband1', 'loband1', 'upband2', 'loband2']
        if not all(col in df.columns for col in required_mrc_cols):
            raise ValueError("MRC calculation failed - missing columns")

        return df

# =====================
# WILLIAMS %R IMPLEMENTATION
# =====================
def williams_r(high, low, close, lookback=14):
    """Calculate Williams %R with NaN handling"""
    highest_high = high.rolling(window=lookback, min_periods=1).max()
    lowest_low = low.rolling(window=lookback, min_periods=1).min()
    
    # Handle division by zero and NaN cases
    denominator = (highest_high - lowest_low).replace(0, np.nan)
    wr = -100 * ((highest_high - close) / denominator)
    return wr.fillna(-50)  # Neutral value when no range

def stochastic_oscillator(df, k_period=14, d_period=3):
    """Calculate Stochastic Oscillator with NaN handling"""
    low_min = df['low'].rolling(k_period).min()
    high_max = df['high'].rolling(k_period).max()
    
    df['%K'] = 100 * ((df['close'] - low_min) / (high_max - low_min))
    df['%K'] = df['%K'].fillna(50)  # Neutral value when no range
    df['%D'] = df['%K'].rolling(d_period).mean()
    return df

# =====================
# FIXED ADX CALCULATION (PANDAS SERIES)
# =====================
def calculate_adx(df, window=14):
    """Fixed ADX calculation with proper initialization"""
    high = df['high']
    low = df['low']
    close = df['close']
    
    # Initialize DI series
    plus_di = pd.Series(0.0, index=df.index)
    minus_di = pd.Series(0.0, index=df.index)
    
    # True Range calculation
    tr = np.maximum(
        high - low,
        np.maximum(
            np.abs(high - close.shift().bfill()),
            np.abs(low - close.shift().bfill())
        )
    )
    
    # Directional Movement
    up_move = high.diff()
    down_move = -low.diff()
    
    # Smoothed values
    tr_smooth = tr.ewm(alpha=1/window, adjust=False).mean()
    plus_dm = up_move.where((up_move > down_move) & (up_move > 0), 0.0)
    minus_dm = down_move.where((down_move > up_move) & (down_move > 0), 0.0)
    
    # Calculate DI values
    plus_di = 100 * (plus_dm.ewm(alpha=1/window, adjust=False).mean() / tr_smooth)
    minus_di = 100 * (minus_dm.ewm(alpha=1/window, adjust=False).mean() / tr_smooth)
    
    # DX and ADX calculation
    di_diff = np.abs(plus_di - minus_di)
    di_sum = (plus_di + minus_di).replace(0, 1e-8)
    dx = 100 * (di_diff / di_sum)
    adx = dx.ewm(alpha=1/window, adjust=False).mean().clip(0, 100)
    
    # Create shifted version
    df['adx'] = adx
    df['+di'] = plus_di
    df['-di'] = minus_di
    df['adx_shifted'] = df['adx'].shift(1).fillna(0)
    
    return df[['adx', '+di', '-di', 'adx_shifted']]

# =====================
# CORRECTED SUPER SMOOTHER
# =====================
def supersmoother(src: pd.Series, length: int) -> pd.Series:
    """Improved Supersmoother implementation."""
    a1 = np.exp(-np.sqrt(2) * np.pi / length)
    b1 = 2 * a1 * np.cos(np.sqrt(2) * np.pi / length)
    c3 = -a1**2
    c2 = b1
    c1 = 1 - c2 - c3

    ss = np.zeros_like(src)
    ss[0] = src.iloc[0]
    ss[1] = src.iloc[1]
    for i in range(2, len(src)):
        ss[i] = c1 * src.iloc[i] + c2 * ss[i - 1] + c3 * ss[i - 2]
    return pd.Series(ss, index=src.index)


def sak_smoothing(series: pd.Series, filter_type: str, length: int) -> pd.Series:
    """Replaces existing technical indicators with unified filter"""
    cycle = 2 * np.pi / length
    alpha, beta, gamma = 0.0, 0.0, 0.0
    
    if filter_type == "Ehlers EMA":
        alpha = (np.cos(cycle) + np.sin(cycle) - 1) / np.cos(cycle)
        return series.ewm(alpha=alpha, adjust=False).mean()
    
    # Add other filter types as needed
    return series  # Fallback to original series

# =====================
# VISUALIZATION ENGINE (FIXED PANEL ORDER)
# =====================
def plot_candlestick(df, backtest=False):
    """Generates panels in correct order: Price, MACD, Volume, RSI, Williams %R, ADX"""
    # ===== REORDERED ADDPLOTS =====
    addplots = []

    # 1. Main Price Panel (0) - Add Lo-Hi Bands
    addplots = [
        mpf.make_addplot(df["upband1"], panel=0, color="darkorange", width=0.8),
        mpf.make_addplot(df["loband1"], panel=0, color="darkorange", width=0.8),
        mpf.make_addplot(df["upband2"], panel=0, color="red", width=0.8),
        mpf.make_addplot(df["loband2"], panel=0, color="red", width=0.8),
        mpf.make_addplot(df["meanline"], panel=0, color="blue", width=1.5),
    ]

    style = mpf.make_mpf_style(
        marketcolors=mpf.make_marketcolors(up="#006400", down="#8B0000"),
        gridstyle=":",
        gridcolor="gainsboro",
        facecolor="white",
    )
    
    # 2. MACD Panel (1)
    macd_hist_colors = np.where(df['Histogram'] >= 0, '#5cb85c', '#D83B2D')
    addplots.extend([
        mpf.make_addplot(df['MACD'], panel=1, color='#1f77b4', width=1.2, ylabel='MACD'),
        mpf.make_addplot(df['Signal'], panel=1, color='#ff7f0e', width=1.2),
        mpf.make_addplot(df['Histogram'], type='bar', panel=1, color=macd_hist_colors, alpha=0.6, width=0.7)
    ])

    # 3. Volume Panel (2)
    volume_colors = np.where(df['close'] > df['open'], '#5cb85c', '#d9534f')
    addplots.append(mpf.make_addplot(df['volume'], type='bar', panel=2, color=volume_colors, alpha=0.6, ylabel='Volume'))

    # 4. RSI Panel (3)
    addplots.extend([
        mpf.make_addplot(df['RSI'], panel=3, color='#4B0082', width=1.2, ylim=(0, 100), ylabel='RSI'),
        *[mpf.make_addplot(pd.Series(level, df.index), panel=3, color='gray', linestyle='--', width=1.0) for level in [30, 50, 70]]
    ])

    # 5. Williams %R Panel (4)
    addplots.extend([
        mpf.make_addplot(df['Williams_%R'], panel=4, color='blue', width=1.2, ylabel='Williams %R'),
        mpf.make_addplot(pd.Series(-20, df.index), panel=4, color='red', linestyle='--', width=1.0),
        mpf.make_addplot(pd.Series(-80, df.index), panel=4, color='green', linestyle='--', width=1.0)
    ])

    # 6. ADX Panel (5)
    addplots.extend([
        mpf.make_addplot(df['adx'], panel=5, color='blue', width=1.5, ylabel='ADX/DIs'),
        mpf.make_addplot(df['+di'], panel=5, color='green', width=1.5, alpha=0.75),
        mpf.make_addplot(df['-di'], panel=5, color='red', width=1.5, alpha=0.75)
    ])

    # 7. Stochastic (6)
    addplots.append(mpf.make_addplot(df['%K'], panel=6, color='blue', width=1.2, ylabel='Stochastic'))
    addplots.append(mpf.make_addplot(df['%D'], panel=6, color='orange', width=1.2))
    addplots.extend([
        mpf.make_addplot(pd.Series(80, index=df.index), panel=6, color='red', linestyle='--', width=1.0),
        mpf.make_addplot(pd.Series(20, index=df.index), panel=6, color='green', linestyle='--', width=1.0)
    ])
    
    # ===== REVISED LEGEND HANDLING =====
    legends = {
        0: [("VWAP", "purple"), ("20 SMA", "blue"), ("MRC Bands", "orange")],
        1: [("MACD", "#1f77b4"), ("Signal", "#ff7f0e"), ("Histogram", "#5cb85c")],
        2: [("Volume (Up)", "#5cb85c"), ("Volume (Down)", "#d9534f")],
        3: [("RSI", "#4B0082"), ("30/70 Bands", "gray")],
        4: [("Williams %R", "blue"), ("-20 Overbought", "red"), ("-80 Oversold", "green")],
        5: [("ADX (Trend Strength)", "blue"),("+DI (Bullish Pressure)", "green"), ("-DI (Bearish Pressure)", "red") , ("25 (Mean Reversion Zone)", "gray")]
    }
    
    # Add ADX threshold line
    addplots.append(
        mpf.make_addplot(pd.Series(25, index=df.index), 
                        panel=5, color='gray', 
                        linestyle='--', width=1.0)
    )


    style = mpf.make_mpf_style(
        marketcolors=mpf.make_marketcolors(up='#006400', down='#8B0000', edge='inherit', wick='inherit',
                                           volume={'up': '#006400', 'down': '#8B0000'}),
        gridstyle=':',
        gridcolor='gainsboro',
        facecolor='white'
    )

    fig, axlist = mpf.plot(
        df,
        type='candle',
        style=style,
        addplot=addplots,
        volume=False,
        panel_ratios=(12, 6, 4, 4, 4, 4, 4),
        figsize=(14, 24),
        returnfig=True
    )

    # === Apply Corrected Legends ===
    for panel_idx, ax in enumerate(axlist):
        if panel_idx in legends:
            legend_handles = [
                Patch(facecolor=color, edgecolor="black", label=label) for label, color in legends[panel_idx]
            ]
            ax.legend(
                handles=legend_handles,
                loc="upper left",  # Adjusted to prevent overlap
                fontsize=8,
                frameon=True,
                bbox_to_anchor=(1.05, 1)  # Fixed position outside of chart area
            )
    logger.info(f"Loaded historical data with {len(df)} rows")
    plt.show()

# =====================
# EXECUTION HANDLERS (Critical Fix)
# =====================
def run_backtest(df):
    for current_dt in df.index:
        try:
            engine.current_row = df.loc[current_dt]  # Set current row
            if check_entry_conditions(df, current_dt):
                row = df.loc[current_dt]
                position_size = engine.calculate_position_size(row)
                shares = max(0.01, position_size / row['close'])

                trade = engine.execute_trade(
                    symbol, row['close'], shares, 'BUY', current_dt
                )
                log_trade(trade, symbol)

            # Evaluate exit conditions
            if engine.current_position and check_exit_conditions(df, current_dt):
                row = df.loc[current_dt]
                trade = engine.execute_trade(
                    symbol,
                    row['close'],
                    engine.current_position['shares'],
                    'SELL',
                    current_dt
                )
                log_trade(trade, symbol)
                
            if 'adx_shifted' not in df.columns:
                raise KeyError("Missing adx_shifted column in DataFrame")

        except Exception as e:
            logger.error(f"Error processing {current_dt}: {str(e)}")
            continue

    return df

# =====================
# MAIN EXECUTION
# =====================
def main():
    ib = IB()
    ib.connect('127.0.0.1', 7497, clientId=1)
    initial_balance = engine.balance  # Get initial balance from engine

    start_date = None
    end_date = None
    try:
        # Backtest mode
        daily_data = get_historical_data(ib, symbol, backtest=True)
        run_backtest(daily_data)
        plot_candlestick(daily_data, backtest=True)

    except Exception as e:
        logger.error(f"Execution error: {str(e)}")
    finally:
        if 'ib' in locals() and ib.isConnected():
            ib.disconnect()

            if engine.trade_history:
                trade_history = pd.DataFrame(engine.trade_history)
                if 'timestamp' in trade_history.columns and len(trade_history) > 1:
                    start_dt = pd.to_datetime(trade_history['timestamp'].min())
                    end_dt = pd.to_datetime(trade_history['timestamp'].max())
                    days = (end_dt - start_dt).days + 1
                    annualized_return = ((engine.balance/initial_balance) ** (252/days) - 1) * 100
                else:
                    annualized_return = 0.0  # No trades or insufficient data
                    
                if 'pnl' in trade_history.columns:
                    # Use only completed trades (SELL actions) for metrics
                    completed_trades = trade_history[trade_history['action'] == 'SELL']
                    total_trades = len(completed_trades)
                    profitable_trades = (completed_trades['pnl'] > 0).sum()
                    losing_trades = (completed_trades['pnl'] < 0).sum()
                    win_rate = (profitable_trades / total_trades * 100) if total_trades > 0 else 0.0

                    # Calculate returns using ONLY completed trades
                    returns = completed_trades['pnl'] / initial_balance
                    total_pnl = completed_trades['pnl'].sum()
                    annualized_return = ((engine.balance/initial_balance) ** (252/days) - 1) * 100

                    # Time-based annualization (fixed)
                    days = 1  # Default to avoid division by zero
                    if 'timestamp' in trade_history.columns and len(trade_history) > 1:
                        start_dt = pd.to_datetime(trade_history['timestamp'].min())
                        end_dt = pd.to_datetime(trade_history['timestamp'].max())
                        days = (end_dt - start_dt).days + 1
                        annualized_return = ((engine.balance/initial_balance) ** (252/days) - 1) * 100
                    else:
                        annualized_return = 0.0

                    # Risk metrics
                    risk_free_rate = 0.02  # 2% annual
                    excess_returns = returns - (risk_free_rate/252)
                    volatility = returns.std() * np.sqrt(252) if len(returns) > 1 else 0.0

                    # Sharpe Ratio (handle zero volatility)
                    sharpe_ratio = (np.sqrt(252) * excess_returns.mean() / returns.std() 
                                   if returns.std() > 0 else 0.0)

                    # Sortino Ratio (handle no downside risk)
                    downside_returns = returns[returns < 0]
                    if len(downside_returns) > 0:
                        sortino_ratio = np.sqrt(252) * excess_returns.mean() / downside_returns.std()
                    else:
                        sortino_ratio = float('inf') if excess_returns.mean() > 0 else 0.0

                    # Drawdown calculation
                    cumulative_returns = (1 + returns).cumprod()
                    rolling_max = cumulative_returns.expanding().max()
                    drawdowns = (cumulative_returns - rolling_max) / rolling_max
                    max_drawdown = drawdowns.min() * 100 if len(drawdowns) > 0 else 0.0

                    # Trade statistics
                    avg_profit = completed_trades[completed_trades['pnl'] > 0]['pnl'].mean()
                    avg_loss = abs(completed_trades[completed_trades['pnl'] < 0]['pnl'].mean())

                    # Profit factor with safeguards
                    gains = completed_trades[completed_trades['pnl'] > 0]['pnl']
                    losses = completed_trades[completed_trades['pnl'] < 0]['pnl']
                    total_gains = gains.sum()
                    total_losses = -losses.sum()

                    if total_losses == 0:
                        profit_factor = float('inf') if total_gains > 0 else 0.0
                    else:
                        profit_factor = total_gains / total_losses

                    # Log metrics
                    logger.info(f"Total Trades: {total_trades}")
                    logger.info(f"Profitable Trades: {profitable_trades}")
                    logger.info(f"Losing Trades: {losing_trades}")
                    logger.info(f"Win Rate: {win_rate:.2f}%")
                    logger.info(f"Total PnL: ${total_pnl:.2f}")
                    logger.info(f"Annualized Return: {annualized_return:.2f}%")
                    logger.info(f"Volatility: {volatility:.2f}")
                    logger.info(f"Sharpe Ratio: {sharpe_ratio:.2f}")
                    logger.info(f"Sortino Ratio: {sortino_ratio:.2f}" 
                              if not np.isinf(sortino_ratio) else "Sortino Ratio: Infinite")
                    logger.info(f"Max Drawdown: {max_drawdown:.2f}%")
                    logger.info(f"Average Profit: ${avg_profit:.2f}" 
                              if not np.isnan(avg_profit) else "Average Profit: $0.00")
                    logger.info(f"Average Loss: ${-avg_loss:.2f}" 
                              if not np.isnan(avg_loss) else "Average Loss: $0.00")
                    logger.info(f"Profit Factor: Infinite" 
                              if profit_factor == float('inf') else f"Profit Factor: {profit_factor:.2f}")

                # Plotting logic remains unchanged
                if 'timestamp' in trade_history.columns and not trade_history['timestamp'].empty:
                    trade_history['timestamp'] = pd.to_datetime(trade_history['timestamp'], utc=True)
                    start_date = pd.Timestamp(trade_history['timestamp'].min()).tz_convert('UTC').replace(
                        hour=0, minute=0, second=0, microsecond=0)
                    end_date = pd.Timestamp(trade_history['timestamp'].max()).tz_convert('UTC').replace(
                        hour=23, minute=59, second=59, microsecond=999)
                    '''plot_pnl_calendar(engine, start_date, end_date, initial_balance, symbol)'''
                else:
                    logger.warning("No trade history or missing timestamp data. Skipping PNL calendar plot.")

if __name__ == '__main__':
    main()
