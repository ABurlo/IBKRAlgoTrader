# =====================
# CORE IMPORTS
# =====================
from ib_insync import IB, Stock, util
import pandas as pd
import numpy as np
import mplfinance as mpf
from datetime import datetime, timedelta, time
import asyncio
import nest_asyncio
import logging
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
from time import sleep
from matplotlib.colors import ListedColormap, Normalize, LinearSegmentedColormap
from collections.abc import MutableMapping
import pytz
import matplotlib.patheffects as pe
from matplotlib.cm import ScalarMappable
import seaborn as sns
from matplotlib.dates import DateFormatter
from scipy.signal import savgol_filter
import sys
from concurrent.futures import ThreadPoolExecutor
from hyperopt import fmin, tpe, hp, Trials
import random
import statsmodels.api as sm
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

PARAM_RANGES = {
    'time_based': {
        'position_risk': [0.005, 0.05],
        'volatility_mult': [0.5, 3.0],
        'entry_conditions': {
            'rsi': {'threshold': [20, 60]},
            'mean_deviation': {'threshold': [-2.0, 0.0]},
            'volume': {'threshold': [1.0, 1.5]}  # Volume > 1.0â€“1.5x MA
        },
        'exit_conditions': {
            'stop_loss': {'threshold': [-3.5, -1.5]},
            'mean_reversion': {'threshold': [0.0, 1.0]},
            'trailing_stop': {'atr_multiplier': [1.5, 3.0]},
            'profit_target': {'threshold': [1.5, 3.0]}
        }
    },
    'signal_score': {
        'position_risk': [0.005, 0.05],
        'entry_conditions': {
            'rsi': {'threshold': [20, 60]},
            'williams_r': {'threshold': [-90, -60]},
            'mean_deviation': {'threshold': [-2.0, 0.0]},
        },
        'signal_weights': {
            'rsi': [0.2, 0.4],
            'williams': [0.2, 0.4],
            'mean_deviation': [0.3, 0.5],
        },
        'exit_conditions': {
            'signal_score': {'threshold': [0.6, 0.8]},
        }
    },
    'pca_stat_arb': {
        'position_risk': [0.005, 0.05],
        'entry_conditions': {
            'zscore': {'threshold': [-2.0, -1.0]},
        },
        'exit_conditions': {
            'zscore_reversion': {'threshold': [-0.5, 0.5]},
        }
    },
    'bollinger_reversion': {
        'position_risk': [0.005, 0.05],
        'volatility_mult': [0.5, 3.0],
        'entry_conditions': {
            'bollinger_zscore': {'threshold': [-2.5, -1.5]},
        },
        'exit_conditions': {
            'mean_reversion': {'threshold': [-0.5, 0.5]},
            'stop_loss': {'threshold': [-4.0, -2.0]},
        }
    },
    'rsi_divergence': {
        'position_risk': [0.005, 0.05],
        'volatility_mult': [0.5, 3.0],
        'entry_conditions': {
            'rsi': {'threshold': [20, 40]},
            'price_divergence': {'threshold': [-0.02, -0.005]},
        },
        'exit_conditions': {
            'rsi_reversion': {'threshold': [50, 70]},
            'stop_loss': {'threshold': [-3.5, -1.5]}
        }
    }
}

def update_config(base_config, mode, params):
    """Update the mode_config with hypertuned parameters."""
    config = base_config[mode].copy()
    for key, value in params.items():
        if key in ['position_risk', 'volatility_mult']:
            config[key] = value
        elif key == 'entry_conditions':
            for cond, cond_params in value.items():
                # Ensure 'threshold' is a scalar
                config['entry_conditions'][cond]['threshold'] = cond_params['threshold']
        elif key == 'exit_conditions':
            for cond, cond_params in value.items():
                # Ensure 'threshold' or 'atr_multiplier' is a scalar
                for param, val in cond_params.items():
                    config['exit_conditions'][cond][param] = val
        elif key == 'signal_weights':
            for sig, weight in value.items():
                config['signal_weights'][sig] = weight
    return config

# =====================
# LOGGING SETUP
# =====================
class TradeFormatter(logging.Formatter):
    GREEN = '\033[92m'
    RED = '\033[91m'
    WHITE = '\033[0m'
    
    def format(self, record):
        message = super().format(record)
        if sys.stdout.isatty():
            if 'BUY' in message:
                message = f"{self.GREEN}{message}{self.WHITE}"
            elif 'SELL' in message:
                message = f"{self.RED}{message}{self.WHITE}"
        return message

# Clear the log file at the start of each run
log_file = 'strategy_execution.log'
with open(log_file, 'w') as f:
    f.truncate(0)  # This ensures the file is cleared

root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)
for handler in root_logger.handlers[:]:
    root_logger.removeHandler(handler)

console_handler = logging.StreamHandler()
console_handler.setFormatter(TradeFormatter('%(asctime)s | %(message)s'))
file_handler = logging.FileHandler(log_file)
file_handler.setFormatter(logging.Formatter('%(asctime)s | %(message)s'))
root_logger.addHandler(console_handler)
root_logger.addHandler(file_handler)
logger = logging.getLogger(__name__)

class GlobalConfig:
    nest_asyncio.apply()
    symbol = 'MSFT'
    durationStr = '30 D'
    timeframes = ['5 mins']
    currency = 'USD'
    initial_balance = 10000
    MIN_REQUIRED_BANDS = 2
    gradient_levels = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
    colors = ['#FF0000', '#FFA500', '#00FF00', '#0000FF']
    outer_levels = ['weak', 'moderate', 'strong']
    volatility_threshold = 0.05
    MIN_PRICE = 5.0
    MAX_PRICE = 1000.0
    MIN_TRADE_VALUE = 10.0
    MODE_TO_ID = {
        'time_based': 'A/1',
        'pca_stat_arb': 'B/2'
    }
    STRATEGIES = {
        'A/1': 'time_based',
        'B/2': 'pca_stat_arb'
    }
    STRATEGY_LABELS = {
        'A/1': 'A: Time-Based',
        'B/2': 'B: PCA Stat Arb',
        'buy_and_hold': 'Benchmark: Buy & Hold'
    }

sns.set_style("whitegrid")
sns.set_context("notebook")
sns.set_palette("tab10")
plt.rcParams.update({
    'font.size': 10,
    'axes.labelcolor': 'black',
    'axes.titlepad': 12,
    'grid.color': 'gray',
    'figure.dpi': 300,
    'axes.facecolor': 'white',
    'figure.facecolor': 'white'
})

MRC_GRADIENT_STYLE = 'full_spectrum'
full_spectrum_colors = ['#FF0000', '#FFA500', '#00FF00', '#0000FF']
def create_colormap(colors_list):
    return LinearSegmentedColormap.from_list('custom_mrc', colors_list, N=len(GlobalConfig.gradient_levels))
full_spectrum_cmap = create_colormap(full_spectrum_colors)
mrc_cmap = full_spectrum_cmap

# =====================
# MARKET REGIME DETECTION
# =====================
def detect_market_regime(row):
    """Detect market regime based on indicators."""
    adx = row['adx_shifted']
    atr_volatility = row['ATR_shifted'] / row['close'] if row['close'] > 0 else 0
    rsi = row['RSI_shifted']
    
    # Relaxed mean-reverting conditions: higher ADX threshold, or RSI extremes
    if adx < 25 or atr_volatility < GlobalConfig.volatility_threshold or rsi < 40 or rsi > 60:
        return 'mean_reverting'
    else:
        return 'trending'

# =====================
# HYPER TUNING PARAMS
# =====================
def objective(params, ib, timeframe, mode, base_config, daily_data, fold_size, folds):
    sharpe_sum = 0
    for fold in range(folds):
        start_idx = fold * fold_size
        end_idx = (fold + 1) * fold_size if fold < folds - 1 else len(daily_data)
        fold_data = daily_data.iloc[start_idx:end_idx]
        engine = BacktestEngine(GlobalConfig.MODE_TO_ID[mode], mode, timeframe)
        engine.mode_config[mode] = update_config(base_config, mode, params)
        engines, _ = run_backtest(fold_data, timeframe, single_strategy=GlobalConfig.MODE_TO_ID[mode])
        if engines is None or GlobalConfig.MODE_TO_ID[mode] not in engines:
            return float('inf')  # Penalize failed backtests
        trades = engines[GlobalConfig.MODE_TO_ID[mode]].trade_history
        metrics = calculate_day_metrics(trades)
        # Normalize metrics to prevent skew
        sharpe = max(metrics['overall']['sharpe_ratio'], -2.0)  # Cap negative Sharpe
        profit_factor = min(metrics['overall']['profit_factor'], 10.0)  # Cap infinite profit factor
        drawdown = min(metrics['overall']['max_drawdown'], 100.0)  # Cap drawdown at 100%
        score = (sharpe * 0.5 + profit_factor * 0.3 - drawdown * 0.2)
        sharpe_sum += score
    return -sharpe_sum / folds  # Minimize negative average score

def hypertune_strategy(ib, timeframe, mode, base_config, num_trials=5, folds=3):
    daily_data = get_historical_data(ib, timeframe, backtest=True)
    if daily_data is None:
        logger.warning(f"No data retrieved for {mode} in {timeframe}")
        return None, None

    fold_size = len(daily_data) // folds
    strategy_id = GlobalConfig.MODE_TO_ID[mode]

    def objective_wrapper(params):
        return objective(params, ib, timeframe, mode, base_config, daily_data, fold_size, folds)

    space = {}
    for key in PARAM_RANGES[mode].keys():
        if key in ['position_risk', 'volatility_mult']:
            space[key] = hp.uniform(key, PARAM_RANGES[mode][key][0], PARAM_RANGES[mode][key][1])
        elif key in ['entry_conditions', 'exit_conditions']:
            space[key] = {
                cond: {p: hp.uniform(f"{key}_{cond}_{p}", PARAM_RANGES[mode][key][cond][p][0], PARAM_RANGES[mode][key][cond][p][1])
                       for p in PARAM_RANGES[mode][key][cond]}
                for cond in PARAM_RANGES[mode][key]
            }
        elif key == 'signal_weights' and mode == 'signal_score':
            space[key] = {
                sig: hp.uniform(f"{key}_{sig}", PARAM_RANGES[mode][key][sig][0], PARAM_RANGES[mode][key][sig][1])
                for sig in PARAM_RANGES[mode][key]
            }

    trials = Trials()
    best = fmin(fn=objective_wrapper, space=space, algo=tpe.suggest, max_evals=num_trials, trials=trials)

    best_params = {}
    for key, value in best.items():
        if key in ['position_risk', 'volatility_mult']:
            best_params[key] = value
        elif key.startswith('entry_conditions') or key.startswith('exit_conditions'):
            parts = key.split('_')
            section, cond, param = parts[0], parts[1], parts[2]
            if section not in best_params:
                best_params[section] = {}
            if cond not in best_params[section]:
                best_params[section][cond] = {}
            best_params[section][cond][param] = value
        elif key.startswith('signal_weights') and mode == 'signal_score':
            if 'signal_weights' not in best_params:
                best_params['signal_weights'] = {}
            sig = key.split('_')[1]
            best_params['signal_weights'][sig] = value

    if 'signal_weights' in best_params:
        total_weight = sum(best_params['signal_weights'].values())
        if total_weight > 0:
            best_params['signal_weights'] = {sig: w / total_weight for sig, w in best_params['signal_weights'].items()}

    logger.info(f"Best params for {mode} after {num_trials} Bayesian trials: {best_params}")

    if best_params:
        engine = BacktestEngine(strategy_id, mode, timeframe)
        engine.mode_config[mode] = update_config(base_config, mode, best_params)
        engines, _ = run_backtest(daily_data, timeframe, single_strategy=strategy_id)
        if engines and strategy_id in engines:
            trades = engines[strategy_id].trade_history
            best_metrics = calculate_day_metrics(trades)
            # Correctly access 'loss' from the 'result' dictionary in trials
            best_sharpe_avg = -min([t['result']['loss'] for t in trials.trials if t['result']['status'] == 'ok'])
            logger.info(f"Best params for {mode} (ID {strategy_id}): {best_params}, Avg Sharpe={best_sharpe_avg:.2f}")
            return best_params, best_metrics
        else:
            logger.warning(f"Final backtest failed for {mode} with best params: {best_params}")
            return best_params, None
    else:
        logger.warning(f"No valid parameters found for {mode} after {num_trials} trials")
        return None, None

# =====================
# MARKET CLOSURE WARNING
# =====================
def enforce_ny_timezone(timestamp):
    ny_tz = pytz.timezone('America/New_York')
    try:
        if not isinstance(timestamp, pd.Timestamp):
            timestamp = pd.to_datetime(timestamp)
        if timestamp.tzinfo is None:
            logger.debug(f"Localizing naive timestamp {timestamp} to NY timezone")
            return ny_tz.localize(timestamp)
        else:
            logger.debug(f"Converting tz-aware timestamp {timestamp} to NY timezone")
            return timestamp.tz_convert(ny_tz)
    except Exception as e:
        logger.error(f"Timezone enforcement failed for {timestamp}: {str(e)}")
        raise ValueError(f"Invalid timestamp: {timestamp}")

def is_market_close(index):
    ny_tz = pytz.timezone('America/New_York')
    if index.tzinfo is None:
        logger.debug(f"Localizing naive index {index} to NY timezone")
        index = index.tz_localize(ny_tz)
    else:
        logger.debug(f"Converting tz-aware index {index} to NY timezone")
        index = index.tz_convert(ny_tz)
    
    current_time = index.time
    market_close_time = time(16, 0)
    time_delta = timedelta(minutes=10)
    
    dummy_date = index.date()
    market_close_dt = ny_tz.localize(datetime.combine(dummy_date, market_close_time))
    
    return (market_close_dt - time_delta) <= index <= market_close_dt

def ensure_ny_timezone(df):
    """Ensure the DataFrame index is in NY timezone."""
    if df.index.tz != pytz.timezone('America/New_York'):
        df.index = df.index.tz_convert('America/New_York')
    return df

# =====================
# METRICS CALCULATION
# =====================
def calculate_day_metrics(trades, risk_free_rate=0.02):
    if not trades:
        logger.warning("No trades provided for metrics calculation")
        return {
            'overall': {
                'win_rate': 0.0,
                'win_loss_ratio': 0.0,
                'num_trades': 0,
                'total_pnl': 0.0,
                'avg_pnl': 0.0,
                'sharpe_ratio': 0.0,
                'sortino_ratio': 0.0,
                'max_drawdown': 0.0,
                'avg_win': 0.0,
                'avg_loss': 0.0,
                'profit_factor': 0.0,
                'avg_holding_hours': 0.0,
                'trades_per_day': 0.0,
                'risk_reward_ratio': 0.0,
                'recovery_factor': 0.0
            },
            'by_exit_strategy': {},
            'holding_periods': {
                'winning': 0.0,
                'losing': 0.0,
                'by_exit_strategy': {}
            },
            'volatility': {
                'avg_atr': 0.0,
                'pnl_volatility_correlation': 0.0
            }
        }

    num_trades = len(trades)
    total_pnl = 0.0
    wins = losses = 0
    pnl_list = []
    win_pnls = []
    loss_pnls = []
    holding_times = []
    exit_strategy_counts = {}
    exit_strategy_pnl = {}
    exit_strategy_wins = {}
    exit_strategy_losses = {}
    exit_strategy_holding = {}
    atr_list = []
    risk_rewards = []
    balance_history = [GlobalConfig.initial_balance]

    for t in trades:
        if not isinstance(t, dict) or 'timestamp' not in t:
            logger.error(f"Invalid trade format: {t}")
            continue
        
        trade_pnl = float(t.get('pnl', 0.0))
        if 'pnl' not in t or t['pnl'] is None:
            logger.warning(f"Trade at {t['timestamp']} missing PnL, defaulting to 0")
        total_pnl += trade_pnl
        pnl_list.append(trade_pnl)
        balance_history.append(balance_history[-1] + trade_pnl)
        
        if t['action'] == 'SELL':
            if trade_pnl > 0:
                wins += 1
                win_pnls.append(trade_pnl)
            elif trade_pnl < 0:
                losses += 1
                loss_pnls.append(trade_pnl)

            entry_time = pd.to_datetime(t.get('entry_time', t['timestamp']))
            exit_time = pd.to_datetime(t['timestamp'])
            holding_time = (exit_time - entry_time).total_seconds() / 3600
            holding_times.append(holding_time)

            exit_type = t.get('exit_type', 'Unknown')
            exit_strategy_counts[exit_type] = exit_strategy_counts.get(exit_type, 0) + 1
            exit_strategy_pnl[exit_type] = exit_strategy_pnl.get(exit_type, 0) + trade_pnl
            if trade_pnl > 0:
                exit_strategy_wins[exit_type] = exit_strategy_wins.get(exit_type, 0) + 1
            elif trade_pnl < 0:
                exit_strategy_losses[exit_type] = exit_strategy_losses.get(exit_type, 0) + 1
            exit_strategy_holding[exit_type] = exit_strategy_holding.get(exit_type, []) + [holding_time]

            if 'ATR' in t and 'entry_price' in t and 'price' in t:
                atr_list.append(float(t['ATR']))
                entry_price = float(t['entry_price'])
                exit_price = float(t['price'])
                potential_loss = abs(entry_price - (entry_price - t['ATR']))
                potential_gain = abs(exit_price - entry_price) if trade_pnl > 0 else 0
                if potential_loss > 0 and potential_gain > 0:
                    risk_rewards.append(potential_gain / potential_loss)

    win_rate = (wins / (wins + losses)) * 100 if (wins + losses) > 0 else 0.0
    win_loss_ratio = (wins / losses) if losses > 0 else float('inf') if wins > 0 else 0.0
    avg_pnl = total_pnl / num_trades if num_trades > 0 else 0.0
    avg_win = sum(win_pnls) / len(win_pnls) if win_pnls else 0.0
    avg_loss = sum(loss_pnls) / len(loss_pnls) if loss_pnls else 0.0
    profit_factor = sum(win_pnls) / abs(sum(loss_pnls)) if loss_pnls and sum(loss_pnls) != 0 else float('inf') if win_pnls else 0.0

    pnl_array = np.array(pnl_list)
    daily_rfr = risk_free_rate / 252
    excess_returns = pnl_array - daily_rfr
    mean_excess_return = np.mean(excess_returns)
    std_dev = np.std(pnl_array, ddof=1) if num_trades > 1 else 0.0
    sharpe_ratio = (mean_excess_return / std_dev) * np.sqrt(252) if std_dev > 0 else 0.0

    downside_returns = pnl_array[pnl_array < 0]
    downside_dev = np.std(downside_returns, ddof=1) if len(downside_returns) > 1 else 0.0
    sortino_ratio = (mean_excess_return / downside_dev) * np.sqrt(252) if downside_dev > 0 else 0.0

    balance_array = np.array(balance_history)
    peak = np.maximum.accumulate(balance_array)
    drawdowns = (peak - balance_array) / peak
    max_drawdown = np.max(drawdowns) * 100 if np.max(drawdowns) > 0 else 0.0

    avg_holding_hours = sum(holding_times) / len(holding_times) if holding_times else 0.0
    days_span = (max(pd.to_datetime([t['timestamp'] for t in trades if t['action'] == 'SELL'])) - 
                 min(pd.to_datetime([t['timestamp'] for t in trades if t['action'] == 'SELL']))).days + 1 if len([t for t in trades if t['action'] == 'SELL']) > 1 else 1
    trades_per_day = len([t for t in trades if t['action'] == 'SELL']) / days_span if days_span > 0 else 0.0
    risk_reward_ratio = sum(risk_rewards) / len(risk_rewards) if risk_rewards and len(risk_rewards) > 0 else 0.0
    recovery_factor = total_pnl / (max_drawdown / 100 * GlobalConfig.initial_balance) if max_drawdown > 0 else float('inf')

    by_exit_strategy = {}
    holding_by_exit = {}
    for exit_type in exit_strategy_counts:
        num_trades_exit = exit_strategy_counts[exit_type]
        wins_exit = exit_strategy_wins.get(exit_type, 0)
        losses_exit = exit_strategy_losses.get(exit_type, 0)
        total_pnl_exit = exit_strategy_pnl[exit_type]
        
        by_exit_strategy[exit_type] = {
            'win_rate': (wins_exit / num_trades_exit * 100) if num_trades_exit > 0 else 0.0,
            'num_trades': num_trades_exit,
            'total_pnl': round(total_pnl_exit, 2),
            'avg_pnl': total_pnl_exit / num_trades_exit if num_trades_exit > 0 else 0.0,
            'win_loss_ratio': (wins_exit / losses_exit) if losses_exit > 0 else float('inf') if wins_exit > 0 else 0.0
        }
        holding_by_exit[exit_type] = sum(exit_strategy_holding[exit_type]) / len(exit_strategy_holding[exit_type]) if exit_strategy_holding[exit_type] else 0.0

    winning_holding = [ht for ht, pnl in zip(holding_times, [t['pnl'] for t in trades if t['action'] == 'SELL']) if pnl > 0]
    losing_holding = [ht for ht, pnl in zip(holding_times, [t['pnl'] for t in trades if t['action'] == 'SELL']) if pnl < 0]
    avg_winning_holding = sum(winning_holding) / len(winning_holding) if winning_holding else 0.0
    avg_losing_holding = sum(losing_holding) / len(losing_holding) if losing_holding else 0.0

    avg_atr = sum(atr_list) / len(atr_list) if atr_list else 0.0
    volatility_pnl_correlation = np.corrcoef(pnl_list, atr_list[:len(pnl_list)])[0, 1] if atr_list and len(pnl_list) <= len(atr_list) else 0.0

    return {
        'overall': {
            'win_rate': round(win_rate, 2),
            'win_loss_ratio': round(win_loss_ratio, 2) if win_loss_ratio != float('inf') else float('inf'),
            'num_trades': num_trades,
            'total_pnl': round(total_pnl, 2),
            'avg_pnl': round(avg_pnl, 2),
            'sharpe_ratio': round(sharpe_ratio, 2),
            'sortino_ratio': round(sortino_ratio, 2),
            'max_drawdown': round(max_drawdown, 2),
            'avg_win': round(avg_win, 2),
            'avg_loss': round(avg_loss, 2),
            'profit_factor': round(profit_factor, 2) if profit_factor != float('inf') else float('inf'),
            'avg_holding_hours': round(avg_holding_hours, 2),
            'trades_per_day': round(trades_per_day, 2),
            'risk_reward_ratio': round(risk_reward_ratio, 2),
            'recovery_factor': round(recovery_factor, 2) if recovery_factor != float('inf') else float('inf')
        },
        'by_exit_strategy': by_exit_strategy,
        'holding_periods': {
            'winning': round(avg_winning_holding, 2),
            'losing': round(avg_losing_holding, 2),
            'by_exit_strategy': {k: round(v, 2) for k, v in holding_by_exit.items()}
        },
        'volatility': {
            'avg_atr': round(avg_atr, 2),
            'pnl_volatility_correlation': round(volatility_pnl_correlation, 2)
        }
    }
    
# =====================
# BACKTEST ENGINE
# =====================
# Helper function for price validation
def is_price_valid(price):
    """Check if the stock price is within acceptable range."""
    return GlobalConfig.MIN_PRICE <= price <= GlobalConfig.MAX_PRICE

def advanced_regime_detection(df):
    features = df[['adx_shifted', 'ATR_shifted', 'RSI_shifted']].dropna()
    kmeans = KMeans(n_clusters=3).fit(features)
    df['regime'] = kmeans.predict(features)
    return df

class BacktestEngine:
    def __init__(self, strategy_id, mode='time_based', timeframe='1 hour'):
        self.strategy_id = strategy_id
        self.mode = mode
        self.timeframe = timeframe
        self.mode_config = {
            'time_based': {
                'position_risk': 0.02,
                'volatility_mult': 1.5,
                'entry_conditions': {
                    'rsi': {'threshold': 40},
                    'mean_deviation': {'threshold': -1.0},
                    'volume': {'threshold': 1.25}
                },
                'exit_conditions': {
                    'stop_loss': {'threshold': -1.5},
                    'mean_reversion': {'threshold': 0.5},
                    'trailing_stop': {'atr_multiplier': 3.0},
                    'profit_target': {'threshold': 2.25}
                }
            },
            'signal_score': {
                'position_risk': 0.02,
                'volatility_mult': 1.5,
                'entry_conditions': {
                    'mean_deviation': {'threshold': -0.5, 'operator': '<'},
                    'rsi': {'threshold': 40, 'operator': '<'},
                    'williams_r': {'threshold': -70, 'operator': '<'}
                },
                'signal_weights': {
                    'mean_deviation': 0.4,
                    'rsi': 0.3,
                    'williams': 0.3
                },
                'exit_conditions': {
                    'signal_score': {'threshold': 0.7}
                }
            },
            'pca_stat_arb': {
                'position_risk': 0.02,
                'volatility_mult': 1.0,
                'num_equities': 20,
                'rebalance_days': 30,
                'entry_conditions': {
                    'zscore': {'threshold': -1.0, 'operator': '<'}
                },
                'exit_conditions': {
                    'zscore_reversion': {'threshold': 0.0, 'operator': '>'}
                }
            },
            'bollinger_reversion': {
                'position_risk': 0.02,
                'volatility_mult': 1.5,
                'entry_conditions': {
                    'bollinger_zscore': {'threshold': -2.0, 'operator': '<'}
                },
                'exit_conditions': {
                    'mean_reversion': {'threshold': 0.0, 'operator': '>'},
                    'stop_loss': {'threshold': -3.0, 'operator': '<'}
                }
            },
            'rsi_divergence': {
                'position_risk': 0.02,
                'volatility_mult': 1.5,
                'entry_conditions': {
                    'rsi': {'threshold': 30, 'operator': '<'},
                    'price_divergence': {'threshold': -0.01, 'operator': '<'}
                },
                'exit_conditions': {
                    'rsi_reversion': {'threshold': 50, 'operator': '>'},
                    'stop_loss': {'threshold': -2.0, 'operator': '<'}
                }
            }
        }
        self.validate_mode_config()  # Validate the configuration
        self.balance = GlobalConfig.initial_balance
        self.current_positions = []  # No limit on positions
        self.trade_history = []
        self.fee_per_share = 0.0035
        self.slippage = 0.0002
        self.volatility_filter = {'min_mrc': 0.02, 'max_mrc': 0.08}
        self.daily_pnl = {}
        self.backtest_data = []
        logger.info(f"Strategy #{strategy_id} ({mode}) initialized for {timeframe} with balance: ${self.balance}")

    def validate_mode_config(self):
        """Validate that mode_config contains all required keys."""
        required_keys = ['position_risk', 'volatility_mult', 'entry_conditions', 'exit_conditions']
        signal_score_required = required_keys + ['signal_weights']
        for mode, config in self.mode_config.items():
            if mode == 'signal_score':
                if not all(k in config for k in signal_score_required):
                    raise ValueError(f"Missing config keys in {mode}: {set(signal_score_required) - set(config.keys())}")
            else:
                if not all(k in config for k in required_keys):
                    raise ValueError(f"Missing config keys in {mode}: {set(required_keys) - set(config.keys())}")

    @property
    def max_position_size(self):
        return self.balance * 0.02  # Caps individual position size at 2% of balance

    def calculate_position_size(self, row):
        config = self.mode_config[self.mode]
        active_positions = len(self.current_positions)
        
        # Base risk capital is 2% of current balance
        base_risk_capital = self.balance * config['position_risk']  # config['position_risk'] = 0.02 by default
        
        # Adjust risk based on number of active positions
        risk_factor = max(1, active_positions * 0.5)  # Scales down with more positions
        risk_capital = base_risk_capital / risk_factor
        
        # ATR-based volatility adjustment
        atr_risk = max(row['ATR_shifted'] * config['volatility_mult'], 0.01)  # Avoid division by zero
        
        # Volume adjustment: Scale risk by volume relative to its moving average
        volume_ratio = row['volume'] / row['volume_ma_shifted'] if row['volume_ma_shifted'] > 0 else 1.0
        volume_factor = min(max(volume_ratio, 0.5), 2.0)  # Cap between 0.5x and 2x
        
        # Risk-reward ratio adjustment (simplified estimate using ATR as potential loss)
        potential_loss = atr_risk
        potential_gain = atr_risk * 2  # Assume 2:1 reward-to-risk as a baseline
        risk_reward_factor = min(max(potential_gain / potential_loss, 0.5), 2.0)  # Cap between 0.5x and 2x
        
        # Calculate dynamic position size, respecting the 2% cap
        dynamic_size = (risk_capital / atr_risk) * volume_factor * risk_reward_factor
        position_size = min(self.max_position_size, dynamic_size)  # Strictly enforce 2% cap
        position_size = max(position_size, GlobalConfig.MIN_TRADE_VALUE)  # Ensure minimum trade value
        
        if not np.isfinite(position_size) or position_size <= 0:
            logger.warning(f"Strategy #{self.strategy_id}: Invalid position size calculated: {position_size}")
            return 0
        
        logger.debug(f"Strategy #{self.strategy_id} - Position size: ${position_size:.2f} (Base Risk=${base_risk_capital:.2f}, ATR Risk={atr_risk:.2f}, Volume Factor={volume_factor:.2f}, RR Factor={risk_reward_factor:.2f}, Active={active_positions})")
        return position_size

    def apply_slippage(self, price, is_buy, row):
        spread = (row['high'] - row['low']) * 0.5  # Proxy for bid-ask spread
        return price * (1 + (spread / price) if is_buy else -(spread / price))

    def calculate_fees(self, shares):
        return abs(shares * self.fee_per_share)

    def composite_signal_score(self, row):
        config = self.mode_config[self.mode]
        if self.mode != 'signal_score':
            return 0.0
        weights = config['signal_weights'].copy()
        total_weight = sum(weights.values())
        scores = {}
        conditions_met = 0
        total_conditions = len(weights)

        if 'mean_deviation' in weights:
            deviation = (row['close'] - row['meanline']) / row['meanrange_shifted'] if row['meanrange_shifted'] > 0 else 0
            scores['mean_deviation'] = weights['mean_deviation'] * min(1.0, max(0, (-deviation - 1.0) / 1.0))
            conditions_met += 1 if deviation < -1.0 else 0
        if 'rsi' in weights:
            rsi = row['RSI_shifted']
            scores['rsi'] = weights['rsi'] * min(1.0, max(0, (30 - rsi) / 30))
            conditions_met += 1 if rsi < 30 else 0
        if 'williams' in weights:
            williams = row['Williams_%R_shifted']
            scores['williams'] = weights['williams'] * min(1.0, max(0, (-80 - williams) / 20))
            conditions_met += 1 if williams < -80 else 0

        weighted_score = sum(scores.values()) / total_weight if total_weight > 0 else 0
        return weighted_score if conditions_met >= total_conditions * 0.75 else 0

    def execute_trade(self, price, shares, action, timestamp, exit_type=None, row=None):
        if not is_price_valid(price):
            logger.warning(f"Strategy #{self.strategy_id}: Price ${price:.2f} outside allowed range "
                          f"(${GlobalConfig.MIN_PRICE}-${GlobalConfig.MAX_PRICE})")
            return None

        metrics = calculate_day_metrics(self.trade_history)
        if metrics['overall']['max_drawdown'] > 20:
            logger.error(f"Strategy #{self.strategy_id}: Max drawdown exceeded. Halting.")
            return None

        try:
            price_with_slippage = self.apply_slippage(price, action == 'BUY', row) if row is not None else price
            fees = self.calculate_fees(shares)
            position_value = shares * price_with_slippage

            if position_value < GlobalConfig.MIN_TRADE_VALUE:
                logger.warning(f"Strategy #{self.strategy_id}: Position value ${position_value:.2f} below minimum ${GlobalConfig.MIN_TRADE_VALUE}")
                return None

            trade = {
                'strategy_id': self.strategy_id,
                'timestamp': timestamp,
                'action': action,
                'price': price_with_slippage,
                'shares': shares,
                'position_value': position_value,
                'balance_before': self.balance,
                'exit_type': exit_type if action == 'SELL' else None
            }

            if action == 'BUY':
                total_cost = position_value + fees
                if total_cost > self.balance:
                    logger.warning(f"Strategy #{self.strategy_id}: Insufficient funds: ${total_cost:.2f} > ${self.balance:.2f}")
                    return None
                if position_value > self.max_position_size:
                    logger.error(f"Strategy #{self.strategy_id}: Position value ${position_value:.2f} exceeds max position size ${self.max_position_size:.2f}")
                    return None
                position_id = len(self.current_positions)
                self.current_positions.append({
                    'position_id': position_id,
                    'symbol': GlobalConfig.symbol,
                    'entry_price': price_with_slippage,
                    'shares': shares,
                    'timestamp': timestamp,
                    'position_value': position_value,
                    'entry_time': timestamp,
                    'highest_price': price_with_slippage
                })
                self.balance -= total_cost
                trade['pnl'] = 0.0
                trade['pnl_pct'] = 0.0
                trade['entry_time'] = timestamp
                trade['position_id'] = position_id
                logger.info(f"Strategy #{self.strategy_id} - Buy: Position #{position_id}, Price=${price_with_slippage:.2f}, Shares={shares:.2f}, Value=${position_value:.2f}, Balance After=${self.balance:.2f}")

            elif action == 'SELL':
                if not self.current_positions:
                    logger.warning(f"Strategy #{self.strategy_id}: Sell attempted with no positions")
                    return None
                if not exit_type or 'Pos #' not in exit_type:
                    logger.error(f"Strategy #{self.strategy_id}: Invalid exit_type format: {exit_type}")
                    return None
                pos_id = int(exit_type.split('Pos #')[1].strip(')'))
                position = next((p for p in self.current_positions if p['position_id'] == pos_id), None)
                if not position:
                    logger.warning(f"Strategy #{self.strategy_id}: Position #{pos_id} not found for sell")
                    return None
                self.current_positions.remove(position)
                entry_price = position['entry_price']
                entry_time = position['entry_time']
                entry_value = entry_price * shares
                exit_value = price_with_slippage * shares
                pnl = exit_value - entry_value - fees
                if not np.isfinite(pnl):
                    logger.error(f"Strategy #{self.strategy_id}: Invalid PnL calculated: {pnl}")
                    pnl = 0.0
                pnl_pct = (pnl / entry_value) * 100 if entry_value != 0 else 0
                trade['pnl'] = pnl
                trade['pnl_pct'] = pnl_pct
                trade['entry_time'] = entry_time
                trade['position_id'] = position['position_id']
                self.balance += (exit_value - fees)
                self.daily_pnl[timestamp.strftime('%Y-%m-%d')] = (
                    self.daily_pnl.get(timestamp.strftime('%Y-%m-%d'), 0) + pnl
                )
                logger.info(f"Strategy #{self.strategy_id} - Sell: Position #{position['position_id']}, Entry=${entry_price:.2f}, Exit=${price_with_slippage:.2f}, Shares={shares:.2f}, PnL=${pnl:.2f}, Balance After=${self.balance:.2f}")

            trade['balance_after'] = self.balance
            if row is not None:
                trade.update(row.to_dict())
            self.trade_history.append(trade)
            self.backtest_data.append(trade)
            return trade
        except Exception as e:
            logger.error(f"Strategy #{self.strategy_id} trade execution failed: {str(e)}", exc_info=True)
            return None

    def compute_pca_zscores(self, df, row):
        config = self.mode_config[self.mode]
        if self.mode != 'pca_stat_arb':
            return 0.0
        
        days = int(GlobalConfig.durationStr.replace(' D', ''))
        bars_per_day = {'5 mins': 78, '15 mins': 26, '30 mins': 13, '1 hour': 6.5}
        bars_per_day = bars_per_day.get(self.timeframe, 78)
        lookback = int(days * bars_per_day)
        
        if len(df) < lookback:
            return 0.0
        
        history = df.iloc[-lookback:].copy()
        history['returns'] = history['close'].pct_change().fillna(0)
        
        pca = PCA(n_components=1)
        factors = pca.fit_transform(history[['returns']])
        
        X = sm.add_constant(factors)
        model = sm.OLS(history['close'], X).fit()
        residuals = model.resid
        
        zscore = (residuals.iloc[-1] - residuals.mean()) / residuals.std()
        return zscore
    
# =====================
# CONDITION CHECKS
# =====================
def check_exit_conditions(df, index, engine, row):
    if str(index.tz) != 'America/New_York':
        raise ValueError(f"Invalid timezone in exit check: {index.tz}")
    
    if not engine.current_positions:
        return None
    
    try:
        config = engine.mode_config[engine.mode]
        conditions = config['exit_conditions']
        current_time = enforce_ny_timezone(index)
        current_price = row['close']
        meanrange = row.get('meanrange_shifted', 0) or 1
        
        for pos in engine.current_positions[:]:
            entry_time = pos['entry_time']
            entry_price = pos['entry_price']
            logger.debug(f"Checking exit for Pos #{pos['position_id']} at {index}: Entry=${entry_price:.2f}, Current=${current_price:.2f}")
            for condition_name, params in conditions.items():
                if condition_name == 'mean_reversion':
                    if engine.mode == 'bollinger_reversion':
                        bollinger_std_shifted = row.get('bollinger_std_shifted', 0) or 1
                        deviation = (current_price - row.get('bollinger_mid_shifted', current_price)) / bollinger_std_shifted
                        if abs(deviation) < abs(params['threshold']):
                            logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: Deviation={deviation:.2f} < {params['threshold']}")
                            return f'Bollinger Mean Reversion (Pos #{pos["position_id"]})'
                    else:
                        deviation = (current_price - row.get('meanline', current_price)) / meanrange
                        if deviation > params['threshold']:
                            logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: Deviation={deviation:.2f} > {params['threshold']}")
                            return f'Mean Reversion (Pos #{pos["position_id"]})'
                    logger.debug(f"No {condition_name} exit for Pos #{pos['position_id']}: Deviation={deviation:.2f}")
                elif condition_name == 'stop_loss':
                    deviation = (current_price - entry_price) / entry_price  # Decimal form
                    if deviation < params['threshold']:  # e.g., -0.015 for -1.5%
                        logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: Deviation={deviation:.2%} < {params['threshold']:.2%}")
                        return f'Stop Loss (Pos #{pos["position_id"]})'
                    logger.debug(f"No {condition_name} exit for Pos #{pos['position_id']}: Deviation={deviation:.2%}")
                elif condition_name == 'trailing_stop':
                    if 'highest_price' not in pos:
                        pos['highest_price'] = entry_price
                    pos['highest_price'] = max(pos['highest_price'], current_price)
                    atr = row.get('ATR_shifted', 0) or 1
                    stop_level = pos['highest_price'] - (atr * params['atr_multiplier'])
                    if current_price <= stop_level:
                        logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: Price={current_price:.2f} <= Stop={stop_level:.2f}")
                        return f'Trailing Stop ({params["atr_multiplier"]}x ATR, Pos #{pos["position_id"]})'
                    logger.debug(f"No {condition_name} exit for Pos #{pos['position_id']}: Price={current_price:.2f}, Stop={stop_level:.2f}")
                elif condition_name == 'signal_score':
                    score = engine.composite_signal_score(row)
                    if score >= params['threshold']:
                        logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: Score={score:.2f} >= {params['threshold']}")
                        return f'Signal Score (Pos #{pos["position_id"]})'
                    logger.debug(f"No {condition_name} exit for Pos #{pos['position_id']}: Score={score:.2f}")
                elif condition_name == 'zscore_reversion':
                    zscore = engine.compute_pca_zscores(df, row)
                    if zscore > params['threshold']:
                        logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: Z-Score={zscore:.2f} > {params['threshold']}")
                        return f'Z-Score Reversion (Pos #{pos["position_id"]})'
                    logger.debug(f"No {condition_name} exit for Pos #{pos['position_id']}: Z-Score={zscore:.2f}")
                elif condition_name == 'rsi_reversion':
                    rsi = row.get('RSI_shifted', 50)
                    if rsi > params['threshold']:
                        logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: RSI={rsi:.2f} > {params['threshold']}")
                        return f'RSI Reversion (Pos #{pos["position_id"]})'
                    logger.debug(f"No {condition_name} exit for Pos #{pos['position_id']}: RSI={rsi:.2f}")
                elif condition_name == 'profit_target':
                    profit = (current_price - entry_price) / entry_price  # Decimal form
                    if profit >= params['threshold']:  # e.g., 0.0225 for 2.25%
                        logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: Profit={profit:.2%} >= {params['threshold']:.2%}")
                        return f'Profit Target (Pos #{pos["position_id"]})'
                    logger.debug(f"No {condition_name} exit for Pos #{pos['position_id']}: Profit={profit:.2%}")
        
        return None
    
    except Exception as e:
        logger.error(f"Strategy #{engine.strategy_id} - Error in exit check at {index}: {str(e)}", exc_info=True)
        return None

def check_all_entry_conditions(df, index, engines, row):
    if str(index.tz) != 'America/New_York':
        raise ValueError(f"Invalid timezone in entry check: {index.tz}")
    
    conditions_results = {}
    log_details = [f"Unified Entry Check at {index}"]
    
    all_conditions = set()
    for engine in engines.values():
        all_conditions.update(engine.mode_config[engine.mode]['entry_conditions'].keys())
    
    try:
        meanline = row['meanline']
        meanrange = max(row['meanrange_shifted'], 1e-6)  # Avoid zero division
        volatility = row['ATR_shifted'] / row['close'] if row['close'] > 0 else float('inf')
        
        if row['meanrange_shifted'] <= 0:
            logger.warning(f"Meanrange_shifted <= 0 at {index}, using epsilon: {row['meanrange_shifted']}")
        
        # Detect market regime
        regime = detect_market_regime(row)
        conditions_results['regime'] = regime
        log_details.append(f"Regime: {regime}")
        
        # Only proceed if mean-reverting regime
        if regime != 'mean_reverting':
            log_details.append("Skipping: Not a mean-reverting regime")
            logger.debug(" | ".join(log_details))
            return conditions_results
        
        if 'mean_deviation' in all_conditions:
            deviation = (row['close'] - meanline) / meanrange
            conditions_results['mean_deviation'] = deviation
            log_details.append(f"Mean Deviation: {deviation:.2f}")
        
        if 'rsi' in all_conditions:
            rsi_value = row['RSI_shifted']
            conditions_results['rsi'] = rsi_value
            log_details.append(f"RSI: {rsi_value:.2f}")
        
        if 'williams_r' in all_conditions:
            williams_value = row['Williams_%R_shifted']
            conditions_results['williams_r'] = williams_value
            log_details.append(f"Williams %R: {williams_value:.2f}")
        
        if 'atr_breakout' in all_conditions:
            prev_high = df.loc[:index, 'high'].iloc[-2] if len(df.loc[:index]) > 1 else row['high']
            breakout_level = prev_high + row['ATR_shifted']
            atr_breakout = row['close'] > breakout_level
            conditions_results['atr_breakout'] = {'value': row['close'] - breakout_level, 'base_level': breakout_level}
            log_details.append(f"ATR Breakout Base: Close={row['close']:.2f}, Base Level={breakout_level:.2f}")
        
        if 'zscore' in all_conditions:
            for strat_id, engine in engines.items():
                if engine.mode == 'pca_stat_arb':
                    zscore = engine.compute_pca_zscores(df, row)
                    conditions_results['zscore'] = zscore
                    log_details.append(f"PCA Z-Score: {zscore:.2f}")
                    break
        
        if 'bollinger_zscore' in all_conditions:
            zscore = row['bollinger_zscore_shifted']
            conditions_results['bollinger_zscore'] = zscore
            log_details.append(f"Bollinger Z-Score: {zscore:.2f}")
        
        if 'price_divergence' in all_conditions:
            divergence = row['price_divergence_shifted']
            conditions_results['price_divergence'] = divergence
            log_details.append(f"Price Divergence: {divergence:.4f}")
        
        if 'volume' in all_conditions:
            volume_condition = row['volume'] / row['volume_ma_shifted'] if row['volume_ma_shifted'] > 0 else 0
            conditions_results['volume'] = volume_condition
            log_details.append(f"Volume Ratio: {volume_condition:.2f}")
        
        # Updated position_ok: Only check balance, no position limit
        conditions_results['position_ok'] = {strat_id: engine.balance > 1000 
                                            for strat_id, engine in engines.items()}
        conditions_results['time_ok'] = not is_market_close(index)
        log_details.append(f"Time OK: {conditions_results['time_ok']}")
        
        logger.debug(" | ".join(log_details))
        return conditions_results
    
    except Exception as e:
        logger.error(f"Error in unified entry check at {index}: {str(e)}", exc_info=True)
        return {}

def evaluate_strategy_entry(strat_id, engine, conditions_results, row):
    config = engine.mode_config[engine.mode]
    conditions = config['entry_conditions']
    total_conditions = len(conditions) + 3  # +3 for position_ok, time_ok, and price check
    conditions_met = 0
    
    log_details = [f"Strategy #{strat_id} Eval at {row.name}"]
    
    # Check price validity first
    current_price = row['close']
    price_valid = is_price_valid(current_price)
    conditions_met += 1 if price_valid else 0
    log_details.append(f"Price Valid (${current_price:.2f}): {price_valid}")
    if not price_valid:
        logger.debug(f"Strategy #{strat_id}: Price ${current_price:.2f} outside allowed range "
                    f"(${GlobalConfig.MIN_PRICE}-${GlobalConfig.MAX_PRICE})")
    
    for condition_name, params in conditions.items():
        if condition_name not in conditions_results:
            continue
        value = conditions_results.get(condition_name)
        condition_met = False
        
        # Ensure threshold is a scalar
        threshold = params['threshold'] if isinstance(params['threshold'], (int, float)) else params['threshold'][0]
        
        if condition_name == 'mean_deviation':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'rsi':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'williams_r':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'volume':
            condition_met = value > threshold if not pd.isna(value) else False
        elif condition_name == 'zscore':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'bollinger_zscore':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'price_divergence':
            condition_met = value < threshold if not pd.isna(value) else False
        
        conditions_met += 1 if condition_met else 0
        log_details.append(f"{condition_name}: Met={condition_met} (Value={value}, Threshold={threshold})")
    
    position_ok = conditions_results.get('position_ok', {}).get(strat_id, False)
    time_ok = conditions_results.get('time_ok', False)
    conditions_met += 1 if position_ok else 0
    conditions_met += 1 if time_ok else 0
    
    fraction_met = conditions_met / total_conditions
    log_details.append(f"Fraction Met: {conditions_met}/{total_conditions} ({fraction_met:.2%})")
    logger.debug(" | ".join(log_details))
    
    return fraction_met >= 0.75

# =====================
# DATA AND INDICATORS
# =====================
def log_trade(trade):
    strategy_id = trade['strategy_id']
    timestamp = pd.to_datetime(trade['timestamp']).tz_convert('America/New_York')
    log_parts = [
        f"#[{strategy_id}] {trade['action'].ljust(6)} | {GlobalConfig.symbol.ljust(5)}",
        f"Time:  {timestamp.strftime('%Y-%m-%d %H:%M:%S%z')}",
        f"Price: ${trade['price']:7.2f}",
        f"Size:  ${trade['position_value']:7.2f}",
        f"Shares: {trade['shares']:>6.2f}"
    ]
    if trade['action'] == 'SELL':
        if 'pnl' not in trade or trade['pnl'] is None:
            logger.error(f"Trade missing PnL: {trade}")
            trade['pnl'] = 0.0
        log_parts.extend([
            f"PnL:   ${trade['pnl']:7.2f}",
            f"Return: {trade['pnl_pct']:6.2f}%",
            f"Exit:  {trade['exit_type']}"
        ])
        logger.info(f"Trade PnL Validation: {trade['pnl']:.2f} for Position #{trade['position_id']}")
    logger.info(" | ".join(log_parts))

def calculate_mrc_with_gradient(df, length=50, gradient_levels=GlobalConfig.gradient_levels, outer_levels=GlobalConfig.outer_levels):
    # Work with a copy to avoid SettingWithCopyWarning
    df = df.copy()
    
    if 'hlc3' not in df.columns:
        df['hlc3'] = (df['high'] + df['low'] + df['close']) / 3

    df['prev_close'] = df['close'].shift(1).ffill()
    df['tr1'] = df['high'] - df['low']
    df['tr2'] = abs(df['high'] - df['prev_close'])
    df['tr3'] = abs(df['low'] - df['prev_close'])
    df['tr'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)
    df.drop(['tr1', 'tr2', 'tr3', 'prev_close'], axis=1, inplace=True, errors='ignore')
    tr_mean = df['tr'].mean()
    tr_std = df['tr'].std()
    if tr_std > 0:
        df['tr'] = df['tr'].clip(tr_mean - 3 * tr_std, tr_mean + 3 * tr_std)

    df['meanline'] = supersmoother(df['hlc3'], length, apply_savgol=False).replace([np.inf, -np.inf, np.nan], np.nan).ffill().bfill()
    df['meanrange'] = df['tr'].rolling(10, min_periods=1).mean().replace([np.inf, -np.inf, np.nan], 0).ffill().bfill()
    meanrange_mean = df['meanrange'].mean()
    meanrange_std = df['meanrange'].std()
    if meanrange_std > 0:
        df['meanrange'] = df['meanrange'].clip(meanrange_mean - 3 * meanrange_std, meanrange_mean + 3 * meanrange_std)

    for level in gradient_levels:
        df[f'upband_{level}'] = df['meanline'] + (df['meanrange'] * level)
        df[f'loband_{level}'] = df['meanline'] - (df['meanrange'] * level)
        df[f'upband_{level}_shifted'] = df[f'upband_{level}'].shift(1).ffill().bfill()
        df[f'loband_{level}_shifted'] = df[f'loband_{level}'].shift(1).ffill().bfill()

    outer_multiples = {'weak': 3.0, 'moderate': 3.5, 'strong': 4.0}
    for level_name in outer_levels:
        multiple = outer_multiples[level_name]
        df[f'upband_{level_name}'] = df['meanline'] + (df['meanrange'] * multiple)
        df[f'loband_{level_name}'] = df['meanline'] - (df['meanrange'] * multiple)

    df['meanrange_shifted'] = df['meanrange'].shift(1).ffill().bfill()
    return df

def supersmoother(src: pd.Series, length: int = 50, apply_savgol: bool = False) -> pd.Series:
    if len(src) < 3 or length < 1:
        return src.ffill().bfill()
    
    src_clean = src.copy()
    mean_val = src_clean.mean()
    std_val = src_clean.std()
    if std_val > 0:
        src_clean = src_clean.clip(mean_val - 3 * std_val, mean_val + 3 * std_val)

    a1 = np.exp(-np.sqrt(2) * np.pi / length)
    b1 = 2 * a1 * np.cos(np.sqrt(2) * np.pi / length)
    c3 = -a1**2
    c2 = b1
    c1 = 1 - c2 - c3
    
    ss = np.zeros_like(src_clean, dtype=float)
    ss[0] = src_clean.iloc[0] if not pd.isna(src_clean.iloc[0]) else 0
    ss[1] = src_clean.iloc[1] if not pd.isna(src_clean.iloc[1]) else ss[0]
    for i in range(2, len(src_clean)):
        ss[i] = c1 * (src_clean.iloc[i] if not pd.isna(src_clean.iloc[i]) else ss[i-1]) + c2 * ss[i-1] + c3 * ss[i-2]
    
    result = pd.Series(ss, index=src_clean.index).replace([np.inf, -np.inf, np.nan], np.nan).ffill().bfill()
    
    if apply_savgol and len(result) >= 5:
        window_length = 5 if len(result) >= 5 else len(result)
        if window_length % 2 == 0:
            window_length += 1
        polyorder = 1
        try:
            result = pd.Series(savgol_filter(result, window_length=window_length, polyorder=polyorder), index=result.index)
        except ValueError as e:
            logger.warning(f"Savitzky-Golay filter failed: {str(e)}. Using raw supersmoother result.")
    
    if result.isna().any():
        result = result.interpolate(method='linear', limit=2).ffill().bfill()
    
    return result

def williams_r(high, low, close, lookback=14):
    highest_high = high.rolling(window=lookback, min_periods=1).max()
    lowest_low = low.rolling(window=lookback, min_periods=1).min()
    denominator = highest_high - lowest_low
    denominator = denominator.replace(0, np.nan)
    wr = -100 * ((highest_high - close) / denominator)
    return wr.fillna(-50).replace([np.inf, -np.inf], -50)

def stochastic_oscillator(df, k_period=14, d_period=3):
    low_min = df['low'].rolling(k_period).min()
    high_max = df['high'].rolling(k_period).max()
    df['%K'] = 100 * ((df['close'] - low_min) / (high_max - low_min))
    df['%K'] = df['%K'].fillna(50)
    df['%D'] = df['%K'].rolling(d_period).mean()
    return df

def calculate_point_in_time_indicators(df, index):
    try:
        row = df.loc[index].copy()
        for col in ['open', 'high', 'low', 'close', 'volume', 'hlc3', 'tr']:
            if col in row:
                row[col] = pd.to_numeric(row[col], errors='coerce')
        return row
    except KeyError:
        logger.warning(f"No data available at index {index}")
        return pd.Series()

def calculate_buy_and_hold(df, initial_balance=GlobalConfig.initial_balance, fee_per_share=0.0035):
    """Calculate Buy & Hold performance: buy at period start, sell at period end."""
    try:
        if df.empty or 'close' not in df.columns:
            logger.error("Invalid DataFrame for Buy & Hold calculation")
            return None

        # Ensure timezone consistency
        df = ensure_ny_timezone(df.copy())
        
        # Get first and last prices
        buy_price = df['close'].iloc[0]
        sell_price = df['close'].iloc[-1]
        
        # Calculate shares (whole shares only, accounting for fees)
        shares = max(1, round((initial_balance - (initial_balance * fee_per_share)) / buy_price, 0))
        buy_cost = shares * buy_price + (shares * fee_per_share)
        sell_value = shares * sell_price - (shares * fee_per_share)
        
        # Calculate PnL
        total_pnl = sell_value - buy_cost
        pnl_pct = (total_pnl / buy_cost) * 100 if buy_cost > 0 else 0.0
        
        # Simulate trade history for metrics compatibility
        trade_history = [
            {
                'strategy_id': 'buy_and_hold',
                'timestamp': df.index[0],
                'action': 'BUY',
                'price': buy_price,
                'shares': shares,
                'position_value': shares * buy_price,
                'pnl': 0.0,
                'entry_time': df.index[0]
            },
            {
                'strategy_id': 'buy_and_hold',
                'timestamp': df.index[-1],
                'action': 'SELL',
                'price': sell_price,
                'shares': shares,
                'position_value': shares * sell_price,
                'pnl': total_pnl,
                'pnl_pct': pnl_pct,
                'entry_time': df.index[0],
                'exit_type': 'End of Period'
            }
        ]
        
        metrics = calculate_day_metrics(trade_history)
        logger.info(f"Buy & Hold - Buy Price: ${buy_price:.2f}, Sell Price: ${sell_price:.2f}, Shares: {shares}, PnL: ${total_pnl:.2f}")
        return {'metrics': metrics, 'final_balance': initial_balance + total_pnl}
    except Exception as e:
        logger.error(f"Error in Buy & Hold calculation: {str(e)}", exc_info=True)
        return None

def get_historical_data(ib, timeframe, exchange='SMART', currency='USD', backtest=False):
    max_retries = 3
    try:
        contract = Stock(GlobalConfig.symbol, exchange, currency)
        ib.qualifyContracts(contract)
        if backtest:
            logger.info(f"Requesting historical data for {GlobalConfig.symbol} at {timeframe}")
            for attempt in range(max_retries):
                try:
                    bars = ib.reqHistoricalData(
                        contract,
                        endDateTime='',
                        durationStr=GlobalConfig.durationStr,
                        barSizeSetting=timeframe,
                        whatToShow='TRADES',
                        useRTH=True,
                        formatDate=2,
                        keepUpToDate=False
                    )
                    if not bars:
                        raise ValueError("No data received from IBKR")
                    break
                except Exception as e:
                    logger.error(f"Attempt {attempt + 1} failed for {timeframe}: {str(e)}")
                    if attempt == max_retries - 1:
                        logger.error(f"Failed to fetch data for {timeframe} after {max_retries} attempts")
                        return None
                    sleep(2)

            df = util.df(bars)
            if df.empty:
                logger.error(f"Empty DataFrame received from IBKR for {timeframe}")
                return None

            df['date'] = pd.to_datetime(df['date'], utc=True)
            df.set_index('date', inplace=True)
            df.index = df.index.tz_convert('America/New_York')

            required_cols = ['open', 'high', 'low', 'close', 'volume']
            for col in required_cols:
                if col not in df.columns:
                    logger.error(f"Missing required column for {timeframe}: {col}")
                    return None
                df[col] = pd.to_numeric(df[col], errors='coerce')
                if df[col].isna().all():
                    logger.error(f"Column {col} contains only NaN values for {timeframe}")
                    return None
                col_mean = df[col].mean()
                col_std = df[col].std()
                if col_std > 0:
                    df[col] = df[col].clip(col_mean - 3 * col_std, col_mean + 3 * col_std)
                df[col] = df[col].interpolate(method='linear', limit=2).ffill().bfill()

            df['hlc3'] = (df['high'] + df['low'] + df['close']) / 3
            df['tr'] = df[['high', 'low', 'close']].apply(
                lambda x: max(x['high'] - x['low'],
                              abs(x['high'] - df['close'].shift().bfill().loc[x.name]),
                              abs(x['low'] - df['close'].shift().bfill().loc[x.name])), axis=1)
            return df
        return None
    except Exception as e:
        logger.error(f"Error in get_historical_data for {timeframe}: {str(e)}", exc_info=True)
        return None

def calculate_adx(df, window=14):
    high = df['high']
    low = df['low']
    close = df['close']
    tr = np.maximum(high - low, np.maximum(np.abs(high - close.shift().bfill()), np.abs(low - close.shift().bfill())))
    up_move = high.diff()
    down_move = -low.diff()
    tr_smooth = tr.ewm(alpha=1/window, adjust=False).mean()
    plus_dm = up_move.where((up_move > down_move) & (up_move > 0), 0.0)
    minus_dm = down_move.where((down_move > up_move) & (down_move > 0), 0.0)
    plus_di = 100 * (plus_dm.ewm(alpha=1/window, adjust=False).mean() / tr_smooth)
    minus_di = 100 * (minus_dm.ewm(alpha=1/window, adjust=False).mean() / tr_smooth)
    di_diff = np.abs(plus_di - minus_di)
    di_sum = (plus_di + minus_di).replace(0, 1e-8)
    dx = 100 * (di_diff / di_sum)
    adx = dx.ewm(alpha=1/window, adjust=False).mean().clip(0, 100)
    df['adx'] = adx
    df['+di'] = plus_di
    df['-di'] = minus_di
    df['adx_shifted'] = adx.shift(1).fillna(0)
    return df

def calculate_rsi(close, period=14):
    delta = close.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss.replace(0, np.inf)
    return 100 - (100 / (1 + rs)).fillna(50)

def calculate_bollinger_bands(df, window=20, num_std=2):
    # Ensure we're working with a copy to avoid SettingWithCopyWarning
    df = df.copy()
    
    # Calculate Bollinger Bands
    df['bollinger_mid'] = df['close'].rolling(window=window, min_periods=1).mean()
    df['bollinger_std'] = df['close'].rolling(window=window, min_periods=1).std()
    df['bollinger_upper'] = df['bollinger_mid'] + (df['bollinger_std'] * num_std)
    df['bollinger_lower'] = df['bollinger_mid'] - (df['bollinger_std'] * num_std)
    df['bollinger_zscore'] = (df['close'] - df['bollinger_mid']) / df['bollinger_std'].replace(0, np.nan).fillna(0)
    
    # Shift all Bollinger-related columns
    shifted_cols = ['bollinger_mid', 'bollinger_std', 'bollinger_upper', 'bollinger_lower', 'bollinger_zscore']
    for col in shifted_cols:
        df[f'{col}_shifted'] = df[col].shift(1).fillna(df[col].iloc[0] if not df[col].empty else 0)
    
    return df

'''def plot_candlestick(df, bar_size, backtest=False):
    if df is None or df.empty:
        logger.error(f"Cannot plot: DataFrame is None or empty for {bar_size}")
        return

    required_cols = ['open', 'high', 'low', 'close', 'volume', 'meanline'] + \
                    [f'upband_{level}' for level in GlobalConfig.gradient_levels] + \
                    [f'loband_{level}' for level in GlobalConfig.gradient_levels]

    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        logger.error(f"Missing required columns for {bar_size}: {missing_cols}")
        return

    for col in required_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').replace([np.inf, -np.inf], np.nan).ffill().bfill()
        if df[col].isna().all():
            logger.error(f"Column {col} contains only NaN values after processing for {bar_size}")
            return

    if df.index.tz != pytz.timezone('America/New_York'):
        df.index = df.index.tz_convert('America/New_York')
    df = df.sort_index()

    style = mpf.make_mpf_style(
        base_mpf_style='classic',
        marketcolors=mpf.make_marketcolors(up='#00FF00', down='#FF0000', edge='black', wick='black', volume='gray'),
        gridstyle=':', gridcolor='gray', facecolor='white'
    )

    addplots = []
    panels_used = set()

    if 'volume' in df.columns and not df['volume'].isna().all():
        addplots.append(mpf.make_addplot(df['volume'], panel=1, type='bar', color='gray', ylabel='Volume'))
        panels_used.add(1)

    num_panels = 1 + len(panels_used)
    panel_ratios = [10] + [3] * len(panels_used)

    try:
        fig, axlist = mpf.plot(
            df[['open', 'high', 'low', 'close']],
            type='candle',
            style=style,
            addplot=addplots,
            volume=False,
            panel_ratios=tuple(panel_ratios),
            figsize=(20, 8 + 2 * len(panels_used)),
            title=f'{GlobalConfig.symbol} Candlestick Chart - {bar_size} (Backtest: {backtest})',
            returnfig=True,
            datetime_format='%Y-%m-%d %H:%M'
        )

        plot_mrc_gradient(axlist[0], df, bar_size)

        for ax in axlist:
            ax.set_facecolor('white')
            ax.grid(True, color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
            ax.tick_params(colors='black', labelsize=8)
            ax.xaxis.set_major_formatter(DateFormatter('%H:%M'))
            ax.set_xlim(df.index[0], df.index[-1])

        y_min = min(df['low'].min(), df[[f'loband_{level}' for level in GlobalConfig.gradient_levels]].min().min()) * 0.95
        y_max = max(df['high'].max(), df[[f'upband_{level}' for level in GlobalConfig.gradient_levels]].max().max()) * 1.05
        axlist[0].set_ylim(y_min, y_max)

        fig.set_facecolor('white')
        plt.tight_layout(pad=2.0)
        plt.show()
    except Exception as e:
        logger.error(f"Failed to plot candlestick chart for {bar_size}: {str(e)}", exc_info=True)

def plot_mrc_gradient(ax, df, time_frame):
    meanline = supersmoother(df['hlc3'], length=200, apply_savgol=True).replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
    if meanline.empty or meanline.isna().all():
        logger.error(f"Meanline data is empty or contains only NaN values for {time_frame}")
        return

    ax.plot(df.index, meanline, color='purple', linestyle='-', linewidth=2.5, zorder=15, label='Meanline (Supersmoother)', 
            path_effects=[pe.Stroke(linewidth=3.5, foreground='purple', alpha=0.3), pe.Normal()], 
            antialiased=True)

    norm = Normalize(vmin=min(GlobalConfig.gradient_levels), vmax=max(GlobalConfig.gradient_levels))
    price_min = df['low'].quantile(0.05)
    price_max = df['high'].quantile(0.95)

    num_points = len(df.index)
    for i, level in enumerate(GlobalConfig.gradient_levels):
        upper_band = df[f'upband_{level}'].replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
        lower_band = df[f'loband_{level}'].replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
        color = mrc_cmap(norm(level))

        upper_band = np.clip(upper_band, price_min, price_max)
        lower_band = np.clip(lower_band, price_min, price_max)

        upper_band_interpolated = np.interp(np.linspace(0, len(upper_band)-1, num_points), np.arange(len(upper_band)), upper_band)
        lower_band_interpolated = np.interp(np.linspace(0, len(lower_band)-1, num_points), np.arange(len(lower_band)), lower_band)
        meanline_interpolated = np.interp(np.linspace(0, len(meanline)-1, num_points), np.arange(len(meanline)), meanline)

        if i == 0:
            ax.fill_between(df.index, meanline_interpolated, upper_band_interpolated, color=color, alpha=0.5, zorder=2 + i, label=f'Level {level}', 
                            interpolate=True)
            ax.fill_between(df.index, meanline_interpolated, lower_band_interpolated, color=color, alpha=0.5, zorder=2 + i, 
                            interpolate=True)
        else:
            prev_level = GlobalConfig.gradient_levels[i - 1]
            prev_upper_band = df[f'upband_{prev_level}'].replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
            prev_lower_band = df[f'loband_{prev_level}'].replace([np.inf, -np.inf, np.nan, 0], np.nan).ffill().bfill()
            prev_upper_band = np.clip(prev_upper_band, price_min, price_max)
            prev_lower_band = np.clip(prev_lower_band, price_min, price_max)
            prev_upper_band_interpolated = np.interp(np.linspace(0, len(prev_upper_band)-1, num_points), np.arange(len(prev_upper_band)), prev_upper_band)
            prev_lower_band_interpolated = np.interp(np.linspace(0, len(prev_lower_band)-1, num_points), np.arange(len(prev_lower_band)), prev_lower_band)

            ax.fill_between(df.index, prev_upper_band_interpolated, upper_band_interpolated, color=color, alpha=0.5, zorder=2 + i, label=f'Level {level}', 
                            interpolate=True)
            ax.fill_between(df.index, prev_lower_band_interpolated, lower_band_interpolated, color=color, alpha=0.5, zorder=2 + i, 
                            interpolate=True)

    ax.legend(loc='upper left', fontsize=8, bbox_to_anchor=(0, 1))
    ax.set_ylim(price_min * 0.95, price_max * 1.05)
    ax.set_xlim(df.index[0], df.index[-1])'''

def print_backtest_report(metrics, bar_size, strategy_name):
    print(f"\n=== {strategy_name} Performance Report - {bar_size} ===")
    print("\nOverall Metrics:")
    for key, value in metrics['overall'].items():
        print(f"  {key.replace('_', ' ').title()}: {value if value != float('inf') else 'âˆž'}")

    print("\nPerformance by Exit Strategy:")
    for strategy, stats in metrics['by_exit_strategy'].items():
        print(f"  {strategy}:")
        for key, value in stats.items():
            print(f"    {key.replace('_', ' ').title()}: {value if value != float('inf') else 'âˆž'}")

    print("\nHolding Periods (hours):")
    print(f"  Winning Trades: {metrics['holding_periods']['winning']}")
    print(f"  Losing Trades: {metrics['holding_periods']['losing']}")
    print("  By Exit Strategy:")
    for strategy, hours in metrics['holding_periods']['by_exit_strategy'].items():
        print(f"    {strategy}: {hours}")

    print("\nVolatility Metrics:")
    print(f"  Average ATR: {metrics['volatility']['avg_atr']}")
    print(f"  PnL-Volatility Correlation: {metrics['volatility']['pnl_volatility_correlation']}")

def execute_entry(strategy_id, engine, price, timestamp, position_size, row):
    timestamp = enforce_ny_timezone(pd.to_datetime(timestamp))
    # Calculate shares with 2dp fractional precision
    shares = max(0.01, round(position_size / price, 2))  # Minimum 0.01 shares, 2dp precision
    if not np.isfinite(shares):
        logger.error(f"Strategy #{strategy_id}: Invalid share calculation: Shares={shares}")
        return None
    trade = engine.execute_trade(price=price, shares=shares, action='BUY', timestamp=timestamp, row=row)
    if trade:
        log_trade(trade)
    return trade

def execute_exit(strategy_id, engine, price, timestamp, exit_type, row):
    if not engine.current_positions:
        logger.warning(f"Strategy #{strategy_id}: Exit attempted with no positions")
        return None
    timestamp = enforce_ny_timezone(pd.to_datetime(timestamp))
    if not exit_type or 'Pos #' not in exit_type:
        logger.error(f"Strategy #{strategy_id}: Invalid exit_type format: {exit_type}")
        return None
    pos_id = int(exit_type.split('Pos #')[1].strip(')'))
    position = next((p for p in engine.current_positions if p['position_id'] == pos_id), None)
    if not position:
        logger.warning(f"Strategy #{strategy_id}: Position #{pos_id} not found for exit")
        return None
    exit_shares = position['shares']
    trade = engine.execute_trade(price=price, shares=exit_shares, action='SELL', timestamp=timestamp, exit_type=exit_type, row=row)
    if trade:
        log_trade(trade)
    else:
        logger.error(f"Strategy #{strategy_id}: Failed to execute exit trade for Pos #{pos_id}")
    return trade

def run_backtest(df, timeframe, collect_non_trades=False, single_strategy=None):
    try:
        if df is None or df.empty:
            logger.error(f"Invalid input data for backtest at {timeframe}")
            return None, None

        logger.info(f"Starting optimized backtest for {timeframe} with data shape: {df.shape}")

        # Calculate MRC with gradient
        df = calculate_mrc_with_gradient(df)
        df['ATR'] = df['tr'].rolling(14, min_periods=1).mean().fillna(0)
        df = calculate_adx(df)
        df = stochastic_oscillator(df)
        df['VWAP'] = (df['hlc3'] * df['volume']).groupby(df.index.date).cumsum() / df['volume'].groupby(df.index.date).cumsum().fillna(df['close'])
        exp12 = df['close'].ewm(span=12, adjust=False).mean()
        exp26 = df['close'].ewm(span=26, adjust=False).mean()
        df['MACD'] = exp12 - exp26
        df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
        df['Histogram'] = df['MACD'] - df['Signal']
        df['RSI'] = calculate_rsi(df['close']).fillna(50)
        df['Williams_%R'] = williams_r(df['high'], df['low'], df['close']).fillna(-50)
        df['volume_ma'] = df['volume'].rolling(20, min_periods=1).mean().fillna(df['volume'].mean())
        
        # Calculate Bollinger Bands (kept for potential future use)
        df = calculate_bollinger_bands(df)
        
        # Calculate price divergence (kept for potential future use)
        df['price_change'] = df['close'].pct_change()
        df['price_divergence_shifted'] = df['price_change'].shift(1).fillna(0)
        
        # Shift relevant columns
        shifted_cols = ['close', 'RSI', 'Williams_%R', 'VWAP', 'MACD', 'Signal', 'Histogram', 'adx', '+di', '-di', '%K', '%D', 'volume_ma', 'ATR', 'meanrange', 
                        'bollinger_mid', 'bollinger_upper', 'bollinger_lower', 'bollinger_zscore', 'bollinger_std']
        for col in shifted_cols:
            if col in df.columns:
                df[f'{col}_shifted'] = df[col].shift(1).fillna(df[col].iloc[0] if not df[col].empty else 0)

        if single_strategy:
            if single_strategy not in GlobalConfig.STRATEGIES:
                logger.error(f"Invalid single_strategy ID: {single_strategy}")
                return None, None
            mode = GlobalConfig.STRATEGIES[single_strategy]
            engines = {single_strategy: BacktestEngine(single_strategy, mode, timeframe)}
        else:
            engines = {
                'A': BacktestEngine('A', 'time_based', timeframe),
                'B': BacktestEngine('B', 'pca_stat_arb', timeframe)
            }

        required_cols = ['open', 'high', 'low', 'close', 'volume', 'hlc3', 'tr', 'meanline', 'meanrange_shifted'] + [f'{col}_shifted' for col in shifted_cols]
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            logger.error(f"Missing required columns for {timeframe}: {missing_cols}")
            return None, None

        last_rebalance = None
        for index, _ in df.iterrows():
            if pd.isna(index):
                logger.debug(f"Skipping index with NaN timestamp at {timeframe}")
                continue
                
            if not is_market_close(index):
                row = calculate_point_in_time_indicators(df, index)
                logger.debug(f"Row data at {index}: {row.to_dict()}")
                
                if not is_price_valid(row['close']):
                    logger.warning(f"Backtest at {timeframe}: Price ${row['close']:.2f} outside allowed range "
                                  f"(${GlobalConfig.MIN_PRICE}-${GlobalConfig.MAX_PRICE}) at {index}")
                    continue
                
                if '3' in engines:
                    if last_rebalance is None or (index - last_rebalance).days >= engines['3'].mode_config['pca_stat_arb']['rebalance_days']:
                        last_rebalance = index
                        logger.debug(f"Rebalance triggered for PCA Stat Arb at {index}")
                
                conditions_results = check_all_entry_conditions(df, index, engines, row)
                
                for strat_id, engine in engines.items():
                    if evaluate_strategy_entry(strat_id, engine, conditions_results, row):
                        position_size = engine.calculate_position_size(row)
                        if position_size > 0:
                            trade = execute_entry(strat_id, engine, row['close'], index, position_size, row)
                            if trade is None:
                                logger.warning(f"Strategy #{strat_id}: Trade entry failed at {index}")
                            else:
                                logger.info(f"Entry trade executed for Strategy #{strat_id}: {trade}")
                    elif len(engine.current_positions) > 0:
                        exit_type = check_exit_conditions(df, index, engine, row)
                        if exit_type:
                            trade = execute_exit(strat_id, engine, row['close'], index, exit_type, row)
                            if trade:
                                logger.info(f"Exit trade executed for Strategy #{strat_id}: {trade}")
                            else:
                                logger.warning(f"Strategy #{strat_id}: Exit trade failed for {exit_type} at {index}")
                        else:
                            logger.debug(f"Strategy #{strat_id}: No exit condition met at {index}, Positions: {len(engine.current_positions)}")

        for strat_id, engine in engines.items():
            logger.info(f"Strategy #{strat_id} completed for {timeframe} - Trades: {len(engine.trade_history)}, Final Balance: ${engine.balance:.2f}")
            logger.info(f"Strategy #{strat_id} Trade History: {engine.trade_history}")
            if len(engine.trade_history) == 0:
                logger.warning(f"Strategy #{strat_id}: No trades recorded during backtest")
            else:
                sell_trades = [t for t in engine.trade_history if t['action'] == 'SELL']
                logger.info(f"Strategy #{strat_id} Sell Trades: {sell_trades}")
            
        return engines, df
    except Exception as e:
        logger.error(f"Error in run_backtest for {timeframe}: {str(e)}", exc_info=True)
        return None, None

# =====================
# MAIN EXECUTION
# =====================
def main():
    ib = IB()
    try:
        logger.info("Starting main execution with PCA, Time-Based, and Buy & Hold comparison")
        ib.connect('127.0.0.1', 7497, clientId=1)
        logger.info("Connected to IBKR")

        all_results = {}
        base_config = BacktestEngine('1', 'time_based', '5 mins').mode_config

        for timeframe in GlobalConfig.timeframes:
            logger.info(f"Processing timeframe: {timeframe}")
            daily_data = get_historical_data(ib, timeframe, backtest=True)
            if daily_data is None:
                logger.error(f"Failed to retrieve data for {timeframe}")
                continue
            if len(daily_data) < 2:
                logger.error(f"Insufficient data for {timeframe} (rows: {len(daily_data)}), need at least 2 for Buy & Hold")
                continue
            
            logger.info(f"GlobalConfig.STRATEGIES: {GlobalConfig.STRATEGIES}")

            # Hypertune only PCA and Time-Based
            tuned_engines = {}
            for mode in ['pca_stat_arb', 'time_based']:
                logger.info(f"Hypertuning {mode} for {timeframe}")
                result = hypertune_strategy(ib, timeframe, mode, base_config, num_trials=5)
                if result is None:
                    logger.error(f"Hyperparameter tuning for {mode} returned None, skipping")
                    continue
                best_params, best_metrics = result
                if best_params:
                    strategy_id = GlobalConfig.MODE_TO_ID[mode]
                    tuned_engine = BacktestEngine(strategy_id, mode, timeframe)
                    tuned_engine.mode_config[mode] = update_config(base_config, mode, best_params)
                    tuned_engines[strategy_id] = tuned_engine
                    if best_metrics is not None:
                        print_backtest_report(best_metrics, timeframe, f"Tuned {mode}")
                    else:
                        logger.warning(f"No metrics available for {mode} after tuning")

            # Run backtest with tuned PCA and Time-Based
            engines, daily_data = run_backtest(daily_data, timeframe)
            if engines is None:
                continue

            # Calculate metrics
            trade_histories = {strat_id: engine.trade_history for strat_id, engine in engines.items()}
            metrics = {}
            for strat_id, trades in trade_histories.items():
                # Map 'A' and 'B' to 'A/1' and 'B/2' to match STRATEGIES keys
                full_strat_id = 'A/1' if strat_id == 'A' else 'B/2' if strat_id == 'B' else strat_id
                strat_name = f"Strategy #{strat_id} ({GlobalConfig.STRATEGIES[full_strat_id]})"
                metrics[strat_name] = calculate_day_metrics(trades)
                print(f"\n=== {strat_name} Final Stats for {timeframe} TF ===")
                print(f"# of Trades: {len(trades)}")
                print(f"Final Balance: ${engines[strat_id].balance:.2f}")
                print_backtest_report(metrics[strat_name], timeframe, strat_name)

            # Check if trades occurred
            if not any(len(trades) > 0 for trades in trade_histories.values()):
                logger.error(f"No trades executed for any strategy in {timeframe}, skipping comparison")
                continue

            # Select PCA and Time-Based
            selected_strategies = {
                'A: Time-Based': metrics["Strategy #A (time_based)"],
                'B: PCA Stat Arb': metrics["Strategy #B (pca_stat_arb)"]
            }

            # Calculate Buy & Hold
            buy_hold_result = calculate_buy_and_hold(daily_data)
            if buy_hold_result:
                selected_strategies['Benchmark: Buy & Hold'] = buy_hold_result['metrics']
                print(f"\n=== Buy & Hold Final Stats for {timeframe} TF ===")
                print(f"# of Trades: 2 (Buy & Sell)")
                print(f"Final Balance: ${buy_hold_result['final_balance']:.2f}")
                print_backtest_report(buy_hold_result['metrics'], timeframe, "Buy & Hold")
            else:
                logger.warning(f"Buy & Hold calculation failed for {timeframe}")

            all_results[timeframe] = {
                'engines': engines,
                'metrics': selected_strategies,
                'data': daily_data
            }

        if all_results:
            print("\n=== Multi-Timeframe Backtest Summary ===")
            results_list = []
            for timeframe, result in all_results.items():
                for strat_name, strat_metrics in result['metrics'].items():
                    results_list.append({
                        'bar_size': timeframe,
                        'strategy': strat_name,
                        'total_pnl': strat_metrics['overall']['total_pnl'],
                        'sharpe_ratio': strat_metrics['overall']['sharpe_ratio'],
                        'profit_factor': strat_metrics['overall']['profit_factor'],
                        'num_trades': strat_metrics['overall']['num_trades'],
                        'win_rate': strat_metrics['overall']['win_rate'],
                        'max_drawdown': strat_metrics['overall']['max_drawdown'],
                        'avg_holding_hours': strat_metrics['overall']['avg_holding_hours']
                    })
            results_df = pd.DataFrame(results_list)
            if not results_df.empty:
                best_pnl = results_df.loc[results_df['total_pnl'].idxmax()]
                print(f"\nBest Total PnL: {best_pnl['strategy']} on {best_pnl['bar_size']}")
                print(f"  Total PnL: ${best_pnl['total_pnl']:.2f}")
                print(f"  Sharpe Ratio: {best_pnl['sharpe_ratio']:.2f}")
                print(f"  Profit Factor: {best_pnl['profit_factor']:.2f}")
                print(f"  Number of Trades: {best_pnl['num_trades']}")
                print(f"  Win Rate: {best_pnl['win_rate']:.2f}%")

                # Compare PCA, Time-Based, and Buy & Hold
                for timeframe, result in all_results.items():
                    print(f"\n=== A/B Test Comparison for {timeframe} ===")
                    for strat_name, strat_metrics in result['metrics'].items():
                        print(f"{strat_name}:")
                        print(f"  Total PnL: ${strat_metrics['overall']['total_pnl']:.2f}")
                        print(f"  Sharpe Ratio: {strat_metrics['overall']['sharpe_ratio']:.2f}")
                        print(f"  Max Drawdown: {strat_metrics['overall']['max_drawdown']:.2f}%")
            else:
                logger.warning("No results to summarize across timeframes")

    except Exception as e:
        logger.error(f"Main execution error: {str(e)}", exc_info=True)
    finally:
        if ib.isConnected():
            ib.disconnect()
            logger.info("Disconnected from IBKR")

if __name__ == '__main__':
    main()
