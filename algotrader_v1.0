# =====================
# CORE IMPORTS
# =====================
from ib_insync import IB, Stock, util
import pandas as pd
import numpy as np
import mplfinance as mpf
from datetime import datetime, timedelta, time
import asyncio
import nest_asyncio
import logging
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
from time import sleep
from matplotlib.colors import ListedColormap, Normalize, LinearSegmentedColormap
from collections.abc import MutableMapping
import pytz
import matplotlib.patheffects as pe
from matplotlib.cm import ScalarMappable
import seaborn as sns
from matplotlib.dates import DateFormatter
from scipy.signal import savgol_filter
import sys
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import statsmodels.api as sm
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from bayes_opt import BayesianOptimization
from sklearn.model_selection import ParameterGrid

param_grid = {
    'A': {
        'bollinger_zscore': [-3.0, -2.5, -2.0],
        'band_width': [0.03, 0.05, 0.07],
        'volume_spike': [1.2, 1.5, 2.0],
        'mean_reversion': [1.5, 2.0, 2.5],
        'stop_loss': [-0.01, -0.02, -0.03],
        'trailing_stop_atr': [0.5, 1.0, 1.5]
    },
    'B': {
        'zscore_entry': [-2.5, -2.0, -1.5],
        'zscore_exit': [-0.5, 0.0, 0.5],
        'profit_target': [0.2, 0.5, 1.0],
        'volatility_mult': [0.5, 1.0, 1.5],
        'position_risk': [0.01, 0.02, 0.03],
        'stop_loss': [-3.0, -2.0, -1.5]  # Added stop_loss to match strategy_bounds
    },
    'C': {
        'keltner_atr_mult_entry': [1.5, 2.0, 2.5],
        'keltner_atr_mult_exit': [1.0, 1.5, 2.0],
        'keltner_ema_period': [10, 20, 30],
        'stop_loss': [-0.03, -0.02, -0.01],  # Adjusted to match strategy_bounds range
        'trailing_stop_atr': [0.5, 1.0, 2.0]  # Adjusted to match strategy_bounds range
    }
}

class GlobalConfig:
    nest_asyncio.apply()
    symbol = 'MSFT'
    durationStr = '365 D'
    timeframes = ['1 hour']
    currency = 'USD'
    initial_balance = 10000
    MIN_REQUIRED_BANDS = 2
    gradient_levels = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
    colors = ['#FF0000', '#FFA500', '#00FF00', '#0000FF']
    outer_levels = ['weak', 'moderate', 'strong']
    volatility_threshold = 0.05
    MIN_PRICE = 5.0
    MAX_PRICE = 1000.0
    MIN_TRADE_VALUE = 10.0
    MODE_TO_ID = {
        'bollinger_reversion': 'A',
        'pca_stat_arb': 'B',
        'keltner_reversion': 'C'
    }
    STRATEGIES = {
        'A': 'bollinger_reversion',
        'B': 'pca_stat_arb',
        'C': 'keltner_reversion'
    }
    STRATEGY_LABELS = {
        'A': 'A: Bollinger Bands MR',
        'B': 'B: PCA Stat Arb MR',
        'C': 'C: Keltner Channels MR',
        'buy_and_hold': 'Benchmark: Buy & Hold'
    }

sns.set_style("whitegrid")
sns.set_context("notebook")
sns.set_palette("tab10")
plt.rcParams.update({
    'font.size': 10,
    'axes.labelcolor': 'black',
    'axes.titlepad': 12,
    'grid.color': 'gray',
    'figure.dpi': 300,
    'axes.facecolor': 'white',
    'figure.facecolor': 'white'
})

MRC_GRADIENT_STYLE = 'full_spectrum'
full_spectrum_colors = ['#FF0000', '#FFA500', '#00FF00', '#0000FF']
def create_colormap(colors_list):
    return LinearSegmentedColormap.from_list('custom_mrc', colors_list, N=len(GlobalConfig.gradient_levels))
full_spectrum_cmap = create_colormap(full_spectrum_colors)
mrc_cmap = full_spectrum_cmap

def evaluate_strategy(df, timeframe, strategy_id, mode, **params):
    engine = BacktestEngine(strategy_id, mode, timeframe)
    if strategy_id == 'A':
        engine.mode_config['bollinger_reversion']['entry_conditions']['bollinger_zscore']['threshold'] = params['bollinger_zscore']
        engine.mode_config['bollinger_reversion']['entry_conditions']['band_width']['threshold'] = params['band_width']
        engine.mode_config['bollinger_reversion']['entry_conditions']['volume_spike']['threshold'] = params['volume_spike']
        engine.mode_config['bollinger_reversion']['exit_conditions']['mean_reversion']['threshold'] = params['mean_reversion']
        engine.mode_config['bollinger_reversion']['exit_conditions']['stop_loss']['threshold'] = params['stop_loss']
        engine.mode_config['bollinger_reversion']['exit_conditions']['trailing_stop']['atr_multiplier'] = params['trailing_stop_atr']
    elif strategy_id == 'B':
        engine.mode_config['pca_stat_arb']['entry_conditions']['zscore']['threshold'] = lambda row: params['zscore_entry'] - row['ATR_shifted'] * 0.5
        engine.mode_config['pca_stat_arb']['exit_conditions']['zscore_reversion']['threshold'] = params['zscore_exit']
        engine.mode_config['pca_stat_arb']['exit_conditions']['profit_target']['threshold'] = params['profit_target']
        engine.mode_config['pca_stat_arb']['exit_conditions']['stop_loss']['threshold'] = params['stop_loss']
        engine.mode_config['pca_stat_arb']['volatility_mult'] = params['volatility_mult']
        engine.mode_config['pca_stat_arb']['position_risk'] = params['position_risk']
    elif strategy_id == 'C':
        engine.mode_config['keltner_reversion']['entry_conditions']['keltner_zscore']['threshold'] = -params['keltner_atr_mult_entry']
        engine.mode_config['keltner_reversion']['exit_conditions']['mean_reversion']['threshold'] = params['keltner_atr_mult_exit']
        engine.mode_config['keltner_reversion']['exit_conditions']['stop_loss']['threshold'] = params['stop_loss']
        engine.mode_config['keltner_reversion']['exit_conditions']['trailing_stop']['atr_multiplier'] = params['trailing_stop_atr']
        engine.mode_config['keltner_reversion']['ema_period'] = params['keltner_ema_period']
    
    engines, _ = run_backtest(df, timeframe)
    if engines is None or strategy_id not in engines:
        logger.error(f"Backtest failed for Strategy {strategy_id}")
        return -1.0
    trade_history = engines[strategy_id].trade_history
    logger.debug(f"Strategy {strategy_id}: Number of trades = {len(trade_history)}")
    metrics = calculate_day_metrics(trade_history)
    sharpe = metrics['overall']['sharpe_ratio']
    logger.debug(f"Strategy {strategy_id}: Sharpe Ratio = {sharpe}, Metrics = {metrics['overall']}")
    return sharpe if np.isfinite(sharpe) and sharpe > -1.0 else 0.01  # Return small positive value if invalid or too low

def optimize_strategy(df, timeframe=GlobalConfig.durationStr, strategy_id='A'):
    logger.info(f"Starting hybrid optimization (Bayesian + Grid) for Strategy {strategy_id} on {timeframe}")

    strategy_bounds = {
        'A': {
            'bollinger_zscore': (-3.0, -1.5),
            'band_width': (0.03, 0.10),
            'volume_spike': (1.2, 2.0),
            'mean_reversion': (1.5, 3.0),
            'stop_loss': (-0.03, -0.01),
            'trailing_stop_atr': (0.5, 2.0)
        },
        'B': {
            'zscore_entry': (-2.5, -1.0),
            'zscore_exit': (-1.0, 0.5),
            'profit_target': (0.2, 1.0),
            'stop_loss': (-3.0, -1.5),
            'volatility_mult': (0.5, 2.0),
            'position_risk': (0.01, 0.05)
        },
        'C': {
            'keltner_atr_mult_entry': (1.0, 2.5),
            'keltner_atr_mult_exit': (0.5, 2.0),
            'stop_loss': (-0.03, -0.005),
            'trailing_stop_atr': (0.5, 2.0),
            'keltner_ema_period': (10, 30)
        }
    }

    if strategy_id not in strategy_bounds:
        logger.error(f"Strategy {strategy_id} not supported for optimization")
        return None

    pbounds = strategy_bounds[strategy_id]
    mode = GlobalConfig.STRATEGIES[strategy_id]

    optimizer = BayesianOptimization(
        f=lambda **params: evaluate_strategy(df, timeframe, strategy_id, mode, **params),
        pbounds=pbounds,
        random_state=1
    )
    logger.debug(f"Running Bayesian optimization with bounds: {pbounds}")
    optimizer.maximize(init_points=5, n_iter=30)
    
    bayesian_best = optimizer.max
    if bayesian_best['target'] <= -1.0:
        logger.warning("Bayesian optimization failed, running minimal grid search")
        grid_results = []
        for params in list(ParameterGrid(param_grid[strategy_id]))[:5]:
            sharpe = evaluate_strategy(df, timeframe, strategy_id, mode, **params)
            grid_results.append({'params': params, 'sharpe': sharpe})
        grid_results.sort(key=lambda x: x['sharpe'], reverse=True)
        best_result = grid_results[0] if grid_results else {
            'params': {
                'keltner_atr_mult_entry': 1.0,
                'keltner_atr_mult_exit': 1.0,
                'stop_loss': -0.01,
                'trailing_stop_atr': 1.0,
                'keltner_ema_period': 20
            } if strategy_id == 'C' else {k: (v[0] + v[1]) / 2 for k, v in pbounds.items()},
            'sharpe': -1.0
        }
        sharpe = evaluate_strategy(df, timeframe, strategy_id, mode, **best_result['params'])
        if sharpe > best_result['sharpe']:
            best_result['sharpe'] = sharpe
        return {'params': best_result['params'], 'target': best_result['sharpe'], 'top_3': grid_results[:3]}
    logger.info(f"Bayesian best for Strategy {strategy_id}: {bayesian_best['params']}, Sharpe={bayesian_best['target']:.2f}")

    def create_refined_grid(best_params, bounds, step_size=0.1):
        grid = {}
        key_params = (
            ['bollinger_zscore', 'mean_reversion', 'stop_loss'] if strategy_id == 'A' else
            ['zscore_entry', 'zscore_exit', 'profit_target'] if strategy_id == 'B' else
            ['keltner_atr_mult_entry', 'keltner_atr_mult_exit', 'stop_loss']
        )
        for param, value in best_params.items():
            if param in key_params:
                min_val, max_val = bounds[param]
                step = step_size * (max_val - min_val) / 2
                grid[param] = [
                    max(min_val, value - step),
                    value,
                    min(max_val, value + step)
                ]
            else:
                grid[param] = [value]
        return grid

    refined_grid = create_refined_grid(bayesian_best['params'], pbounds)
    grid_combinations = list(ParameterGrid(refined_grid))
    logger.info(f"Refined grid for Strategy {strategy_id}: {len(grid_combinations)} combinations")

    grid_results = []
    import os
    max_workers = min(4, os.cpu_count() or 1)
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        future_to_params = {
            executor.submit(evaluate_strategy, df, timeframe, strategy_id, mode, **params): params
            for params in grid_combinations
        }
        for future in future_to_params:
            params = future_to_params[future]
            try:
                sharpe = future.result()
                grid_results.append({'params': params, 'sharpe': sharpe})
                logger.debug(f"Grid search for {params}: Sharpe={sharpe:.2f}")
            except Exception as e:
                logger.error(f"Grid search failed for {params}: {str(e)}")

    grid_results.sort(key=lambda x: x['sharpe'], reverse=True)
    top_3 = grid_results[:3]

    logger.info(f"Top 3 parameter sets for Strategy {strategy_id} after hybrid optimization:")
    print(f"\n=== Top 3 Parameter Sets for Strategy {strategy_id} ({GlobalConfig.STRATEGY_LABELS[strategy_id]}) ===")
    for i, result in enumerate(top_3, 1):
        logger.info(f"Rank {i}: Parameters={result['params']}, Sharpe Ratio={result['sharpe']:.2f}")
        print(f"Rank {i}:")
        print(f"  Parameters: {result['params']}")
        print(f"  Sharpe Ratio: {result['sharpe']:.2f}")

    best_result = top_3[0] if top_3 else {'params': bayesian_best['params'], 'sharpe': bayesian_best['target']}
    return {'params': best_result['params'], 'target': best_result['sharpe'], 'top_3': top_3}

def update_config(base_config, mode, params):
    """Update the mode_config with parameters (kept for potential future use)."""
    config = base_config[mode].copy()
    for key, value in params.items():
        if key in ['position_risk', 'volatility_mult']:
            config[key] = value
        elif key == 'entry_conditions':
            for cond, cond_params in value.items():
                config['entry_conditions'][cond]['threshold'] = cond_params['threshold']
        elif key == 'exit_conditions':
            for cond, cond_params in value.items():
                for param, val in cond_params.items():
                    config['exit_conditions'][cond][param] = val
        elif key == 'signal_weights':
            for sig, weight in value.items():
                config['signal_weights'][sig] = weight
    return config

# =====================
# LOGGING SETUP
# =====================
class TradeFormatter(logging.Formatter):
    GREEN = '\033[92m'
    RED = '\033[91m'
    WHITE = '\033[0m'
    
    def format(self, record):
        message = super().format(record)
        if sys.stdout.isatty():
            if 'BUY' in message:
                message = f"{self.GREEN}{message}{self.WHITE}"
            elif 'SELL' in message:
                message = f"{self.RED}{message}{self.WHITE}"
        return message

class ErrorFilter(logging.Filter):
    def filter(self, record):
        # Filter for ERROR level or messages containing "error", "fail", "could not"
        msg = record.getMessage().lower()
        return (record.levelno >= logging.ERROR or 
                any(keyword in msg for keyword in ["error", "fail", "could not", "warning"]))

# Define log files
main_log_file = 'strategy_execution.log'
error_log_file = 'error_logs.log'

# Clear existing log files
with open(main_log_file, 'w') as f:
    f.truncate(0)
with open(error_log_file, 'w') as f:
    f.truncate(0)

# Set up root logger
root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)  # Base level for all logs

# Remove any existing handlers
for handler in root_logger.handlers[:]:
    root_logger.removeHandler(handler)

# Console handler with colored output
console_handler = logging.StreamHandler()
console_handler.setFormatter(TradeFormatter('%(asctime)s | %(message)s'))

# Main file handler (all logs)
main_file_handler = logging.FileHandler(main_log_file)
main_file_handler.setFormatter(logging.Formatter('%(asctime)s | %(levelname)s | %(message)s'))

# Error file handler (filtered logs)
error_file_handler = logging.FileHandler(error_log_file)
error_file_handler.setLevel(logging.INFO)  # Capture INFO and above, filtered by ErrorFilter
error_file_handler.setFormatter(logging.Formatter('%(asctime)s | %(levelname)s | %(message)s'))
error_file_handler.addFilter(ErrorFilter())

# Add handlers to root logger
root_logger.addHandler(console_handler)
root_logger.addHandler(main_file_handler)
root_logger.addHandler(error_file_handler)

# Create logger instance
logger = logging.getLogger(__name__)

# =====================
# MARKET REGIME DETECTION
# =====================
def detect_market_regime(row):
    """Detect market regime based on ADX, ATR volatility, and RSI."""
    adx = row['adx_shifted']
    atr_volatility = row['ATR_shifted'] / row['close'] if row['close'] > 0 else float('inf')
    rsi = row['RSI_shifted']
    
    # Mean-reverting: Low ADX (< 25), moderate volatility (< 0.1), and RSI not in extreme trend (30-70)
    if (adx < 25 and  # Low trend strength
        atr_volatility < 0.1 and  # Moderate volatility
        30 < rsi < 70):  # Not overbought/oversold
        regime = 'mean_reverting'
    else:
        regime = 'trending'
    
    # Log for debugging
    logger.debug(f"Regime Check at {row.name}: ADX={adx:.2f}, ATR_Vol={atr_volatility:.4f}, RSI={rsi:.2f} -> {regime}")
    return regime

# =====================
# MARKET CLOSURE WARNING
# =====================
def enforce_ny_timezone(timestamp):
    ny_tz = pytz.timezone('America/New_York')
    try:
        if not isinstance(timestamp, pd.Timestamp):
            timestamp = pd.to_datetime(timestamp)
        if timestamp.tzinfo is None:
            logger.debug(f"Localizing naive timestamp {timestamp} to NY timezone")
            return ny_tz.localize(timestamp)
        else:
            logger.debug(f"Converting tz-aware timestamp {timestamp} to NY timezone")
            return timestamp.tz_convert(ny_tz)
    except Exception as e:
        logger.error(f"Timezone enforcement failed for {timestamp}: {str(e)}")
        raise ValueError(f"Invalid timestamp: {timestamp}")

def is_market_close(index):
    ny_tz = pytz.timezone('America/New_York')
    if index.tzinfo is None:
        logger.debug(f"Localizing naive index {index} to NY timezone")
        index = index.tz_localize(ny_tz)
    else:
        logger.debug(f"Converting tz-aware index {index} to NY timezone")
        index = index.tz_convert(ny_tz)
    
    current_time = index.time
    market_close_time = time(16, 0)
    time_delta = timedelta(minutes=10)
    
    dummy_date = index.date()
    market_close_dt = ny_tz.localize(datetime.combine(dummy_date, market_close_time))
    
    return (market_close_dt - time_delta) <= index <= market_close_dt

def ensure_ny_timezone(df):
    """Ensure the DataFrame index is in NY timezone."""
    if df.index.tz != pytz.timezone('America/New_York'):
        df.index = df.index.tz_convert('America/New_York')
    return df

# =====================
# METRICS CALCULATION
# =====================
def calculate_day_metrics(trades, risk_free_rate=0.02):
    if not trades:
        logger.debug("No trades provided, returning default metrics")
        return {
            'overall': {
                'win_rate': 0.0, 'win_loss_ratio': 0.0, 'num_trades': 0, 'total_pnl': 0.0,
                'avg_pnl': 0.0, 'sharpe_ratio': 0.0, 'sortino_ratio': 0.0, 'max_drawdown': 0.0,
                'avg_win': 0.0, 'avg_loss': 0.0, 'profit_factor': 0.0, 'avg_holding_hours': 0.0,
                'trades_per_day': 0.0, 'risk_reward_ratio': 0.0, 'recovery_factor': 0.0
            },
            'by_exit_strategy': {},
            'holding_periods': {
                'winning': 0.0,
                'losing': 0.0,
                'by_exit_strategy': {}
            },
            'volatility': {
                'avg_atr': 0.0,
                'pnl_volatility_correlation': 0.0
            }
        }

    num_trades = len(trades)
    total_pnl = 0.0
    wins = losses = 0
    pnl_list = []
    win_pnls = []
    loss_pnls = []
    holding_times = []
    exit_strategy_counts = {}
    exit_strategy_pnl = {}
    exit_strategy_wins = {}
    exit_strategy_losses = {}
    exit_strategy_holding = {}
    atr_list = []
    risk_rewards = []
    balance_history = [GlobalConfig.initial_balance]

    for t in trades:
        if not isinstance(t, dict) or 'timestamp' not in t:
            logger.error(f"Invalid trade format: {t}")
            continue
        
        trade_pnl = float(t.get('pnl', 0.0))
        if 'pnl' not in t or t['pnl'] is None:
            logger.warning(f"Trade at {t['timestamp']} missing PnL, defaulting to 0")
        total_pnl += trade_pnl
        pnl_list.append(trade_pnl)
        balance_history.append(balance_history[-1] + trade_pnl)
        
        if t['action'] == 'SELL':
            if trade_pnl > 0:
                wins += 1
                win_pnls.append(trade_pnl)
            elif trade_pnl < 0:
                losses += 1
                loss_pnls.append(trade_pnl)

            entry_time = pd.to_datetime(t.get('entry_time', t['timestamp']))
            exit_time = pd.to_datetime(t['timestamp'])
            holding_time = (exit_time - entry_time).total_seconds() / 3600
            holding_times.append(holding_time)

            exit_type = t.get('exit_type', 'Unknown')
            exit_strategy_counts[exit_type] = exit_strategy_counts.get(exit_type, 0) + 1
            exit_strategy_pnl[exit_type] = exit_strategy_pnl.get(exit_type, 0) + trade_pnl
            if trade_pnl > 0:
                exit_strategy_wins[exit_type] = exit_strategy_wins.get(exit_type, 0) + 1
            elif trade_pnl < 0:
                exit_strategy_losses[exit_type] = exit_strategy_losses.get(exit_type, 0) + 1
            exit_strategy_holding[exit_type] = exit_strategy_holding.get(exit_type, []) + [holding_time]

            if 'ATR' in t and 'entry_price' in t and 'price' in t:
                atr_list.append(float(t['ATR']))
                entry_price = float(t['entry_price'])
                exit_price = float(t['price'])
                potential_loss = abs(entry_price - (entry_price - t['ATR']))
                potential_gain = abs(exit_price - entry_price) if trade_pnl > 0 else 0
                if potential_loss > 0 and potential_gain > 0:
                    risk_rewards.append(potential_gain / potential_loss)

    win_rate = (wins / (wins + losses)) * 100 if (wins + losses) > 0 else 0.0
    win_loss_ratio = (wins / losses) if losses > 0 else float('inf') if wins > 0 else 0.0
    avg_pnl = total_pnl / num_trades if num_trades > 0 else 0.0
    avg_win = sum(win_pnls) / len(win_pnls) if win_pnls else 0.0
    avg_loss = sum(loss_pnls) / len(loss_pnls) if loss_pnls else 0.0
    profit_factor = sum(win_pnls) / abs(sum(loss_pnls)) if loss_pnls and sum(loss_pnls) != 0 else float('inf') if win_pnls else 0.0

    pnl_array = np.array(pnl_list)
    daily_rfr = risk_free_rate / 252
    excess_returns = pnl_array - daily_rfr
    mean_excess_return = np.mean(excess_returns)
    std_dev = np.std(pnl_array, ddof=1) if num_trades > 1 else 0.0
    sharpe_ratio = (mean_excess_return / std_dev) * np.sqrt(252) if std_dev > 0 else 0.0 if mean_excess_return >= 0 else -1.0

    downside_returns = pnl_array[pnl_array < 0]
    downside_dev = np.std(downside_returns, ddof=1) if len(downside_returns) > 1 else 0.0
    sortino_ratio = (mean_excess_return / downside_dev) * np.sqrt(252) if downside_dev > 0 else 0.0

    balance_array = np.array(balance_history)
    peak = np.maximum.accumulate(balance_array)
    drawdowns = (peak - balance_array) / peak
    max_drawdown = np.max(drawdowns) * 100 if np.max(drawdowns) > 0 else 0.0

    avg_holding_hours = sum(holding_times) / len(holding_times) if holding_times else 0.0
    days_span = (max(pd.to_datetime([t['timestamp'] for t in trades if t['action'] == 'SELL'])) - 
                 min(pd.to_datetime([t['timestamp'] for t in trades if t['action'] == 'SELL']))).days + 1 if len([t for t in trades if t['action'] == 'SELL']) > 1 else 1
    trades_per_day = len([t for t in trades if t['action'] == 'SELL']) / days_span if days_span > 0 else 0.0
    risk_reward_ratio = sum(risk_rewards) / len(risk_rewards) if risk_rewards and len(risk_rewards) > 0 else 0.0
    recovery_factor = total_pnl / (max_drawdown / 100 * GlobalConfig.initial_balance) if max_drawdown > 0 else float('inf')

    by_exit_strategy = {}
    holding_by_exit = {}
    for exit_type in exit_strategy_counts:
        num_trades_exit = exit_strategy_counts[exit_type]
        wins_exit = exit_strategy_wins.get(exit_type, 0)
        losses_exit = exit_strategy_losses.get(exit_type, 0)
        total_pnl_exit = exit_strategy_pnl[exit_type]
        
        by_exit_strategy[exit_type] = {
            'win_rate': (wins_exit / num_trades_exit * 100) if num_trades_exit > 0 else 0.0,
            'num_trades': num_trades_exit,
            'total_pnl': round(total_pnl_exit, 2),
            'avg_pnl': total_pnl_exit / num_trades_exit if num_trades_exit > 0 else 0.0,
            'win_loss_ratio': (wins_exit / losses_exit) if losses_exit > 0 else float('inf') if wins_exit > 0 else 0.0
        }
        holding_by_exit[exit_type] = sum(exit_strategy_holding[exit_type]) / len(exit_strategy_holding[exit_type]) if exit_strategy_holding[exit_type] else 0.0

    winning_holding = [ht for ht, pnl in zip(holding_times, [t['pnl'] for t in trades if t['action'] == 'SELL']) if pnl > 0]
    losing_holding = [ht for ht, pnl in zip(holding_times, [t['pnl'] for t in trades if t['action'] == 'SELL']) if pnl < 0]
    avg_winning_holding = sum(winning_holding) / len(winning_holding) if winning_holding else 0.0
    avg_losing_holding = sum(losing_holding) / len(losing_holding) if losing_holding else 0.0

    avg_atr = sum(atr_list) / len(atr_list) if atr_list else 0.0
    volatility_pnl_correlation = np.corrcoef(pnl_list, atr_list[:len(pnl_list)])[0, 1] if atr_list and len(pnl_list) <= len(atr_list) else 0.0

    return {
        'overall': {
            'win_rate': round(win_rate, 2),
            'win_loss_ratio': round(win_loss_ratio, 2) if win_loss_ratio != float('inf') else float('inf'),
            'num_trades': num_trades,
            'total_pnl': round(total_pnl, 2),
            'avg_pnl': round(avg_pnl, 2),
            'sharpe_ratio': round(sharpe_ratio, 2),
            'sortino_ratio': round(sortino_ratio, 2),
            'max_drawdown': round(max_drawdown, 2),
            'avg_win': round(avg_win, 2),
            'avg_loss': round(avg_loss, 2),
            'profit_factor': round(profit_factor, 2) if profit_factor != float('inf') else float('inf'),
            'avg_holding_hours': round(avg_holding_hours, 2),
            'trades_per_day': round(trades_per_day, 2),
            'risk_reward_ratio': round(risk_reward_ratio, 2),
            'recovery_factor': round(recovery_factor, 2) if recovery_factor != float('inf') else float('inf')
        },
        'by_exit_strategy': by_exit_strategy,
        'holding_periods': {
            'winning': round(avg_winning_holding, 2),
            'losing': round(avg_losing_holding, 2),
            'by_exit_strategy': {k: round(v, 2) for k, v in holding_by_exit.items()}
        },
        'volatility': {
            'avg_atr': round(avg_atr, 2),
            'pnl_volatility_correlation': round(volatility_pnl_correlation, 2)
        }
    }

# =====================
# BACKTEST ENGINE
# =====================
def is_price_valid(price):
    """Check if the stock price is within acceptable range."""
    return GlobalConfig.MIN_PRICE <= price <= GlobalConfig.MAX_PRICE

def advanced_regime_detection(df):
    features = df[['adx_shifted', 'ATR_shifted', 'RSI_shifted']].dropna()
    kmeans = KMeans(n_clusters=3).fit(features)
    df['regime'] = kmeans.predict(features)
    return df

class BacktestEngine:
    def __init__(self, strategy_id, mode, timeframe=GlobalConfig.durationStr):
        if strategy_id not in GlobalConfig.STRATEGIES:
            raise ValueError(f"Invalid strategy_id: {strategy_id}")
        self.strategy_id = strategy_id
        self.mode = mode
        self.timeframe = timeframe
        self.mode_config = {
            'bollinger_reversion': {
                'position_risk': 0.02,
                'volatility_mult': 1.5,
                'entry_conditions': {
                    'bollinger_zscore': {'threshold': -2.0, 'operator': '<'},
                    'band_width': {'threshold': 0.03, 'operator': '>'},
                    'volume_spike': {'threshold': 1.2, 'operator': '>'}
                },
                'exit_conditions': {
                    'mean_reversion': {'threshold': 2.0, 'operator': '>'},
                    'stop_loss': {'threshold': -0.015, 'operator': '<'},
                    'trailing_stop': {'atr_multiplier': 1.0}
                }
            },
            'pca_stat_arb': {
                'position_risk': 0.02,
                'volatility_mult': 1.0,
                'num_equities': 1,
                'rebalance_days': 30,
                'entry_conditions': {
                    'zscore': {'threshold': lambda row: -1.0 - row['ATR_shifted'] * 0.5, 'operator': '<'},
                    'regime': {'threshold': 'mean_reverting', 'operator': '=='}
                },
                'exit_conditions': {
                    'zscore_reversion': {'threshold': -0.5, 'operator': '>'},
                    'profit_target': {'threshold': 0.5, 'operator': '>'},
                    'stop_loss': {'threshold': -2.5, 'operator': '<'}
                }
            },
            'keltner_reversion': {
                'position_risk': 0.02,
                'volatility_mult': 1.5,
                'ema_period': 20,
                'entry_conditions': {
                    'keltner_zscore': {'threshold': -2.0, 'operator': '<'}
                },
                'exit_conditions': {
                    'mean_reversion': {'threshold': 1.5, 'operator': '>'},
                    'stop_loss': {'threshold': -0.015, 'operator': '<'},
                    'trailing_stop': {'atr_multiplier': 1.0}
                }
            }
        }
        self.validate_mode_config()
        self.balance = GlobalConfig.initial_balance
        self.current_positions = []
        self.trade_history = []
        self.fee_per_share = 0.0035
        self.slippage = 0.0002
        self.volatility_filter = {'min_mrc': 0.02, 'max_mrc': 0.08}
        self.daily_pnl = {}
        self.backtest_data = []
        self.last_metrics = None
        logger.info(f"Strategy {strategy_id} ({mode}) initialized for {timeframe} with balance: ${self.balance}")

    def validate_mode_config(self):
        required_keys = ['position_risk', 'volatility_mult', 'entry_conditions', 'exit_conditions']
        for mode, config in self.mode_config.items():
            if not all(k in config for k in required_keys):
                raise ValueError(f"Missing config keys in {mode}: {set(required_keys) - set(config.keys())}")

    @property
    def max_position_size(self):
        return self.balance * 0.02

    def calculate_position_size(self, row):
        config = self.mode_config[self.mode]
        active_positions = len(self.current_positions)
        
        if self.trade_history and not self.last_metrics:
            self.last_metrics = calculate_day_metrics(self.trade_history)
        metrics = self.last_metrics if self.last_metrics else {'overall': {'max_drawdown': 0.0}}
        drawdown_factor = max(0.5, 1 - metrics['overall']['max_drawdown'] / 50)
        
        base_risk_capital = self.balance * config['position_risk'] * drawdown_factor
        risk_factor = max(1, active_positions * 0.5)
        risk_capital = base_risk_capital / risk_factor
        
        atr_shifted = max(row.get('ATR_shifted', 0.01) or 0.01, 0.01)
        atr_risk = max(atr_shifted * config['volatility_mult'], 0.01)
        
        volume_ratio = row['volume'] / row['volume_ma_shifted'] if row['volume_ma_shifted'] > 0 else 1.0
        volume_factor = min(max(volume_ratio, 0.5), 2.0)
        
        position_size = (risk_capital / atr_risk) * volume_factor
        position_size = min(self.max_position_size, position_size)
        position_size = max(position_size, GlobalConfig.MIN_TRADE_VALUE)
        
        if position_size <= 0:
            logger.warning(f"Strategy {self.strategy_id}: Position size invalid (${position_size:.2f}), skipping trade")
            return 0
        if atr_shifted < 0.01:
            logger.warning(f"Strategy {self.strategy_id}: ATR too low ({atr_shifted:.4f}), skipping trade")
            return 0
        
        logger.debug(f"Strategy {self.strategy_id} - Position size: ${position_size:.2f} (Drawdown Factor={drawdown_factor:.2f})")
        return position_size

    def apply_slippage(self, price, is_buy, row):
        spread = (row['high'] - row['low']) * 0.5
        return price * (1 + (spread / price) if is_buy else -(spread / price))

    def calculate_fees(self, shares):
        return abs(shares * self.fee_per_share)

    def execute_trade(self, price, shares, action, timestamp, exit_type=None, row=None, position=None):
        if not is_price_valid(price):
            logger.warning(f"Strategy {self.strategy_id}: Price ${price:.2f} invalid - Range: ${GlobalConfig.MIN_PRICE}-${GlobalConfig.MAX_PRICE}, Row: {row.to_dict() if row is not None else 'None'}")
            return None

        metrics = calculate_day_metrics(self.trade_history)
        if metrics['overall']['max_drawdown'] > 20:
            logger.error(f"Strategy {self.strategy_id}: Max drawdown exceeded. Halting.")
            return None

        if action == 'BUY' and len(self.current_positions) >= 5:
            logger.warning(f"Strategy {self.strategy_id}: Max positions (5) reached, skipping buy")
            return None

        try:
            price_with_slippage = price
            if row is not None:
                if 'high' in row and 'low' in row and not pd.isna(row['high']) and not pd.isna(row['low']):
                    spread = (row['high'] - row['low']) * 0.5
                    spread_factor = spread / price
                    spread_factor = min(max(spread_factor, -0.1), 0.1)
                    price_with_slippage = price * (1 + spread_factor if action == 'BUY' else 1 - spread_factor)
                    logger.debug(f"Strategy {self.strategy_id}: Slippage applied - Price={price:.2f}, Spread={spread:.2f}, Adjusted Price={price_with_slippage:.2f}")
                else:
                    logger.warning(f"Strategy {self.strategy_id}: Missing high/low in row, skipping slippage")
                    price_with_slippage = price
            
            if not np.isfinite(price_with_slippage) or price_with_slippage <= 0:
                logger.error(f"Strategy {self.strategy_id}: Invalid price_with_slippage: {price_with_slippage}")
                return None
            
            if action == 'BUY':
                position_size = self.calculate_position_size(row)
                shares = max(0.01, round(position_size / price_with_slippage, 2))
            
            fees = self.calculate_fees(shares)
            position_value = shares * price_with_slippage

            if not np.isfinite(position_value) or position_value <= 0:
                logger.error(f"Strategy {self.strategy_id}: Invalid position value ${position_value:.2f} (shares={shares}, price_with_slippage={price_with_slippage})")
                return None
            
            if action == 'BUY' and position_value < GlobalConfig.MIN_TRADE_VALUE:
                logger.warning(f"Strategy {self.strategy_id}: Position value ${position_value:.2f} below min ${GlobalConfig.MIN_TRADE_VALUE} for BUY")
                return None

            trade = {
                'strategy_id': self.strategy_id,
                'timestamp': timestamp,
                'action': action,
                'price': price_with_slippage,
                'shares': shares,
                'position_value': position_value,
                'balance_before': self.balance,
                'exit_type': exit_type if action == 'SELL' else None
            }

            if action == 'BUY':
                total_cost = position_value + fees
                if total_cost > self.balance:
                    logger.warning(f"Strategy {self.strategy_id}: Insufficient funds: ${total_cost:.2f} > ${self.balance:.2f}")
                    return None
                if position_value > self.max_position_size:
                    logger.warning(f"Strategy {self.strategy_id}: Adjusted position value ${position_value:.2f} still exceeds max ${self.max_position_size:.2f}, scaling down")
                    shares = max(0.01, round(self.max_position_size / price_with_slippage, 2))
                    position_value = shares * price_with_slippage
                    total_cost = position_value + fees
                    if total_cost > self.balance:
                        logger.warning(f"Strategy {self.strategy_id}: Insufficient funds after scaling: ${total_cost:.2f} > ${self.balance:.2f}")
                        return None
                
                position_id = len(self.current_positions)
                self.current_positions.append({
                    'position_id': position_id,
                    'symbol': GlobalConfig.symbol,
                    'entry_price': price_with_slippage,
                    'shares': shares,
                    'timestamp': timestamp,
                    'position_value': position_value,
                    'entry_time': timestamp,
                    'highest_price': price_with_slippage
                })
                self.balance -= total_cost
                trade['pnl'] = 0.0
                trade['pnl_pct'] = 0.0
                trade['entry_time'] = timestamp
                trade['position_id'] = position_id
                logger.info(f"Strategy {self.strategy_id} - Buy: Position #{position_id}, Price=${price_with_slippage:.2f}, Shares={shares:.2f}, Value=${position_value:.2f}, Balance After=${self.balance:.2f}")

            elif action == 'SELL':
                if not position:
                    logger.error(f"Strategy {self.strategy_id}: No position provided for sell")
                    return None
                logger.debug(f"Strategy {self.strategy_id}: Before sell, positions={len(self.current_positions)}, removing Pos #{position['position_id']}")
                if position not in self.current_positions:
                    logger.error(f"Strategy {self.strategy_id}: Position #{position['position_id']} not in current_positions: {self.current_positions}")
                    return None
                self.current_positions.remove(position)
                entry_price = position['entry_price']
                entry_time = position['entry_time']
                entry_value = entry_price * shares
                exit_value = price_with_slippage * shares
                pnl = exit_value - entry_value - fees
                if not np.isfinite(pnl):
                    logger.error(f"Strategy {self.strategy_id}: Invalid PnL calculated: {pnl} (entry_value={entry_value}, exit_value={exit_value}, fees={fees})")
                    pnl = 0.0
                pnl_pct = (pnl / entry_value) * 100 if entry_value != 0 else 0
                trade['pnl'] = pnl
                trade['pnl_pct'] = pnl_pct
                trade['entry_time'] = entry_time
                trade['position_id'] = position['position_id']
                trade['Profit_Outcome'] = 1 if pnl > 0 else 0
                self.balance += (exit_value - fees)
                self.daily_pnl[timestamp.strftime('%Y-%m-%d')] = (
                    self.daily_pnl.get(timestamp.strftime('%Y-m-%d'), 0) + pnl
                )
                logger.info(f"Strategy {self.strategy_id} - Sell: Position #{position['position_id']}, Entry=${entry_price:.2f}, Exit=${price_with_slippage:.2f}, Shares={shares:.2f}, PnL=${pnl:.2f}, Profit_Outcome={trade['Profit_Outcome']}, Balance After=${self.balance:.2f}")

            trade['balance_after'] = self.balance
            if row is not None:
                trade.update(row.to_dict())
            self.trade_history.append(trade)
            self.backtest_data.append(trade)
            return trade
        except Exception as e:
            logger.error(f"Strategy {self.strategy_id} trade execution failed: {str(e)}", exc_info=True)
            return None

    def compute_pca_zscores(self, df, row):
        lookback = min(78 * 30, len(df) - 1)
        if lookback < 50:
            logger.warning(f"Insufficient data for PCA (len={len(df)}), using lookback={lookback}")
        if lookback < 2:
            return 0.0
        
        history = df.iloc[-lookback:].copy()
        if len(history) < 4:  # Minimum rows for 4 features
            logger.warning(f"History too short for PCA: {len(history)} rows")
            return 0.0
        
        history['returns'] = history['close'].pct_change().fillna(0)
        history['rsi_scaled'] = (history['RSI_shifted'] - 50) / 50
        history['volume_scaled'] = history['volume'] / history['volume_ma_shifted'] - 1
        history['macd_scaled'] = history['MACD_shifted'] / history['ATR_shifted']
        
        features = history[['returns', 'rsi_scaled', 'volume_scaled', 'macd_scaled']].fillna(0)
        if features.isna().any().any():
            logger.error(f"NaNs remain in PCA features after fillna: {features.isna().sum()}")
            return 0.0
        
        try:
            pca = PCA(n_components=1)
            factors = pca.fit_transform(features)
            X = sm.add_constant(factors)
            model = sm.OLS(history['close'], X).fit()
            residuals = model.resid
            zscore = (residuals.iloc[-1] - residuals.mean()) / residuals.std(ddof=1)
            return zscore if np.isfinite(zscore) else 0.0
        except Exception as e:
            logger.error(f"PCA computation failed: {str(e)}")
            return 0.0

    def check_exit_conditions(self, df, index, row):
        if str(index.tz) != 'America/New_York':
            raise ValueError(f"Invalid timezone in exit check: {index.tz}")
        
        if not self.current_positions:
            return None
        
        try:
            config = self.mode_config[self.mode]
            conditions = config['exit_conditions']
            current_time = enforce_ny_timezone(index)
            current_price = row['close']
            
            for pos in self.current_positions[:]:
                entry_time = pos['entry_time']
                entry_price = pos['entry_price']
                deviation = (current_price - entry_price) / entry_price
                
                atr = row.get('ATR_shifted', 1) or 1
                
                if self.mode == 'bollinger_reversion':
                    bollinger_std_shifted = row.get('bollinger_std_shifted', 1) or 1
                    bollinger_mid_shifted = row.get('bollinger_mid_shifted', current_price)
                    bollinger_deviation = (current_price - bollinger_mid_shifted) / bollinger_std_shifted
                elif self.mode == 'keltner_reversion':
                    keltner_ema = row.get('keltner_ema_shifted', current_price)
                    keltner_upper = row.get('keltner_upper_shifted', keltner_ema + atr * 2)
                    keltner_lower = row.get('keltner_lower_shifted', keltner_ema - atr * 2)
                    keltner_deviation = (current_price - keltner_ema) / atr
                elif self.mode == 'pca_stat_arb':
                    zscore = self.compute_pca_zscores(df, row)
                
                for condition_name, params in conditions.items():
                    if 'threshold' in params:
                        threshold = (params['threshold'] if isinstance(params['threshold'], (int, float))
                                     else params['threshold'](row) if callable(params['threshold'])
                                     else params['threshold'])
                    else:
                        threshold = None
                    
                    if condition_name == 'mean_reversion':
                        if self.mode == 'bollinger_reversion' and threshold is not None and bollinger_deviation > threshold:
                            logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: "
                                      f"Deviation={bollinger_deviation:.2f} > {threshold:.2f}")
                            return f'Bollinger Overbought (Pos #{pos["position_id"]})'
                        elif self.mode == 'keltner_reversion' and threshold is not None and keltner_deviation > threshold:
                            logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: "
                                      f"Deviation={keltner_deviation:.2f} > {threshold:.2f}")
                            return f'Keltner Overbought (Pos #{pos["position_id"]})'
                    
                    elif condition_name == 'stop_loss':
                        if threshold is not None and deviation < threshold:
                            logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: "
                                      f"Deviation={deviation:.2%} < {threshold:.2%}")
                            return f'Stop Loss (Pos #{pos["position_id"]})'
                    
                    elif condition_name == 'trailing_stop':
                        if 'atr_multiplier' in params:
                            atr_multiplier = params['atr_multiplier']
                            if 'highest_price' not in pos:
                                pos['highest_price'] = entry_price
                            pos['highest_price'] = max(pos['highest_price'], current_price)
                            stop_level = pos['highest_price'] - (atr * atr_multiplier)
                            if current_price <= stop_level:
                                logger.info(f"Triggered {condition_name} exit for Pos #{pos['position_id']}: "
                                          f"Price={current_price:.2f} <= Stop={stop_level:.2f}")
                                return f'Trailing Stop ({atr_multiplier}x ATR, Pos #{pos["position_id"]})'
                    
                    elif condition_name == 'zscore_reversion' and self.mode == 'pca_stat_arb':
                        if threshold is not None and zscore > threshold:
                            logger.info(f"Triggered zscore_reversion exit for Pos #{pos['position_id']}: "
                                      f"Z-Score={zscore:.2f} > {threshold:.2f}")
                            return f'Z-Score Reversion (Pos #{pos["position_id"]})'
                    
                    elif condition_name == 'profit_target' and self.mode == 'pca_stat_arb':
                        if threshold is not None and zscore > threshold:
                            logger.info(f"Triggered profit_target exit for Pos #{pos['position_id']}: "
                                      f"Z-Score={zscore:.2f} > {threshold:.2f}")
                            return f'Profit Target (Pos #{pos["position_id"]})'
            
            return None
        
        except Exception as e:
            logger.error(f"Strategy {self.strategy_id} - Error in exit check at {index}: {str(e)}", exc_info=True)
            return None

def check_all_entry_conditions(df, index, engines, row):
    if str(index.tz) != 'America/New_York':
        raise ValueError(f"Invalid timezone in entry check: {index.tz}")
    
    conditions_results = {}
    log_details = [f"Unified Entry Check at {index}"]
    
    all_conditions = set()
    for engine in engines.values():
        all_conditions.update(engine.mode_config[engine.mode]['entry_conditions'].keys())
    
    try:
        meanline = row['meanline']
        meanrange = max(row['meanrange_shifted'], 1e-6)
        volatility = row['ATR_shifted'] / row['close'] if row['close'] > 0 else float('inf')
        
        if row['meanrange_shifted'] <= 0:
            logger.warning(f"Meanrange_shifted <= 0 at {index}, using epsilon: {row['meanrange_shifted']}")
        
        regime = detect_market_regime(row)
        conditions_results['regime'] = regime
        log_details.append(f"Regime: {regime}")
        
        if 'mean_deviation' in all_conditions:
            deviation = (row['close'] - meanline) / meanrange
            conditions_results['mean_deviation'] = deviation
            log_details.append(f"Mean Deviation: {deviation:.2f}")
        
        if 'rsi' in all_conditions:
            rsi_value = row['RSI_shifted']
            conditions_results['rsi'] = rsi_value
            log_details.append(f"RSI: {rsi_value:.2f}")
        
        if 'williams_r' in all_conditions:
            williams_value = row['Williams_%R_shifted']
            conditions_results['williams_r'] = williams_value
            log_details.append(f"Williams %R: {williams_value:.2f}")
        
        if 'atr_breakout' in all_conditions:
            prev_high = df.loc[:index, 'high'].iloc[-2] if len(df.loc[:index]) > 1 else row['high']
            breakout_level = prev_high + row['ATR_shifted']
            atr_breakout = row['close'] > breakout_level
            conditions_results['atr_breakout'] = {'value': row['close'] - breakout_level, 'base_level': breakout_level}
            log_details.append(f"ATR Breakout Base: Close={row['close']:.2f}, Base Level={breakout_level:.2f}")
        
        if 'zscore' in all_conditions:
            for strat_id, engine in engines.items():
                if engine.mode == 'pca_stat_arb':
                    zscore = engine.compute_pca_zscores(df, row)
                    conditions_results['zscore'] = zscore
                    log_details.append(f"PCA Z-Score: {zscore:.2f}")
                    break
        
        if 'bollinger_zscore' in all_conditions:
            zscore = row['bollinger_zscore_shifted']
            conditions_results['bollinger_zscore'] = zscore
            log_details.append(f"Bollinger Z-Score: {zscore:.2f}")
        
        if 'band_width' in all_conditions:  # Added for Strategy A
            band_width = ((row['bollinger_upper_shifted'] - row['bollinger_lower_shifted']) / row['close']) / \
                         max(row['ATR_shifted'] / row['close'] if row['close'] > 0 else 0.01, 0.01)
            conditions_results['band_width'] = band_width
            log_details.append(f"Bollinger Band Width: {band_width:.2f}")
        
        if 'volume_spike' in all_conditions:  # Added for Strategy A
            volume_spike = row['volume'] / row['volume_ma_shifted'] if row['volume_ma_shifted'] > 0 else 0
            conditions_results['volume_spike'] = volume_spike
            log_details.append(f"Volume Spike: {volume_spike:.2f}")
        
        if 'price_divergence' in all_conditions:
            divergence = row['price_divergence_shifted']
            conditions_results['price_divergence'] = divergence
            log_details.append(f"Price Divergence: {divergence:.4f}")
        
        if 'volume' in all_conditions:
            volume_condition = row['volume'] / row['volume_ma_shifted'] if row['volume_ma_shifted'] > 0 else 0
            conditions_results['volume'] = volume_condition
            log_details.append(f"Volume Ratio: {volume_condition:.2f}")
        
        conditions_results['position_ok'] = {strat_id: engine.balance > 1000 
                                            for strat_id, engine in engines.items()}
        conditions_results['time_ok'] = not is_market_close(index)
        log_details.append(f"Time OK: {conditions_results['time_ok']}")
        
        logger.debug(" | ".join(log_details))
        return conditions_results
    
    except Exception as e:
        logger.error(f"Error in unified entry check at {index}: {str(e)}", exc_info=True)
        return {}

def evaluate_strategy_entry(strat_id, engine, conditions_results, row):
    config = engine.mode_config[engine.mode]
    conditions = config['entry_conditions']
    total_conditions = len(conditions) + 3
    conditions_met = 0
    
    log_details = [f"Strategy {strat_id} Eval at {row.name}"]
    
    current_price = row['close']
    price_valid = is_price_valid(current_price)
    conditions_met += 1 if price_valid else 0
    log_details.append(f"Price Valid (${current_price:.2f}): {price_valid}")
    if not price_valid:
        logger.debug(f"Strategy {strat_id}: Price ${current_price:.2f} outside allowed range "
                    f"(${GlobalConfig.MIN_PRICE}-${GlobalConfig.MAX_PRICE})")
    
    regime = conditions_results.get('regime', 'unknown')
    conditions_met += 1 if regime == 'mean_reverting' else 0
    log_details.append(f"Regime Mean-Reverting: {regime == 'mean_reverting'}")
    
    for condition_name, params in conditions.items():
        if condition_name not in conditions_results:
            continue
        value = conditions_results.get(condition_name)
        condition_met = False
        
        threshold = params['threshold'] if isinstance(params['threshold'], (int, float)) else params['threshold'](row) if callable(params['threshold']) else params['threshold']
        
        if condition_name == 'mean_deviation':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'rsi':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'williams_r':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'volume':
            condition_met = value > threshold if not pd.isna(value) else False
        elif condition_name == 'zscore':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'bollinger_zscore':
            condition_met = value < threshold if not pd.isna(value) else False
        elif condition_name == 'band_width':
            atr_normalized = max(row['ATR_shifted'] / max(row['close'], 0.01) if row['close'] > 0 else 0.01, 0.01)
            value = (row['bollinger_upper_shifted'] - row['bollinger_lower_shifted']) / max(row['close'], 0.01) / atr_normalized
            condition_met = value > threshold if not pd.isna(value) else False
        elif condition_name == 'volume_spike':
            condition_met = value > threshold if not pd.isna(value) else False
        elif condition_name == 'regime':
            condition_met = value == threshold if value is not None else False
        elif condition_name == 'price_divergence':
            condition_met = value < threshold if not pd.isna(value) else False
        
        conditions_met += 1 if condition_met else 0
        log_details.append(f"{condition_name}: Met={condition_met} (Value={value}, Threshold={threshold})")
    
    position_ok = conditions_results.get('position_ok', {}).get(strat_id, False)
    time_ok = conditions_results.get('time_ok', False)
    conditions_met += 1 if position_ok and time_ok else 0
    
    fraction_met = conditions_met / total_conditions
    log_details.append(f"Fraction Met: {conditions_met}/{total_conditions} ({fraction_met:.2%})")
    logger.debug(" | ".join(log_details))
    
    return fraction_met >= 0.75

# =====================
# DATA AND INDICATORS
# =====================
def log_trade(trade):
    strategy_id = trade['strategy_id']
    timestamp = pd.to_datetime(trade['timestamp']).tz_convert('America/New_York')
    log_parts = [
        f"#[{strategy_id}] {trade['action'].ljust(6)} | {GlobalConfig.symbol.ljust(5)}",
        f"Time:  {timestamp.strftime('%Y-%m-%d %H:%M:%S%z')}",
        f"Price: ${trade['price']:7.2f}",
        f"Size:  ${trade['position_value']:7.2f}",
        f"Shares: {trade['shares']:>6.2f}"
    ]
    if trade['action'] == 'SELL':
        if 'pnl' not in trade or trade['pnl'] is None:
            logger.error(f"Trade missing PnL: {trade}")
            trade['pnl'] = 0.0
        if 'Profit_Outcome' not in trade:
            trade['Profit_Outcome'] = 1 if trade['pnl'] > 0 else 0
        log_parts.extend([
            f"PnL:   ${trade['pnl']:7.2f}",
            f"Return: {trade['pnl_pct']:6.2f}%",
            f"Profit_Outcome: {trade['Profit_Outcome']}",
            f"Exit:  {trade['exit_type']}"
        ])
        logger.info(f"Trade PnL Validation: {trade['pnl']:.2f} for Position #{trade['position_id']}, Profit_Outcome: {trade['Profit_Outcome']}")
    logger.info(" | ".join(log_parts))

def calculate_mrc_with_gradient(df, length=50, gradient_levels=GlobalConfig.gradient_levels, outer_levels=GlobalConfig.outer_levels):
    if df.empty or not all(col in df.columns for col in ['high', 'low', 'close']):
        logger.error("DataFrame is empty or missing required HLC columns for MRC calculation")
        return df
    
    df = df.copy()
    
    if 'hlc3' not in df.columns:
        df['hlc3'] = (df['high'] + df['low'] + df['close']) / 3

    df['prev_close'] = df['close'].shift(1).ffill()
    df['tr1'] = df['high'] - df['low']
    df['tr2'] = abs(df['high'] - df['prev_close'])
    df['tr3'] = abs(df['low'] - df['prev_close'])
    df['tr'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)
    df.drop(['tr1', 'tr2', 'tr3', 'prev_close'], axis=1, inplace=True, errors='ignore')
    tr_mean = df['tr'].mean()
    tr_std = df['tr'].std()
    if tr_std > 0:
        df['tr'] = df['tr'].clip(tr_mean - 3 * tr_std, tr_mean + 3 * tr_std)

    df['meanline'] = supersmoother(df['hlc3'], length, apply_savgol=False).replace([np.inf, -np.inf, np.nan], np.nan).ffill().bfill()
    df['meanrange'] = df['tr'].rolling(10, min_periods=1).mean().replace([np.inf, -np.inf, np.nan], 0).ffill().bfill()
    meanrange_mean = df['meanrange'].mean()
    meanrange_std = df['meanrange'].std()
    if meanrange_std > 0:
        df['meanrange'] = df['meanrange'].clip(meanrange_mean - 3 * meanrange_std, meanrange_mean + 3 * meanrange_std)

    for level in gradient_levels:
        df[f'upband_{level}'] = df['meanline'] + (df['meanrange'] * level)
        df[f'loband_{level}'] = df['meanline'] - (df['meanrange'] * level)
        df[f'upband_{level}_shifted'] = df[f'upband_{level}'].shift(1).ffill().bfill()
        df[f'loband_{level}_shifted'] = df[f'loband_{level}'].shift(1).ffill().bfill()

    outer_multiples = {'weak': 3.0, 'moderate': 3.5, 'strong': 4.0}
    for level_name in outer_levels:
        multiple = outer_multiples[level_name]
        df[f'upband_{level_name}'] = df['meanline'] + (df['meanrange'] * multiple)
        df[f'loband_{level_name}'] = df['meanline'] - (df['meanrange'] * multiple)

    df['meanrange_shifted'] = df['meanrange'].shift(1).ffill().bfill()
    return df

def supersmoother(src: pd.Series, length: int = 50, apply_savgol: bool = False) -> pd.Series:
    if len(src) < 3 or length < 1:
        return src.ffill().bfill()
    
    src_clean = src.copy()
    mean_val = src_clean.mean()
    std_val = src_clean.std()
    if std_val > 0:
        src_clean = src_clean.clip(mean_val - 3 * std_val, mean_val + 3 * std_val)

    a1 = np.exp(-np.sqrt(2) * np.pi / length)
    b1 = 2 * a1 * np.cos(np.sqrt(2) * np.pi / length)
    c3 = -a1**2
    c2 = b1
    c1 = 1 - c2 - c3
    
    ss = np.zeros_like(src_clean, dtype=float)
    ss[0] = src_clean.iloc[0] if not pd.isna(src_clean.iloc[0]) else 0
    ss[1] = src_clean.iloc[1] if not pd.isna(src_clean.iloc[1]) else ss[0]
    for i in range(2, len(src_clean)):
        ss[i] = c1 * (src_clean.iloc[i] if not pd.isna(src_clean.iloc[i]) else ss[i-1]) + c2 * ss[i-1] + c3 * ss[i-2]
    
    result = pd.Series(ss, index=src_clean.index).replace([np.inf, -np.inf, np.nan], np.nan).ffill().bfill()
    
    if apply_savgol and len(result) >= 5:
        window_length = 5 if len(result) >= 5 else len(result)
        if window_length % 2 == 0:
            window_length += 1
        polyorder = 1
        try:
            result = pd.Series(savgol_filter(result, window_length=window_length, polyorder=polyorder), index=result.index)
        except ValueError as e:
            logger.warning(f"Savitzky-Golay filter failed: {str(e)}. Using raw supersmoother result.")
    
    if result.isna().any():
        result = result.interpolate(method='linear', limit=2).ffill().bfill()
    
    return result

def williams_r(high, low, close, lookback=14):
    highest_high = high.rolling(window=lookback, min_periods=1).max()
    lowest_low = low.rolling(window=lookback, min_periods=1).min()
    denominator = highest_high - lowest_low
    denominator = denominator.replace(0, np.nan)
    wr = -100 * ((highest_high - close) / denominator)
    return wr.fillna(-50).replace([np.inf, -np.inf], -50)

def stochastic_oscillator(df, k_period=14, d_period=3):
    low_min = df['low'].rolling(k_period).min()
    high_max = df['high'].rolling(k_period).max()
    df['%K'] = 100 * ((df['close'] - low_min) / (high_max - low_min))
    df['%K'] = df['%K'].fillna(50)
    df['%D'] = df['%K'].rolling(d_period).mean()
    return df

def calculate_point_in_time_indicators(df, index):
    try:
        row = df.loc[index].copy()
        for col in ['open', 'high', 'low', 'close', 'volume', 'hlc3', 'tr']:
            if col in row:
                row[col] = pd.to_numeric(row[col], errors='coerce')
        return row
    except KeyError:
        logger.warning(f"No data available at index {index}")
        return pd.Series()

def calculate_buy_and_hold(df, initial_balance=GlobalConfig.initial_balance, fee_per_share=0.0035):
    try:
        if df.empty or 'close' not in df.columns:
            logger.error("Invalid DataFrame for Buy & Hold calculation")
            return None

        df = ensure_ny_timezone(df.copy())
        
        buy_price = df['close'].iloc[0]
        sell_price = df['close'].iloc[-1]
        
        shares = max(1, round((initial_balance - (initial_balance * fee_per_share)) / buy_price, 0))
        buy_cost = shares * buy_price + (shares * fee_per_share)
        sell_value = shares * sell_price - (shares * fee_per_share)
        
        total_pnl = sell_value - buy_cost
        pnl_pct = (total_pnl / buy_cost) * 100 if buy_cost > 0 else 0.0
        
        trade_history = [
            {
                'strategy_id': 'buy_and_hold',
                'timestamp': df.index[0],
                'action': 'BUY',
                'price': buy_price,
                'shares': shares,
                'position_value': shares * buy_price,
                'pnl': 0.0,
                'entry_time': df.index[0]
            },
            {
                'strategy_id': 'buy_and_hold',
                'timestamp': df.index[-1],
                'action': 'SELL',
                'price': sell_price,
                'shares': shares,
                'position_value': shares * sell_price,
                'pnl': total_pnl,
                'pnl_pct': pnl_pct,
                'entry_time': df.index[0],
                'exit_type': 'End of Period'
            }
        ]
        
        metrics = calculate_day_metrics(trade_history)
        logger.info(f"Buy & Hold - Buy Price: ${buy_price:.2f}, Sell Price: ${sell_price:.2f}, Shares: {shares}, PnL: ${total_pnl:.2f}")
        return {'metrics': metrics, 'final_balance': initial_balance + total_pnl}
    except Exception as e:
        logger.error(f"Error in Buy & Hold calculation: {str(e)}", exc_info=True)
        return None

def get_historical_data(ib, timeframe, exchange='SMART', currency='USD', backtest=False):
    max_retries = 3
    try:
        contract = Stock(GlobalConfig.symbol, exchange, currency)
        ib.qualifyContracts(contract)
        if backtest:
            logger.info(f"Requesting historical data for {GlobalConfig.symbol} at {timeframe}")
            for attempt in range(max_retries):
                try:
                    bars = ib.reqHistoricalData(
                        contract,
                        endDateTime='',
                        durationStr=GlobalConfig.durationStr,
                        barSizeSetting=timeframe,
                        whatToShow='TRADES',
                        useRTH=True,
                        formatDate=2,
                        keepUpToDate=False
                    )
                    if not bars:
                        raise ValueError("No data received from IBKR")
                    break
                except Exception as e:
                    logger.error(f"Attempt {attempt + 1} failed for {timeframe}: {str(e)}")
                    if attempt == max_retries - 1:
                        logger.error(f"Failed to fetch data for {timeframe} after {max_retries} attempts")
                        return None
                    sleep(2)

            df = util.df(bars)
            if df.empty:
                logger.error(f"Empty DataFrame received from IBKR for {timeframe}")
                return None

            df['date'] = pd.to_datetime(df['date'], utc=True)
            df.set_index('date', inplace=True)
            df.index = df.index.tz_convert('America/New_York')

            required_cols = ['open', 'high', 'low', 'close', 'volume']
            for col in required_cols:
                if col not in df.columns:
                    logger.error(f"Missing required column for {timeframe}: {col}")
                    return None
                df[col] = pd.to_numeric(df[col], errors='coerce')
                if df[col].isna().all():
                    logger.error(f"Column {col} contains only NaN values for {timeframe}")
                    return None
                col_mean = df[col].mean()
                col_std = df[col].std()
                if col_std > 0:
                    df[col] = df[col].clip(col_mean - 3 * col_std, col_mean + 3 * col_std)
                df[col] = df[col].interpolate(method='linear', limit=2).ffill().bfill()

            df['hlc3'] = (df['high'] + df['low'] + df['close']) / 3
            df['tr'] = df[['high', 'low', 'close']].apply(
                lambda x: max(x['high'] - x['low'],
                              abs(x['high'] - df['close'].shift().bfill().loc[x.name]),
                              abs(x['low'] - df['close'].shift().bfill().loc[x.name])), axis=1)
            return df
        return None
    except Exception as e:
        logger.error(f"Error in get_historical_data for {timeframe}: {str(e)}", exc_info=True)
        return None

def calculate_adx(df, window=14):
    high = df['high']
    low = df['low']
    close = df['close']
    tr = np.maximum(high - low, np.maximum(np.abs(high - close.shift().bfill()), np.abs(low - close.shift().bfill())))
    up_move = high.diff()
    down_move = -low.diff()
    tr_smooth = tr.ewm(alpha=1/window, adjust=False).mean()
    plus_dm = up_move.where((up_move > down_move) & (up_move > 0), 0.0)
    minus_dm = down_move.where((down_move > up_move) & (down_move > 0), 0.0)
    plus_di = 100 * (plus_dm.ewm(alpha=1/window, adjust=False).mean() / tr_smooth)
    minus_di = 100 * (minus_dm.ewm(alpha=1/window, adjust=False).mean() / tr_smooth)
    di_diff = np.abs(plus_di - minus_di)
    di_sum = (plus_di + minus_di).replace(0, 1e-8)
    dx = 100 * (di_diff / di_sum)
    adx = dx.ewm(alpha=1/window, adjust=False).mean().clip(0, 100)
    df['adx'] = adx
    df['+di'] = plus_di
    df['-di'] = minus_di
    df['adx_shifted'] = adx.shift(1).fillna(0)
    return df

def calculate_rsi(close, period=14):
    delta = close.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss.replace(0, np.inf)
    return 100 - (100 / (1 + rs)).fillna(50)

def calculate_bollinger_bands(df, window=20, num_std=2):
    df = df.copy()
    
    df['bollinger_mid'] = df['close'].rolling(window=window, min_periods=1).mean()
    df['bollinger_std'] = df['close'].rolling(window=window, min_periods=1).std()
    df['bollinger_upper'] = df['bollinger_mid'] + (df['bollinger_std'] * num_std)
    df['bollinger_lower'] = df['bollinger_mid'] - (df['bollinger_std'] * num_std)
    df['bollinger_zscore'] = (df['close'] - df['bollinger_mid']) / df['bollinger_std'].replace(0, np.nan).fillna(0)
    
    shifted_cols = ['bollinger_mid', 'bollinger_std', 'bollinger_upper', 'bollinger_lower', 'bollinger_zscore']
    for col in shifted_cols:
        df[f'{col}_shifted'] = df[col].shift(1).fillna(df[col].iloc[0] if not df[col].empty else 0)
    
    return df

def calculate_bollinger_width(row):
    """Calculate Bollinger Band width relative to ATR."""
    band_width = (row['bollinger_upper_shifted'] - row['bollinger_lower_shifted']) / row['close']
    atr_normalized = row['ATR_shifted'] / row['close'] if row['close'] > 0 else 0.01
    return band_width / max(atr_normalized, 0.01)  # Avoid division by zero

def print_backtest_report(metrics, bar_size, strategy_name):
    print(f"\n=== {strategy_name} Performance Report - {bar_size} ===")
    print("\nOverall Metrics:")
    for key, value in metrics['overall'].items():
        print(f"  {key.replace('_', ' ').title()}: {value if value != float('inf') else '∞'}")

    print("\nPerformance by Exit Strategy:")
    for strategy, stats in metrics['by_exit_strategy'].items():
        print(f"  {strategy}:")
        for key, value in stats.items():
            print(f"    {key.replace('_', ' ').title()}: {value if value != float('inf') else '∞'}")

    print("\nHolding Periods (hours):")
    print(f"  Winning Trades: {metrics['holding_periods']['winning']}")
    print(f"  Losing Trades: {metrics['holding_periods']['losing']}")
    print("  By Exit Strategy:")
    for strategy, hours in metrics['holding_periods']['by_exit_strategy'].items():
        print(f"    {strategy}: {hours}")

    print("\nVolatility Metrics:")
    print(f"  Average ATR: {metrics['volatility']['avg_atr']}")
    print(f"  PnL-Volatility Correlation: {metrics['volatility']['pnl_volatility_correlation']}")

def execute_entry(strategy_id, engine, price, timestamp, position_size, row):
    timestamp = enforce_ny_timezone(pd.to_datetime(timestamp))
    shares = max(0.01, round(position_size / price, 2))
    if not np.isfinite(shares):
        logger.error(f"Strategy {strategy_id}: Invalid share calculation: Shares={shares}")
        return None
    trade = engine.execute_trade(price=price, shares=shares, action='BUY', timestamp=timestamp, row=row)
    if trade:
        log_trade(trade)
    return trade

def execute_exit(strategy_id, engine, price, timestamp, exit_type, row):
    if not engine.current_positions:
        logger.warning(f"Strategy {strategy_id}: Exit attempted with no positions")
        return None
    timestamp = enforce_ny_timezone(pd.to_datetime(timestamp))
    if not exit_type or 'Pos #' not in exit_type:
        logger.error(f"Strategy {strategy_id}: Invalid exit_type format: {exit_type}")
        return None
    try:
        pos_id = int(exit_type.split('Pos #')[1].strip(')'))
    except (IndexError, ValueError) as e:
        logger.error(f"Strategy {strategy_id}: Failed to parse pos_id from exit_type '{exit_type}': {str(e)}")
        return None
    position = next((p for p in engine.current_positions if p['position_id'] == pos_id), None)
    if not position:
        logger.warning(f"Strategy {strategy_id}: Position #{pos_id} not found for exit in {engine.current_positions}")
        return None
    exit_shares = position['shares']
    logger.debug(f"Strategy {strategy_id}: Attempting exit for Pos #{pos_id}, Shares={exit_shares}, Price={price}")
    trade = engine.execute_trade(price=price, shares=exit_shares, action='SELL', timestamp=timestamp, exit_type=exit_type, row=row, position=position)
    if trade:
        log_trade(trade)
    else:
        logger.error(f"Strategy {strategy_id}: Failed to execute exit trade for Pos #{pos_id}")
    return trade

def calculate_keltner_channels(df, ema_period=20, atr_period=14, atr_multiplier=2.0):
    df = df.copy()
    df['keltner_ema'] = df['close'].ewm(span=ema_period, adjust=False).mean()
    df['ATR'] = df['tr'].rolling(atr_period, min_periods=1).mean()
    df['keltner_upper'] = df['keltner_ema'] + (df['ATR'] * atr_multiplier)
    df['keltner_lower'] = df['keltner_ema'] - (df['ATR'] * atr_multiplier)
    df['keltner_zscore'] = (df['close'] - df['keltner_ema']) / df['ATR'].replace(0, np.nan).fillna(0.01)
    
    shifted_cols = ['keltner_ema', 'keltner_upper', 'keltner_lower', 'keltner_zscore']
    for col in shifted_cols:
        df[f'{col}_shifted'] = df[col].shift(1).fillna(df[col].iloc[0] if not df[col].empty else 0)
    
    return df

def run_backtest(df, timeframe, collect_non_trades=False, cache=None):
    try:
        if df is None or df.empty:
            logger.error(f"Invalid input data for backtest at {timeframe}")
            return None, None
        if not all(col in df.columns for col in ['open', 'high', 'low', 'close', 'volume']):
            logger.error("DataFrame missing required OHLCV columns")
            return None, None
        if cache and timeframe in cache:
            logger.info(f"Using cached data for {timeframe}")
            df = cache[timeframe]
        else:
            logger.info(f"Starting optimized backtest for {timeframe} with data shape: {df.shape}")
            df = calculate_mrc_with_gradient(df)
            df['ATR'] = df['tr'].rolling(14, min_periods=1).mean().fillna(0)
            df = calculate_adx(df)
            df = stochastic_oscillator(df)
            df['VWAP'] = (df['hlc3'] * df['volume']).groupby(df.index.date).cumsum() / df['volume'].groupby(df.index.date).cumsum().fillna(df['close'])
            df['MACD'] = df['close'].ewm(span=12, adjust=False).mean() - df['close'].ewm(span=26, adjust=False).mean()
            df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
            df['Histogram'] = df['MACD'] - df['Signal']
            df['RSI'] = calculate_rsi(df['close']).fillna(50)
            df['Williams_%R'] = williams_r(df['high'], df['low'], df['close']).fillna(-50)
            df['volume_ma'] = df['volume'].rolling(20, min_periods=1).mean().fillna(df['volume'].mean())
            df = calculate_bollinger_bands(df)
            df = calculate_keltner_channels(df)
            df['price_change'] = df['close'].pct_change()
            df['price_divergence_shifted'] = df['price_change'].shift(1).fillna(0)

            shifted_cols = ['close', 'RSI', 'Williams_%R', 'VWAP', 'MACD', 'Signal', 'Histogram', 'adx', '+di', '-di', '%K', '%D', 'volume_ma', 'ATR', 'meanrange',
                            'bollinger_mid', 'bollinger_upper', 'bollinger_lower', 'bollinger_zscore', 'bollinger_std',
                            'keltner_ema', 'keltner_upper', 'keltner_lower', 'keltner_zscore']
            for col in shifted_cols:
                if col in df.columns:
                    df[f'{col}_shifted'] = df[col].shift(1).fillna(df[col].iloc[0])
            if cache is not None:
                cache[timeframe] = df.copy()

        # Ensure market open and price validity columns are defined
        df['is_market_open'] = ~df.index.map(is_market_close)  # True if not near market close
        df['price_valid'] = df['close'].apply(is_price_valid)  # True if price within valid range
        logger.debug(f"Market open periods: {df['is_market_open'].sum()}, Price valid periods: {df['price_valid'].sum()}")

        engines = {
            'A': BacktestEngine('A', 'bollinger_reversion', timeframe),
            'B': BacktestEngine('B', 'pca_stat_arb', timeframe),
            'C': BacktestEngine('C', 'keltner_reversion', timeframe)
        }

        # Adjust thresholds for better trade frequency while enforcing regime
        engines['A'].mode_config['bollinger_reversion']['entry_conditions']['bollinger_zscore']['threshold'] = -1.5
        engines['A'].mode_config['bollinger_reversion']['entry_conditions']['band_width']['threshold'] = 0.02
        engines['A'].mode_config['bollinger_reversion']['entry_conditions']['volume_spike']['threshold'] = 1.1
        engines['A'].mode_config['bollinger_reversion']['exit_conditions']['mean_reversion']['threshold'] = 0.5
        engines['A'].mode_config['bollinger_reversion']['exit_conditions']['trailing_stop']['atr_multiplier'] = 2.0

        engines['B'].mode_config['pca_stat_arb']['entry_conditions']['zscore']['threshold'] = lambda row: -1.0 - row['ATR_shifted'] * 0.2
        engines['B'].mode_config['pca_stat_arb']['exit_conditions']['zscore_reversion']['threshold'] = 0.5
        engines['B'].mode_config['pca_stat_arb']['exit_conditions']['trailing_stop'] = {'atr_multiplier': 2.0}  # Add trailing stop

        engines['C'].mode_config['keltner_reversion']['entry_conditions']['keltner_zscore']['threshold'] = -1.5
        engines['C'].mode_config['keltner_reversion']['exit_conditions']['mean_reversion']['threshold'] = 0.5
        engines['C'].mode_config['keltner_reversion']['exit_conditions']['trailing_stop']['atr_multiplier'] = 2.0

        # Calculate regime for all rows
        df['regime'] = df.apply(detect_market_regime, axis=1)
        logger.info(f"Regime distribution: {df['regime'].value_counts().to_dict()}")

        # Entry conditions with forced regime check
        config_a = engines['A'].mode_config['bollinger_reversion']
        df['entry_a'] = (
            (df['bollinger_zscore_shifted'] < config_a['entry_conditions']['bollinger_zscore']['threshold']) &
            ((df['bollinger_upper_shifted'] - df['bollinger_lower_shifted']) / df['close'] / 
             (df['ATR_shifted'] / df['close']).clip(lower=0.01) > config_a['entry_conditions']['band_width']['threshold']) &
            (df['volume'] / df['volume_ma_shifted'] > config_a['entry_conditions']['volume_spike']['threshold']) &
            (df['regime'] == 'mean_reverting') &  # Enforced regime check
            df['is_market_open'] & df['price_valid']
        )
        logger.info(f"Strategy A potential entries: {df['entry_a'].sum()}")

        config_b = engines['B'].mode_config['pca_stat_arb']
        df['zscore'] = df.apply(lambda row: engines['B'].compute_pca_zscores(df, row), axis=1)
        df['entry_b'] = (
            (df['zscore'] < config_b['entry_conditions']['zscore']['threshold'](df.iloc[-1])) &
            (df['regime'] == 'mean_reverting') &  # Already present, kept for consistency
            df['is_market_open'] & df['price_valid']
        )
        logger.info(f"Strategy B potential entries: {df['entry_b'].sum()}")

        config_c = engines['C'].mode_config['keltner_reversion']
        df['entry_c'] = (
            (df['keltner_zscore_shifted'] < config_c['entry_conditions']['keltner_zscore']['threshold']) &
            (df['regime'] == 'mean_reverting') &  # Enforced regime check
            df['is_market_open'] & df['price_valid']
        )
        logger.info(f"Strategy C potential entries: {df['entry_c'].sum()}")

        # Exit conditions
        df['exit_a_mean'] = df['bollinger_zscore_shifted'] > config_a['exit_conditions']['mean_reversion']['threshold']
        df['exit_b_zscore'] = df['zscore'] > config_b['exit_conditions']['zscore_reversion']['threshold']
        df['exit_c_mean'] = df['keltner_zscore_shifted'] > config_c['exit_conditions']['mean_reversion']['threshold']

        # Trade execution loop
        for strat_id, engine in engines.items():
            entry_col = f'entry_{strat_id.lower()}'
            trade_history = []

            logger.debug(f"Processing Strategy {strat_id} with {df[entry_col].sum()} potential entries")
            for idx, row in df[df[entry_col]].iterrows():
                if len(engine.current_positions) < 5:
                    position_size = engine.calculate_position_size(row)
                    logger.debug(f"Strategy {strat_id} at {idx}: Position size calculated as ${position_size:.2f}")
                    if position_size > 0:
                        trade = engine.execute_trade(row['close'], position_size / row['close'], 'BUY', idx, row=row)
                        if trade:
                            trade_history.append(trade)
                        else:
                            logger.debug(f"Strategy {strat_id} at {idx}: Trade execution failed")

            for i in range(len(df)):
                row = df.iloc[i]
                exit_type = engine.check_exit_conditions(df, row.name, row)
                if exit_type:
                    pos_id = int(exit_type.split('Pos #')[1].strip(')'))
                    position = next((p for p in engine.current_positions if p['position_id'] == pos_id), None)
                    if position:
                        trade = engine.execute_trade(row['close'], position['shares'], 'SELL', row.name, exit_type, row=row, position=position)
                        if trade:
                            trade_history.append(trade)

            engine.trade_history = trade_history
            logger.info(f"Strategy {strat_id} completed - Trades: {len(trade_history)}")

        return engines, df
    except Exception as e:
        logger.error(f"Error in run_backtest: {str(e)}", exc_info=True)
        return None, None
    
# =====================
# MAIN EXECUTION
# =====================
def main():
    ib = IB()
    max_retries = 3
    try:
        logger.setLevel(logging.DEBUG)
        logger.info("Starting main execution with Bollinger Bands MR, PCA Stat Arb MR, Keltner Channels MR, and Buy & Hold comparison")
        ib_connected = False
        for attempt in range(max_retries):
            try:
                ib.connect('127.0.0.1', 7497, clientId=1)
                logger.info("Connected to IBKR")
                ib_connected = True
                break
            except Exception as e:
                logger.error(f"IB connection attempt {attempt + 1} failed: {str(e)}")
                if attempt == max_retries - 1:
                    logger.warning("Failed to connect to IBKR after retries, using synthetic data")
        
        all_results = {}
        for timeframe in GlobalConfig.timeframes:
            logger.info(f"Processing timeframe: {timeframe}")
            if ib_connected:
                daily_data = get_historical_data(ib, timeframe, backtest=True)
            else:
                # Synthetic data fallback
                logger.info(f"Generating synthetic data for {timeframe}")
                daily_data = pd.DataFrame({
                    'open': np.random.uniform(100, 110, 100),
                    'high': np.random.uniform(110, 120, 100),
                    'low': np.random.uniform(90, 100, 100),
                    'close': np.random.uniform(100, 110, 100),
                    'volume': np.random.randint(1000, 10000, 100)
                }, index=pd.date_range('2025-02-01', periods=100, freq='5min', tz='America/New_York'))
            
            if daily_data is None or len(daily_data) < 2:
                logger.error(f"Failed or insufficient data for {timeframe}, skipping")
                continue
            
            engines, daily_data = run_backtest(daily_data, timeframe)
            if engines is None:
                logger.error(f"Backtest failed for {timeframe}, skipping")
                continue

            trade_histories = {strat_id: engine.trade_history for strat_id, engine in engines.items()}
            metrics = {}
            for strat_id, trades in trade_histories.items():
                strat_name = GlobalConfig.STRATEGY_LABELS[strat_id]
                metrics[strat_name] = calculate_day_metrics(trades)
                print(f"\n=== {strat_name} Final Stats for {timeframe} TF ===")
                print(f"# of Trades: {len(trades)}")
                print(f"Final Balance: ${engines[strat_id].balance:.2f}")
                print_backtest_report(metrics[strat_name], timeframe, strat_name)

            selected_strategies = {
                'A: Bollinger Bands MR': metrics['A: Bollinger Bands MR'],
                'B: PCA Stat Arb MR': metrics['B: PCA Stat Arb MR'],
                'C: Keltner Channels MR': metrics['C: Keltner Channels MR']
            }

            buy_hold_result = calculate_buy_and_hold(daily_data)
            if buy_hold_result:
                selected_strategies['Benchmark: Buy & Hold'] = buy_hold_result['metrics']
                print(f"\n=== Buy & Hold Final Stats for {timeframe} TF ===")
                print(f"# of Trades: 2 (Buy & Sell)")
                print(f"Final Balance: ${buy_hold_result['final_balance']:.2f}")
                print_backtest_report(buy_hold_result['metrics'], timeframe, "Buy & Hold")

            all_results[timeframe] = {
                'engines': engines,
                'metrics': selected_strategies,
                'data': daily_data
            }

        # Optimize all strategies
        optimized_results = {}
        for timeframe, result in all_results.items():
            for strat_id in ['A', 'B', 'C']:
                logger.info(f"Optimizing Strategy {strat_id} for timeframe {timeframe}")
                optimized_result = optimize_strategy(result['data'], timeframe, strat_id)
                if optimized_result and 'top_3' in optimized_result:
                    optimized_results[f"{strat_id}_{timeframe}"] = optimized_result
                    engine = result['engines'][strat_id]
                    
                    if strat_id == 'A':
                        engine.mode_config['bollinger_reversion']['entry_conditions']['bollinger_zscore']['threshold'] = optimized_result['params']['bollinger_zscore']
                        engine.mode_config['bollinger_reversion']['entry_conditions']['band_width']['threshold'] = optimized_result['params']['band_width']
                        engine.mode_config['bollinger_reversion']['entry_conditions']['volume_spike']['threshold'] = optimized_result['params']['volume_spike']
                        engine.mode_config['bollinger_reversion']['exit_conditions']['mean_reversion']['threshold'] = optimized_result['params']['mean_reversion']
                        engine.mode_config['bollinger_reversion']['exit_conditions']['stop_loss']['threshold'] = optimized_result['params']['stop_loss']
                        engine.mode_config['bollinger_reversion']['exit_conditions']['trailing_stop']['atr_multiplier'] = optimized_result['params']['trailing_stop_atr']
                    elif strat_id == 'B':
                        engine.mode_config['pca_stat_arb']['entry_conditions']['zscore']['threshold'] = lambda row: optimized_result['params']['zscore_entry'] - row['ATR_shifted'] * 0.5
                        engine.mode_config['pca_stat_arb']['exit_conditions']['zscore_reversion']['threshold'] = optimized_result['params']['zscore_exit']
                        engine.mode_config['pca_stat_arb']['exit_conditions']['profit_target']['threshold'] = optimized_result['params']['profit_target']
                        engine.mode_config['pca_stat_arb']['exit_conditions']['stop_loss']['threshold'] = optimized_result['params']['stop_loss']
                        engine.mode_config['pca_stat_arb']['volatility_mult'] = optimized_result['params']['volatility_mult']
                        engine.mode_config['pca_stat_arb']['position_risk'] = optimized_result['params']['position_risk']
                    elif strat_id == 'C':
                        engine.mode_config['keltner_reversion']['entry_conditions']['keltner_zscore']['threshold'] = optimized_result['params']['keltner_atr_mult_entry']
                        engine.mode_config['keltner_reversion']['exit_conditions']['mean_reversion']['threshold'] = optimized_result['params']['keltner_atr_mult_exit']
                        engine.mode_config['keltner_reversion']['exit_conditions']['stop_loss']['threshold'] = optimized_result['params']['stop_loss']
                        engine.mode_config['keltner_reversion']['exit_conditions']['trailing_stop']['atr_multiplier'] = optimized_result['params']['trailing_stop_atr']
                        engine.mode_config['keltner_reversion']['ema_period'] = optimized_result['params']['keltner_ema_period']
                    
                    engines_opt, _ = run_backtest(result['data'], timeframe)
                    if engines_opt and strat_id in engines_opt:
                        optimized_metrics = calculate_day_metrics(engines_opt[strat_id].trade_history)
                        print(f"\n=== Optimized {GlobalConfig.STRATEGY_LABELS[strat_id]} Stats for {timeframe} TF ===")
                        print(f"# of Trades: {len(engines_opt[strat_id].trade_history)}")
                        print(f"Final Balance: ${engines_opt[strat_id].balance:.2f}")
                        print_backtest_report(optimized_metrics, timeframe, f"Optimized {GlobalConfig.STRATEGY_LABELS[strat_id]}")
                    else:
                        logger.debug(f"Optimized backtest failed for Strategy {strat_id} on {timeframe}")
                else:
                    logger.debug(f"No optimization result for Strategy {strat_id} on {timeframe}")

        # Summary
        if all_results:
            print("\n=== Multi-Timeframe Backtest Summary ===")
            results_list = []
            for timeframe, result in all_results.items():
                for strat_name, strat_metrics in result['metrics'].items():
                    results_list.append({
                        'bar_size': timeframe,
                        'strategy': strat_name,
                        'total_pnl': strat_metrics['overall']['total_pnl'],
                        'sharpe_ratio': strat_metrics['overall']['sharpe_ratio'],
                        'profit_factor': strat_metrics['overall']['profit_factor'],
                        'num_trades': strat_metrics['overall']['num_trades'],
                        'win_rate': strat_metrics['overall']['win_rate'],
                        'max_drawdown': strat_metrics['overall']['max_drawdown'],
                        'avg_holding_hours': strat_metrics['overall']['avg_holding_hours']
                    })
            results_df = pd.DataFrame(results_list)
            if not results_df.empty:
                best_pnl = results_df.loc[results_df['total_pnl'].idxmax()]
                print(f"\nBest Total PnL: {best_pnl['strategy']} on {best_pnl['bar_size']}")
                print(f"  Total PnL: ${best_pnl['total_pnl']:.2f}")
                print(f"  Sharpe Ratio: {best_pnl['sharpe_ratio']:.2f}")
                print(f"  Profit Factor: {best_pnl['profit_factor']:.2f}")

    except Exception as e:
        logger.error(f"Main execution error: {str(e)}", exc_info=True)
    finally:
        if ib.isConnected():
            ib.disconnect()
            logger.info("Disconnected from IBKR")

if __name__ == '__main__':
    main()
